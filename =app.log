2023-04-04 11:09:42,249 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 8787 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:09:42,277 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:09:44,841 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:09:44,842 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:09:44,973 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:09:45,296 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7f42e06e]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:09:45,340 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bb82149b3887ee0d94f18', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:23}] to localhost:27017
2023-04-04 11:09:45,341 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bb82149b3887ee0d94f18', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=67025790}
2023-04-04 11:09:45,358 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bb82149b3887ee0d94f18', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:22}] to localhost:27017
2023-04-04 11:09:48,694 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 7.192 seconds (JVM running for 9.026)
2023-04-04 11:09:48,701 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:09:48,724 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:11:37,356 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:11:37,390 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-1] Unauthorized error: Full authentication is required to access this resource
2023-04-04 11:11:46,899 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-3] Invalid JWT signature: JWT signature does not match locally computed signature. JWT validity cannot be asserted and should not be trusted.
2023-04-04 11:11:46,901 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-3] Unauthorized error: Full authentication is required to access this resource
2023-04-04 11:12:29,935 INFO org.mongodb.driver.connection [http-nio-8080-exec-4] Opened connection [connectionId{localValue:3, serverValue:24}] to localhost:27017
2023-04-04 11:12:30,154 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-4] Unauthorized error: Bad credentials
2023-04-04 11:12:34,195 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-5] Unauthorized error: Bad credentials
2023-04-04 11:14:18,823 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-8] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: Error: Role is not found.] with root cause
java.lang.RuntimeException: Error: Role is not found.
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$4(AuthController.java:112)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$2(AuthController.java:112)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at com.example.spring.jwt.mongodb.controllers.AuthController.registerUser(AuthController.java:102)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:12,100 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-10] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: Error: Role is not found.] with root cause
java.lang.RuntimeException: Error: Role is not found.
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$1(AuthController.java:99)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at com.example.spring.jwt.mongodb.controllers.AuthController.registerUser(AuthController.java:99)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:51,243 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(8)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 11:15:51,246 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(8)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 11:15:51,255 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:51,257 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bb82149b3887ee0d94f18', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:51,259 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bb82149b3887ee0d94f18', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:51,260 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:15:56,617 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 9348 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:15:56,621 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:15:58,670 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:15:58,672 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:15:58,806 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:15:59,029 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@6048e26a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:15:59,059 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bb9964361a41515a7f41f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:27}] to localhost:27017
2023-04-04 11:15:59,060 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bb9964361a41515a7f41f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:28}] to localhost:27017
2023-04-04 11:15:59,061 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bb9964361a41515a7f41f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=34823262}
2023-04-04 11:16:01,418 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.385 seconds (JVM running for 6.582)
2023-04-04 11:16:01,424 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:16:01,425 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:16:48,897 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:16:49,226 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:29}] to localhost:27017
2023-04-04 11:16:49,502 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: Error: Role is not found.] with root cause
java.lang.RuntimeException: Error: Role is not found.
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$4(AuthController.java:112)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$2(AuthController.java:112)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at com.example.spring.jwt.mongodb.controllers.AuthController.registerUser(AuthController.java:102)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:19:44,701 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-4] Unauthorized error: Bad credentials
2023-04-04 11:20:09,125 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(6)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 11:20:09,128 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(6)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 11:20:09,137 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:20:09,138 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bb9964361a41515a7f41f', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:20:09,141 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bb9964361a41515a7f41f', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:20:09,142 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:20:38,002 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 9690 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:20:38,011 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:20:40,459 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:20:40,460 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:20:40,611 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:20:40,929 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@73ca34e7]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:20:40,967 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bbab0d96fbc0c05c12325', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:30}] to localhost:27017
2023-04-04 11:20:40,967 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bbab0d96fbc0c05c12325', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:31}] to localhost:27017
2023-04-04 11:20:40,969 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bbab0d96fbc0c05c12325', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=45261149}
2023-04-04 11:20:44,289 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 7.048 seconds (JVM running for 9.197)
2023-04-04 11:20:44,295 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:20:44,296 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:21:05,348 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:21:06,762 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 556 ms
2023-04-04 11:22:29,128 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-4] Unauthorized error: Full authentication is required to access this resource
2023-04-04 11:22:52,814 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-5] Unauthorized error: Full authentication is required to access this resource
2023-04-04 11:24:23,018 INFO org.mongodb.driver.connection [http-nio-8080-exec-8] Opened connection [connectionId{localValue:3, serverValue:32}] to localhost:27017
2023-04-04 11:24:42,269 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-8] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: Error: Role is not found.] with root cause
java.lang.RuntimeException: Error: Role is not found.
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$5(AuthController.java:118)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$2(AuthController.java:118)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at com.example.spring.jwt.mongodb.controllers.AuthController.registerUser(AuthController.java:102)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:26:20,500 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 10056 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:26:20,504 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:26:22,673 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:26:22,674 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:26:22,809 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:26:23,052 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4a9a878]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:26:23,095 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bbc068a85e21f0c5e9136', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:33}] to localhost:27017
2023-04-04 11:26:23,096 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bbc068a85e21f0c5e9136', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=31418941}
2023-04-04 11:26:23,103 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bbc068a85e21f0c5e9136', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:34}] to localhost:27017
2023-04-04 11:26:25,410 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.644 seconds (JVM running for 7.398)
2023-04-04 11:26:25,415 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:26:25,415 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:26:50,744 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:26:51,096 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:35}] to localhost:27017
2023-04-04 11:26:51,363 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.RuntimeException: Error: Role is not found.] with root cause
java.lang.RuntimeException: Error: Role is not found.
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$4(AuthController.java:112)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at com.example.spring.jwt.mongodb.controllers.AuthController.lambda$2(AuthController.java:112)
	at java.base/java.lang.Iterable.forEach(Iterable.java:75)
	at com.example.spring.jwt.mongodb.controllers.AuthController.registerUser(AuthController.java:102)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:28:18,863 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(5)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 11:28:18,865 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(5)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 11:28:18,874 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(5)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:28:18,876 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(5)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bbc068a85e21f0c5e9136', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:28:18,878 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(5)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bbc068a85e21f0c5e9136', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:28:18,880 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(5)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:31:54,652 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 10459 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:31:54,658 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:31:57,654 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:31:57,655 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:31:57,797 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:31:58,053 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@23c767e6]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:31:58,106 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bbd55fb45ee07a062913e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:43}] to localhost:27017
2023-04-04 11:31:58,107 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bbd55fb45ee07a062913e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:42}] to localhost:27017
2023-04-04 11:31:58,107 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bbd55fb45ee07a062913e', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=57608473}
2023-04-04 11:32:00,679 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.723 seconds (JVM running for 8.059)
2023-04-04 11:32:00,691 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:32:00,692 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:32:05,543 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:32:05,913 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:44}] to localhost:27017
2023-04-04 11:34:24,695 INFO com.example.spring.jwt.mongodb.controllers.FileUploadDownloadController [http-nio-8080-exec-5] inside method get directory
2023-04-04 11:34:24,697 INFO com.example.spring.jwt.mongodb.controllers.FileUploadDownloadController [http-nio-8080-exec-5] Getting contents of directory
2023-04-04 11:34:24,698 INFO com.example.spring.jwt.mongodb.controllers.FileUploadDownloadController [http-nio-8080-exec-5] content acquired
2023-04-04 11:34:24,699 INFO com.example.spring.jwt.mongodb.controllers.FileUploadDownloadController [http-nio-8080-exec-5] sorting content into file and directory
2023-04-04 11:34:24,700 INFO com.example.spring.jwt.mongodb.controllers.FileUploadDownloadController [http-nio-8080-exec-5] Sorting success
2023-04-04 11:36:21,142 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-7] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.mail.MailSendException: Failed messages: com.sun.mail.smtp.SMTPSendFailedException: 550 5.4.5 Daily user sending quota exceeded. j7-20020aa783c7000000b006251e1fdd1fsm7860226pfn.200 - gsmtp
; message exceptions (1) are:
Failed message 1: com.sun.mail.smtp.SMTPSendFailedException: 550 5.4.5 Daily user sending quota exceeded. j7-20020aa783c7000000b006251e1fdd1fsm7860226pfn.200 - gsmtp
] with root cause
org.springframework.mail.MailSendException: Failed messages: com.sun.mail.smtp.SMTPSendFailedException: 550 5.4.5 Daily user sending quota exceeded. j7-20020aa783c7000000b006251e1fdd1fsm7860226pfn.200 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.EmailService.sendMail(EmailService.java:39)
	at com.example.spring.jwt.mongodb.controllers.EmailController.sendMail(EmailController.java:35)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:37:58,946 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-9] Servlet.service() for servlet [dispatcherServlet] threw exception
javax.mail.internet.AddressException: Missing ']'
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:984)
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:728)
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:705)
	at org.springframework.mail.javamail.MimeMessageHelper.parseAddress(MimeMessageHelper.java:735)
	at org.springframework.mail.javamail.MimeMessageHelper.setTo(MimeMessageHelper.java:621)
	at org.springframework.mail.javamail.MimeMailMessage.setTo(MimeMailMessage.java:109)
	at org.springframework.mail.SimpleMailMessage.copyTo(SimpleMailMessage.java:204)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:320)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.EmailService.sendMail(EmailService.java:39)
	at com.example.spring.jwt.mongodb.service.EmailService$1.call(EmailService.java:57)
	at com.example.spring.jwt.mongodb.service.EmailService$1.call(EmailService.java:1)
	at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:337)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:37:58,949 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-9] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.mail.MailParseException: Could not parse mail; nested exception is javax.mail.internet.AddressException: Missing ']' in string ``["shitalpatiol1912@gmail.com"'' at position 29] with root cause
javax.mail.internet.AddressException: Missing ']'
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:984)
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:728)
	at javax.mail.internet.InternetAddress.parse(InternetAddress.java:705)
	at org.springframework.mail.javamail.MimeMessageHelper.parseAddress(MimeMessageHelper.java:735)
	at org.springframework.mail.javamail.MimeMessageHelper.setTo(MimeMessageHelper.java:621)
	at org.springframework.mail.javamail.MimeMailMessage.setTo(MimeMailMessage.java:109)
	at org.springframework.mail.SimpleMailMessage.copyTo(SimpleMailMessage.java:204)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:320)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.EmailService.sendMail(EmailService.java:39)
	at com.example.spring.jwt.mongodb.service.EmailService$1.call(EmailService.java:57)
	at com.example.spring.jwt.mongodb.service.EmailService$1.call(EmailService.java:1)
	at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:337)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:46:29,754 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(18)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 11:46:29,757 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(18)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 11:46:29,769 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(18)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:46:29,771 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(18)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bbd55fb45ee07a062913e', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:46:29,773 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(18)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bbd55fb45ee07a062913e', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:46:29,775 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(18)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:46:34,813 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 11100 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:46:34,819 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:46:37,003 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:46:37,004 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:46:37,131 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:46:37,380 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@6048e26a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:46:37,412 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc0c5de282d5d7884a6a7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:48}] to localhost:27017
2023-04-04 11:46:37,412 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc0c5de282d5d7884a6a7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:47}] to localhost:27017
2023-04-04 11:46:37,413 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc0c5de282d5d7884a6a7', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=40003215}
2023-04-04 11:46:40,032 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.912 seconds (JVM running for 7.128)
2023-04-04 11:46:40,037 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:46:40,038 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:47:05,430 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:47:06,610 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 462 ms
2023-04-04 11:47:48,050 INFO org.mongodb.driver.connection [http-nio-8080-exec-10] Opened connection [connectionId{localValue:3, serverValue:49}] to localhost:27017
2023-04-04 11:50:30,105 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(7)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 11:50:30,109 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(7)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 11:50:30,118 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:50:30,120 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bc0c5de282d5d7884a6a7', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:50:30,122 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bc0c5de282d5d7884a6a7', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:50:30,124 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 11:50:37,458 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 11322 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:50:37,466 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:50:40,084 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:50:40,085 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:50:40,237 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:50:40,575 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@ab2e6d2]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:50:40,647 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc1b81ad0f90da35021bb', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:51}] to localhost:27017
2023-04-04 11:50:40,643 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc1b81ad0f90da35021bb', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:50}] to localhost:27017
2023-04-04 11:50:40,650 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc1b81ad0f90da35021bb', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=69678342}
2023-04-04 11:50:43,856 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 7.237 seconds (JVM running for 9.031)
2023-04-04 11:50:43,862 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:50:43,863 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:50:52,740 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:50:53,034 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:52}] to localhost:27017
2023-04-04 11:53:57,163 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 11636 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:53:57,176 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:53:59,665 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:53:59,666 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:53:59,814 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:54:00,080 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@481b2f10]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:54:00,112 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc27f4a6dae58bccc8502', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:54}] to localhost:27017
2023-04-04 11:54:00,112 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc27f4a6dae58bccc8502', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:53}] to localhost:27017
2023-04-04 11:54:00,113 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc27f4a6dae58bccc8502', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=36440045}
2023-04-04 11:54:02,981 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.596 seconds (JVM running for 8.389)
2023-04-04 11:54:02,987 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:54:02,987 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:54:29,521 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:54:29,833 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:55}] to localhost:27017
2023-04-04 11:56:23,588 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 11902 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 11:56:23,599 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 11:56:26,090 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 11:56:26,091 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 11:56:26,264 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 11:56:26,658 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@49cd946c]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 11:56:26,690 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc312b4be9851594b328b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:57}] to localhost:27017
2023-04-04 11:56:26,691 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc312b4be9851594b328b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=41751764}
2023-04-04 11:56:26,692 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc312b4be9851594b328b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:56}] to localhost:27017
2023-04-04 11:56:30,166 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 7.313 seconds (JVM running for 9.214)
2023-04-04 11:56:30,173 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 11:56:30,174 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 11:56:33,898 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 11:56:34,198 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:58}] to localhost:27017
2023-04-04 12:01:42,252 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 12343 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:01:42,257 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:01:44,189 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:01:44,190 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:01:44,329 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:01:44,553 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@61cda923]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:01:44,583 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc450492ea91ed49ed9c3', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:59}] to localhost:27017
2023-04-04 12:01:44,586 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc450492ea91ed49ed9c3', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=35418921}
2023-04-04 12:01:44,585 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc450492ea91ed49ed9c3', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:60}] to localhost:27017
2023-04-04 12:01:47,294 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.664 seconds (JVM running for 7.312)
2023-04-04 12:01:47,299 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:01:47,302 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:01:54,965 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(2)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 12:01:54,977 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(2)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:01:54,983 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(2)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bc450492ea91ed49ed9c3', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:01:54,987 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(2)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bc450492ea91ed49ed9c3', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:01:54,989 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(2)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:02:04,321 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 12481 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:02:04,331 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:02:07,251 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:02:07,253 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:02:07,400 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:02:07,736 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@40bf4386]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:02:07,771 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc4676604d55e58528bc6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:61}] to localhost:27017
2023-04-04 12:02:07,779 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc4676604d55e58528bc6', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:62}] to localhost:27017
2023-04-04 12:02:07,780 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc4676604d55e58528bc6', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=41239672}
2023-04-04 12:02:10,785 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 7.325 seconds (JVM running for 9.216)
2023-04-04 12:02:10,791 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:02:10,792 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:02:14,256 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:02:14,552 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:63}] to localhost:27017
2023-04-04 12:10:19,628 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 12883 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:10:19,637 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:10:22,155 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:10:22,155 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:10:22,298 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:10:22,618 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5348d83c]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:10:22,652 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc656c134093c26f72e09', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:64}] to localhost:27017
2023-04-04 12:10:22,652 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc656c134093c26f72e09', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:65}] to localhost:27017
2023-04-04 12:10:22,654 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc656c134093c26f72e09', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=43999291}
2023-04-04 12:10:25,450 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.691 seconds (JVM running for 8.332)
2023-04-04 12:10:25,455 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:10:25,456 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:10:33,882 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:10:34,175 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:66}] to localhost:27017
2023-04-04 12:12:25,841 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 13110 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:12:25,847 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:12:28,179 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:12:28,180 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:12:28,309 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:12:28,529 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bc6da03]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:12:28,557 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc6d4c1fcf669da1b6cf7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:68}] to localhost:27017
2023-04-04 12:12:28,558 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc6d4c1fcf669da1b6cf7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:67}] to localhost:27017
2023-04-04 12:12:28,559 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc6d4c1fcf669da1b6cf7', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32080481}
2023-04-04 12:12:31,002 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.761 seconds (JVM running for 7.03)
2023-04-04 12:12:31,008 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:12:31,009 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:12:39,410 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:12:39,641 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:69}] to localhost:27017
2023-04-04 12:16:36,319 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(7)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 12:16:36,321 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(7)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 12:16:36,330 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:16:36,331 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642bc6d4c1fcf669da1b6cf7', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:16:36,332 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642bc6d4c1fcf669da1b6cf7', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:16:36,334 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(7)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 12:16:42,072 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 13416 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:16:42,080 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:16:44,632 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:16:44,633 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:16:44,783 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:16:45,137 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@ab2e6d2]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:16:45,171 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc7d5fc4bfa141bf0346f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:70}] to localhost:27017
2023-04-04 12:16:45,171 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc7d5fc4bfa141bf0346f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:71}] to localhost:27017
2023-04-04 12:16:45,172 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc7d5fc4bfa141bf0346f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=46882636}
2023-04-04 12:16:48,006 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.757 seconds (JVM running for 8.365)
2023-04-04 12:16:48,013 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:16:48,014 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:16:57,783 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:16:58,082 INFO org.mongodb.driver.connection [http-nio-8080-exec-2] Opened connection [connectionId{localValue:3, serverValue:72}] to localhost:27017
2023-04-04 12:20:47,326 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-3] JWT token is expired: JWT expired at 2023-04-04T12:17:48Z. Current time: 2023-04-04T12:20:47Z, a difference of 179325 milliseconds.  Allowed clock skew: 0 milliseconds.
2023-04-04 12:20:47,331 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-3] Unauthorized error: Full authentication is required to access this resource
2023-04-04 12:21:38,693 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-4] JWT token is expired: JWT expired at 2023-04-04T12:17:48Z. Current time: 2023-04-04T12:21:38Z, a difference of 230693 milliseconds.  Allowed clock skew: 0 milliseconds.
2023-04-04 12:21:38,695 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-4] Unauthorized error: Full authentication is required to access this resource
2023-04-04 12:22:01,418 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-3] Init duration for springdoc-openapi is: 458 ms
2023-04-04 12:24:41,879 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 14036 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:24:41,891 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:24:45,203 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:24:45,205 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:24:45,450 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:24:45,799 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@49cd946c]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:24:45,847 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bc9b51ad2f0096952a144', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:74}] to localhost:27017
2023-04-04 12:24:45,847 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bc9b51ad2f0096952a144', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:73}] to localhost:27017
2023-04-04 12:24:45,848 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bc9b51ad2f0096952a144', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=47611356}
2023-04-04 12:24:48,987 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 8.135 seconds (JVM running for 9.853)
2023-04-04 12:24:48,993 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:24:48,994 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:24:59,414 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:24:59,739 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:75}] to localhost:27017
2023-04-04 12:25:12,571 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-1] mail send Successfully.
2023-04-04 12:27:14,672 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 14439 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 12:27:14,679 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 12:27:17,253 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 12:27:17,255 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 12:27:17,430 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 12:27:17,794 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5934ca1e]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 12:27:17,838 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642bca4d57d078599e186505', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:77}] to localhost:27017
2023-04-04 12:27:17,839 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642bca4d57d078599e186505', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=52497072}
2023-04-04 12:27:17,842 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642bca4d57d078599e186505', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:76}] to localhost:27017
2023-04-04 12:27:20,613 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.694 seconds (JVM running for 8.231)
2023-04-04 12:27:20,618 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 12:27:20,618 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 12:27:30,654 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 12:27:30,952 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:78}] to localhost:27017
2023-04-04 12:27:37,801 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-1] mail send Successfully.
2023-04-04 16:26:19,313 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 26660 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 16:26:19,354 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 16:26:25,236 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 16:26:25,237 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 16:26:25,442 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 16:26:25,744 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1c8f6c66]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 16:26:25,764 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642c0259a2e25a1f9269615e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:242}] to localhost:27017
2023-04-04 16:26:25,764 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642c0259a2e25a1f9269615e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:243}] to localhost:27017
2023-04-04 16:26:25,765 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642c0259a2e25a1f9269615e', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=27393548}
2023-04-04 16:26:29,856 INFO org.apache.catalina.core.StandardService [main] Stopping service [Tomcat]
2023-04-04 16:26:29,898 WARN org.apache.catalina.loader.WebappClassLoaderBase [main] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 16:26:29,959 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [main] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Web server failed to start. Port 8080 was already in use.

Action:

Identify and stop the process that's listening on port 8080 or configure this application to listen on another port.

2023-04-04 16:26:53,996 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 26807 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 16:26:54,003 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 16:26:55,925 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 16:26:55,926 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 16:26:56,061 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 16:26:56,304 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2ad99cf3]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 16:26:56,340 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642c0278124c6f0bbb23bcdf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:244}] to localhost:27017
2023-04-04 16:26:56,341 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642c0278124c6f0bbb23bcdf', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=58307943}
2023-04-04 16:26:56,352 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642c0278124c6f0bbb23bcdf', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:245}] to localhost:27017
2023-04-04 16:26:58,654 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.246 seconds (JVM running for 6.337)
2023-04-04 16:26:58,660 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 16:26:58,661 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 16:27:37,057 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 16:27:37,096 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-2] Unauthorized error: Full authentication is required to access this resource
2023-04-04 16:27:47,878 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-3] Invalid JWT signature: JWT signature does not match locally computed signature. JWT validity cannot be asserted and should not be trusted.
2023-04-04 16:27:47,879 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-3] Unauthorized error: Full authentication is required to access this resource
2023-04-04 16:28:30,458 INFO org.mongodb.driver.connection [http-nio-8080-exec-4] Opened connection [connectionId{localValue:3, serverValue:246}] to localhost:27017
2023-04-04 16:28:54,369 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shital@gmail.com"
2023-04-04 16:28:58,579 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shital@gmail.com"
2023-04-04 16:28:58,580 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shital@gmail.com"
2023-04-04 16:28:58,678 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "to"
2023-04-04 16:29:01,457 ERROR com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Failed to send mail to: "to"
org.springframework.mail.MailSendException: Failed messages: javax.mail.SendFailedException: Invalid Addresses;
  nested exception is:
	com.sun.mail.smtp.SMTPAddressFailedException: 553-5.1.3 The recipient address <to> is not a valid RFC-5321 address. Learn more
553-5.1.3 at
553 5.1.3  https://support.google.com/mail/answer/6596 q9-20020a170902b10900b00194caf3e975sm8092821plr.208 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.ThreadService.sendMail(ThreadService.java:45)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:60)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:1)
	at com.example.spring.jwt.mongodb.controllers.ThreadController.lambda$0(ThreadController.java:63)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1760)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
2023-04-04 16:29:01,463 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "erwdfsd"
2023-04-04 16:29:04,213 ERROR com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Failed to send mail to: "erwdfsd"
org.springframework.mail.MailSendException: Failed messages: javax.mail.SendFailedException: Invalid Addresses;
  nested exception is:
	com.sun.mail.smtp.SMTPAddressFailedException: 553-5.1.3 The recipient address <erwdfsd> is not a valid RFC-5321 address. Learn
553-5.1.3 more at
553 5.1.3  https://support.google.com/mail/answer/6596 v9-20020a62a509000000b005941ff79428sm8819443pfm.90 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.ThreadService.sendMail(ThreadService.java:45)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:60)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:1)
	at com.example.spring.jwt.mongodb.controllers.ThreadController.lambda$0(ThreadController.java:63)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1760)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
2023-04-04 16:29:04,219 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shitalpatil1912@gmail.com"
2023-04-04 16:29:07,593 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shitalpatil1912@gmail.com"
2023-04-04 16:29:07,594 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shitalpatil1912@gmail.com"
2023-04-04 16:29:07,599 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shitalbhinge29@gmail.com"
2023-04-04 16:29:10,971 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shitalbhinge29@gmail.com"
2023-04-04 16:29:10,972 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shitalbhinge29@gmail.com"
2023-04-04 16:29:37,883 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-7] Retrieving failed mail ids
2023-04-04 16:29:37,892 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-7] Retrieved 2 failed mail ids
2023-04-04 16:29:45,376 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-8] Retrieving successful mail ids
2023-04-04 16:29:45,385 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-8] Retrieved 3 successful mail ids
2023-04-04 16:32:10,017 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(8)-127.0.0.1] Stopping service [Tomcat]
2023-04-04 16:32:10,020 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(8)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-04 16:32:10,030 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 16:32:10,032 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642c0278124c6f0bbb23bcdf', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 16:32:10,033 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642c0278124c6f0bbb23bcdf', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 16:32:10,035 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(8)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-04 16:32:19,554 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 27130 (/home/inferyx/git/SpringApplicationWithSecurity/data/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/data)
2023-04-04 16:32:19,558 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-04 16:32:21,643 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-04 16:32:21,644 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-04 16:32:21,774 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-04 16:32:21,998 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3249e278]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-04 16:32:22,026 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642c03bded9b6b6a6101212f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:247}] to localhost:27017
2023-04-04 16:32:22,026 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642c03bded9b6b6a6101212f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:248}] to localhost:27017
2023-04-04 16:32:22,027 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642c03bded9b6b6a6101212f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=34229179}
2023-04-04 16:32:24,380 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 5.401 seconds (JVM running for 6.649)
2023-04-04 16:32:24,386 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-04 16:32:24,387 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-04 16:32:52,370 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-04 16:32:52,581 INFO org.mongodb.driver.connection [http-nio-8080-exec-2] Opened connection [connectionId{localValue:3, serverValue:249}] to localhost:27017
2023-04-04 16:32:52,691 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shital@gmail.com"
2023-04-04 16:32:56,657 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shital@gmail.com"
2023-04-04 16:32:56,659 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shital@gmail.com"
2023-04-04 16:32:56,705 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "to"
2023-04-04 16:32:59,497 ERROR com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Failed to send mail to: "to"
org.springframework.mail.MailSendException: Failed messages: javax.mail.SendFailedException: Invalid Addresses;
  nested exception is:
	com.sun.mail.smtp.SMTPAddressFailedException: 553-5.1.3 The recipient address <to> is not a valid RFC-5321 address. Learn more
553-5.1.3 at
553 5.1.3  https://support.google.com/mail/answer/6596 r26-20020a62e41a000000b006281273f1f5sm8563530pfh.8 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.ThreadService.sendMail(ThreadService.java:45)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:60)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:1)
	at com.example.spring.jwt.mongodb.controllers.ThreadController.lambda$0(ThreadController.java:63)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1760)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
2023-04-04 16:32:59,502 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "erwdfsd"
2023-04-04 16:33:02,239 ERROR com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Failed to send mail to: "erwdfsd"
org.springframework.mail.MailSendException: Failed messages: javax.mail.SendFailedException: Invalid Addresses;
  nested exception is:
	com.sun.mail.smtp.SMTPAddressFailedException: 553-5.1.3 The recipient address <erwdfsd> is not a valid RFC-5321 address. Learn
553-5.1.3 more at
553 5.1.3  https://support.google.com/mail/answer/6596 t12-20020a170902bc4c00b001a1d4a985eesm8046459plz.228 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.ThreadService.sendMail(ThreadService.java:45)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:60)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:1)
	at com.example.spring.jwt.mongodb.controllers.ThreadController.lambda$0(ThreadController.java:63)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1760)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
2023-04-04 16:33:02,245 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shitalpatil1912@gmail.com"
2023-04-04 16:33:05,693 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shitalpatil1912@gmail.com"
2023-04-04 16:33:05,694 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shitalpatil1912@gmail.com"
2023-04-04 16:33:05,698 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shitalbhinge29@gmail.com"
2023-04-04 16:33:09,209 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to "shitalbhinge29@gmail.com"
2023-04-04 16:33:09,209 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: "shitalbhinge29@gmail.com"
2023-04-04 16:34:44,464 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-6] Retrieving failed mail ids
2023-04-04 16:34:44,472 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-6] Retrieved 2 failed mail ids
2023-04-04 16:34:47,948 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-7] Retrieving successful mail ids
2023-04-04 16:34:47,953 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-7] Retrieved 3 successful mail ids
2023-04-07 16:16:36,712 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 7691 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:16:36,718 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:16:39,299 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 16:16:39,300 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 16:16:39,426 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 16:16:39,806 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3ba1308d]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:16:39,860 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff48ffcff5c16d03b65ea', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:3}] to localhost:27017
2023-04-07 16:16:39,861 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff48ffcff5c16d03b65ea', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=38974986}
2023-04-07 16:16:39,864 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff48ffcff5c16d03b65ea', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
2023-04-07 16:16:42,456 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 6.333 seconds (JVM running for 7.673)
2023-04-07 16:16:42,462 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-07 16:16:42,463 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-07 16:16:56,257 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-07 16:16:58,024 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-8] Init duration for springdoc-openapi is: 531 ms
2023-04-07 16:23:22,073 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(15)-127.0.0.1] Stopping service [Tomcat]
2023-04-07 16:23:22,077 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(15)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-07 16:23:22,087 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(15)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:23:22,088 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(15)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642ff48ffcff5c16d03b65ea', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:23:22,090 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(15)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642ff48ffcff5c16d03b65ea', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:23:22,092 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(15)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:23:38,838 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 8251 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:23:38,845 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:23:40,884 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 16:23:40,885 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 16:23:41,068 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 16:23:41,300 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5c4cc644]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:23:41,326 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff635ac10e47a3183bd60', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:5}] to localhost:27017
2023-04-07 16:23:41,328 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff635ac10e47a3183bd60', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32232273}
2023-04-07 16:23:41,337 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff635ac10e47a3183bd60', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:6}] to localhost:27017
2023-04-07 16:23:42,519 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:23:42,522 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:23:42,683 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:23:43,100 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:23:43,444 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:23:43,522 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:23:43,524 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:23:43,526 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:23:43,527 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:23:43,529 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:23:43,983 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 46769.
2023-04-07 16:23:44,017 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:23:44,051 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:23:44,057 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:23:44,059 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:23:44,073 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-7aca27ec-b353-43ee-b713-263b7487c8f2
2023-04-07 16:23:44,114 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:23:44,142 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:23:44,267 INFO org.spark_project.jetty.util.log [main] Logging initialized @7542ms
2023-04-07 16:23:44,334 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:23:44,361 INFO org.spark_project.jetty.server.Server [main] Started @7638ms
2023-04-07 16:23:44,395 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@63551c66{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:23:44,396 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 16:23:44,429 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@339cde4b{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,432 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5b80b41d{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,434 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@54ef9698{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,440 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@197180a5{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,442 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@31028e45{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,444 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@68f75a35{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,445 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@50e0b472{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,449 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@29eaf100{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,450 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c1a6db1{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,452 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5dac6bc3{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,454 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@a6204e4{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,456 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@747e8659{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,457 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4b360a82{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,459 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@75fa9254{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,461 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f25ed2b{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,463 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f69e2d8{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,465 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@147097ad{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,467 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3539cf45{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,469 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7535307c{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,470 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@556a6320{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,490 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@45375bdf{/static,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,493 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@46d51d5e{/,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,499 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@530df3ab{/api,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,501 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58d79479{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,504 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@102c24d1{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:23:44,507 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 16:23:44,641 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:23:44,674 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45727.
2023-04-07 16:23:44,675 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:45727
2023-04-07 16:23:44,677 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:23:44,716 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 45727, None)
2023-04-07 16:23:44,721 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:45727 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 45727, None)
2023-04-07 16:23:44,729 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 45727, None)
2023-04-07 16:23:44,731 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 45727, None)
2023-04-07 16:23:44,753 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@346e5cc{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:23:48,789 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 10.67 seconds (JVM running for 12.065)
2023-04-07 16:23:48,794 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-07 16:23:48,794 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-07 16:24:31,346 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-2] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-07 16:24:31,506 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-2] Unauthorized error: Full authentication is required to access this resource
2023-04-07 16:25:47,868 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-5] Unauthorized error: Full authentication is required to access this resource
2023-04-07 16:25:58,026 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-6] JWT token is expired: JWT expired at 2023-04-04T16:58:30Z. Current time: 2023-04-07T16:25:58Z, a difference of 257248025 milliseconds.  Allowed clock skew: 0 milliseconds.
2023-04-07 16:25:58,027 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-6] Unauthorized error: Full authentication is required to access this resource
2023-04-07 16:26:19,770 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-5] Init duration for springdoc-openapi is: 635 ms
2023-04-07 16:26:59,383 INFO org.mongodb.driver.connection [http-nio-8080-exec-6] Opened connection [connectionId{localValue:3, serverValue:7}] to localhost:27017
2023-04-07 16:27:22,715 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-4] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/inferyx/git/SpringApplicationWithSecurity/Spring/spark-warehouse').
2023-04-07 16:27:22,717 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-4] Warehouse path is 'file:/home/inferyx/git/SpringApplicationWithSecurity/Spring/spark-warehouse'.
2023-04-07 16:27:22,734 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-4] Started o.s.j.s.ServletContextHandler@8ead17c{/SQL,null,AVAILABLE,@Spark}
2023-04-07 16:27:22,736 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-4] Started o.s.j.s.ServletContextHandler@4cec1b7e{/SQL/json,null,AVAILABLE,@Spark}
2023-04-07 16:27:22,737 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-4] Started o.s.j.s.ServletContextHandler@10218ca0{/SQL/execution,null,AVAILABLE,@Spark}
2023-04-07 16:27:22,739 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-4] Started o.s.j.s.ServletContextHandler@33312e93{/SQL/execution/json,null,AVAILABLE,@Spark}
2023-04-07 16:27:22,742 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-4] Started o.s.j.s.ServletContextHandler@155e38d7{/static/sql,null,AVAILABLE,@Spark}
2023-04-07 16:27:23,491 INFO org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef [http-nio-8080-exec-4] Registered StateStoreCoordinator endpoint
2023-04-07 16:27:24,034 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-4] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @21d03963] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @21d03963
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:29:32,199 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 8703 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:29:32,266 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:29:39,491 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 16:29:39,516 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 16:29:39,832 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 16:29:40,161 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@76cdafa3]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:29:40,202 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff79c28aed86754b5389f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:8}] to localhost:27017
2023-04-07 16:29:40,203 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff79c28aed86754b5389f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=44651281}
2023-04-07 16:29:40,227 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff79c28aed86754b5389f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:9}] to localhost:27017
2023-04-07 16:29:43,148 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:29:43,150 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:29:43,514 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:29:44,175 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:29:44,756 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:29:45,135 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:29:45,136 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:29:45,140 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:29:45,142 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:29:45,143 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:29:46,101 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 45127.
2023-04-07 16:29:46,289 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:29:46,424 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:29:46,438 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:29:46,439 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:29:46,614 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-1b0988bf-3fff-4a42-9cd6-f017a00c4a83
2023-04-07 16:29:46,718 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:29:46,799 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:29:47,058 INFO org.spark_project.jetty.util.log [main] Logging initialized @18557ms
2023-04-07 16:29:47,260 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:29:47,283 INFO org.spark_project.jetty.server.Server [main] Started @18789ms
2023-04-07 16:29:47,313 WARN org.apache.spark.util.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2023-04-07 16:29:47,319 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@478fe415{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:29:47,320 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4041.
2023-04-07 16:29:47,358 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@495f7ca4{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,361 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2648aa1b{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,363 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a3333be{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,366 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2c2edbe7{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,367 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7f53a31f{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,368 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4ba1f425{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,369 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@29d563bd{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,371 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5703c1fb{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,373 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d2be319{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,374 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@35d3202b{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,375 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2dfd157b{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,377 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@64381526{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,378 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@46290193{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,380 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6ad7a305{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,381 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2fc435e9{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,383 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@bf18412{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,385 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5da2966{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,388 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52c27d53{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,390 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5ca7619f{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,392 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5b71af0d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,401 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@fb42c1c{/static,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,403 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1e7113f8{/,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,404 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3e149513{/api,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,405 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@af94b0b{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,407 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@208185c0{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:29:47,429 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4041
2023-04-07 16:29:47,824 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:29:47,898 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42107.
2023-04-07 16:29:47,899 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:42107
2023-04-07 16:29:47,902 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:29:47,975 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 42107, None)
2023-04-07 16:29:47,982 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:42107 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 42107, None)
2023-04-07 16:29:48,021 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 42107, None)
2023-04-07 16:29:48,022 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 42107, None)
2023-04-07 16:29:48,097 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3b590f6a{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:29:55,457 INFO org.spark_project.jetty.server.AbstractConnector [main] Stopped Spark@478fe415{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:29:55,459 INFO org.apache.spark.ui.SparkUI [main] Stopped Spark web UI at http://192.168.1.125:4041
2023-04-07 16:29:55,525 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:29:55,575 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore cleared
2023-04-07 16:29:55,646 INFO org.apache.spark.storage.BlockManager [main] BlockManager stopped
2023-04-07 16:29:55,684 INFO org.apache.spark.storage.BlockManagerMaster [main] BlockManagerMaster stopped
2023-04-07 16:29:55,706 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-07 16:29:55,712 INFO org.apache.spark.SparkContext [main] Successfully stopped SparkContext
2023-04-07 16:29:55,713 INFO org.apache.spark.SparkContext [main] SparkContext already stopped.
2023-04-07 16:29:55,736 INFO org.apache.catalina.core.StandardService [main] Stopping service [Tomcat]
2023-04-07 16:29:55,895 WARN org.apache.catalina.loader.WebappClassLoaderBase [main] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:29:55,969 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [main] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Web server failed to start. Port 8080 was already in use.

Action:

Identify and stop the process that's listening on port 8080 or configure this application to listen on another port.

2023-04-07 16:30:07,420 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-7] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @21d03963] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @21d03963
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:34,558 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(14)-127.0.0.1] Stopping service [Tomcat]
2023-04-07 16:30:34,561 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(14)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-07 16:30:34,604 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:34,606 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642ff635ac10e47a3183bd60', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:34,606 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642ff635ac10e47a3183bd60', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:34,607 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:34,614 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [spark-listener-group-streams] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3463)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3434)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1623)
 java.base@17.0.6/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:97)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
 app//org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
 app//org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1302)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
2023-04-07 16:30:34,615 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(14)-127.0.0.1] The web application [ROOT] appears to have started a thread named [org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Object.wait(Native Method)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
 app//org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:2989)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:30:35,712 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 16:30:35,713 INFO org.apache.spark.SparkContext [Thread-2] SparkContext already stopped.
2023-04-07 16:30:35,738 INFO org.apache.spark.storage.DiskBlockManager [Thread-2] Shutdown hook called
2023-04-07 16:30:35,741 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(14)-127.0.0.1] Stopped Spark@63551c66{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:30:35,746 INFO org.apache.spark.ui.SparkUI [RMI TCP Connection(14)-127.0.0.1] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 16:30:35,767 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Shutdown hook called
2023-04-07 16:30:35,769 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-5c5dfcc3-6e77-4e91-a3ba-15a6c16c86cc
2023-04-07 16:30:35,773 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-5c5dfcc3-6e77-4e91-a3ba-15a6c16c86cc/userFiles-1175bde9-c1f8-4cf6-b697-16cb05a15f3a
2023-04-07 16:30:35,811 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:30:35,923 INFO org.apache.spark.storage.memory.MemoryStore [RMI TCP Connection(14)-127.0.0.1] MemoryStore cleared
2023-04-07 16:30:35,925 INFO org.apache.spark.storage.BlockManager [RMI TCP Connection(14)-127.0.0.1] BlockManager stopped
2023-04-07 16:30:35,936 INFO org.apache.spark.storage.BlockManagerMaster [RMI TCP Connection(14)-127.0.0.1] BlockManagerMaster stopped
2023-04-07 16:30:35,941 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-07 16:30:35,983 INFO org.apache.spark.SparkContext [RMI TCP Connection(14)-127.0.0.1] Successfully stopped SparkContext
2023-04-07 16:30:35,983 INFO org.apache.spark.SparkContext [RMI TCP Connection(14)-127.0.0.1] SparkContext already stopped.
2023-04-07 16:30:43,535 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 8958 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:30:43,540 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:30:45,900 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 16:30:45,900 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 16:30:46,089 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 16:30:46,349 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@21f7e537]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:30:46,403 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff7dea3386059e913bfa0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:11}] to localhost:27017
2023-04-07 16:30:46,403 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff7dea3386059e913bfa0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:10}] to localhost:27017
2023-04-07 16:30:46,404 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff7dea3386059e913bfa0', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=56906283}
2023-04-07 16:30:47,732 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:30:47,734 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:30:47,808 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:30:48,126 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:30:48,327 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:30:48,404 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:30:48,406 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:30:48,407 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:30:48,409 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:30:48,411 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:30:48,863 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 39959.
2023-04-07 16:30:48,898 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:30:48,924 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:30:48,930 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:30:48,931 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:30:48,945 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-10c4c245-bc0f-48b0-a873-6074b9cd6756
2023-04-07 16:30:48,991 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:30:49,016 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:30:49,145 INFO org.spark_project.jetty.util.log [main] Logging initialized @7904ms
2023-04-07 16:30:49,215 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:30:49,236 INFO org.spark_project.jetty.server.Server [main] Started @7997ms
2023-04-07 16:30:49,263 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@411933{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:30:49,265 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 16:30:49,295 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@744db9fb{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,297 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3794b7b1{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,299 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3225d950{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,300 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@55315a00{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,302 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4942e6af{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,303 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73a1a1b4{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,304 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@669daa93{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,306 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3370be55{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,307 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3d2b13f{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,308 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58c36104{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,309 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1fc8047f{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,310 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@29fc83c5{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,311 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3fb1948c{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,313 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7c39193f{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,314 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@230d013b{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,315 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6e225c34{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,317 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5d84b088{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,325 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@69c0bae6{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,327 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@220f6a3c{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,330 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5eb041b5{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,340 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2648aa1b{/static,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,342 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@fb42c1c{/,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,343 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4edde05c{/api,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,345 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@70cac22a{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,346 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@57a0c261{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:30:49,349 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 16:30:49,481 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:30:49,526 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46645.
2023-04-07 16:30:49,529 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:46645
2023-04-07 16:30:49,532 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:30:49,579 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 46645, None)
2023-04-07 16:30:49,585 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:46645 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 46645, None)
2023-04-07 16:30:49,595 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 46645, None)
2023-04-07 16:30:49,596 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 46645, None)
2023-04-07 16:30:49,615 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@737445ab{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:30:52,663 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 9.903 seconds (JVM running for 11.424)
2023-04-07 16:30:52,669 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-07 16:30:52,669 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-07 16:31:31,323 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-07 16:31:32,101 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:12}] to localhost:27017
2023-04-07 16:31:32,546 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/inferyx/git/SpringApplicationWithSecurity/Spring/spark-warehouse').
2023-04-07 16:31:32,557 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Warehouse path is 'file:/home/inferyx/git/SpringApplicationWithSecurity/Spring/spark-warehouse'.
2023-04-07 16:31:32,615 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@6a7d1063{/SQL,null,AVAILABLE,@Spark}
2023-04-07 16:31:32,616 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@616a2b3e{/SQL/json,null,AVAILABLE,@Spark}
2023-04-07 16:31:32,617 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@a8dbb47{/SQL/execution,null,AVAILABLE,@Spark}
2023-04-07 16:31:32,619 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@79a9d860{/SQL/execution/json,null,AVAILABLE,@Spark}
2023-04-07 16:31:32,630 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@f0d5e94{/static/sql,null,AVAILABLE,@Spark}
2023-04-07 16:31:34,385 INFO org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef [http-nio-8080-exec-1] Registered StateStoreCoordinator endpoint
2023-04-07 16:31:34,764 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 68 ms to list leaf files for 1 paths.
2023-04-07 16:31:35,198 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 2 ms to list leaf files for 1 paths.
2023-04-07 16:31:40,008 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:40,016 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#0, None)) > 0)
2023-04-07 16:31:40,025 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:40,059 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:40,845 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 279.995925 ms
2023-04-07 16:31:41,464 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 35.671328 ms
2023-04-07 16:31:41,658 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_0 stored as values in memory (estimated size 112.8 KB, free 998.3 MB)
2023-04-07 16:31:41,805 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.3 MB)
2023-04-07 16:31:41,810 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_0_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:41,833 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 0 from csv at SparkController.java:55
2023-04-07 16:31:41,893 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:42,218 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:55
2023-04-07 16:31:42,260 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 0 (csv at SparkController.java:55) with 1 output partitions
2023-04-07 16:31:42,262 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 0 (csv at SparkController.java:55)
2023-04-07 16:31:42,263 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:42,265 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:42,272 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at SparkController.java:55), which has no missing parents
2023-04-07 16:31:42,404 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 998.3 MB)
2023-04-07 16:31:42,407 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 998.3 MB)
2023-04-07 16:31:42,409 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_1_piece0 in memory on 192.168.1.125:46645 (size: 4.6 KB, free: 998.4 MB)
2023-04-07 16:31:42,411 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 1 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:42,447 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at SparkController.java:55) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:42,449 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 0.0 with 1 tasks
2023-04-07 16:31:42,533 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-07 16:31:42,551 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 0] Running task 0.0 in stage 0.0 (TID 0)
2023-04-07 16:31:42,718 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 0] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-07 16:31:42,754 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 0] Code generated in 24.360752 ms
2023-04-07 16:31:42,911 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 0] Finished task 0.0 in stage 0.0 (TID 0). 1307 bytes result sent to driver
2023-04-07 16:31:42,923 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 0.0 (TID 0) in 401 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:42,931 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 0.0, whose tasks have all completed, from pool 
2023-04-07 16:31:42,940 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 0 (csv at SparkController.java:55) finished in 0.614 s
2023-04-07 16:31:42,951 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 0 finished: csv at SparkController.java:55, took 0.732198 s
2023-04-07 16:31:43,132 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:43,133 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:43,134 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:43,135 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:43,161 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 13.49089 ms
2023-04-07 16:31:43,208 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_2 stored as values in memory (estimated size 112.8 KB, free 998.1 MB)
2023-04-07 16:31:43,248 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.1 MB)
2023-04-07 16:31:43,258 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_2_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:43,260 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 2 from csv at SparkController.java:55
2023-04-07 16:31:43,261 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:43,401 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:55
2023-04-07 16:31:43,405 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 1 (csv at SparkController.java:55) with 1 output partitions
2023-04-07 16:31:43,406 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 1 (csv at SparkController.java:55)
2023-04-07 16:31:43,406 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:43,407 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:43,412 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at SparkController.java:55), which has no missing parents
2023-04-07 16:31:43,420 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 998.1 MB)
2023-04-07 16:31:43,424 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 998.1 MB)
2023-04-07 16:31:43,426 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_3_piece0 in memory on 192.168.1.125:46645 (size: 7.6 KB, free: 998.3 MB)
2023-04-07 16:31:43,428 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 3 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:43,430 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at SparkController.java:55) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:43,430 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 1.0 with 1 tasks
2023-04-07 16:31:43,431 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-07 16:31:43,432 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 1] Running task 0.0 in stage 1.0 (TID 1)
2023-04-07 16:31:43,462 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 1] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-07 16:31:43,531 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 1] Finished task 0.0 in stage 1.0 (TID 1). 1493 bytes result sent to driver
2023-04-07 16:31:43,533 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 1.0 (TID 1) in 102 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:43,534 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 1.0, whose tasks have all completed, from pool 
2023-04-07 16:31:43,541 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 1 (csv at SparkController.java:55) finished in 0.126 s
2023-04-07 16:31:43,546 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 1 finished: csv at SparkController.java:55, took 0.143741 s
2023-04-07 16:31:43,649 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:43,650 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:43,651 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:43,651 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:43,747 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 46.882235 ms
2023-04-07 16:31:43,801 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_4 stored as values in memory (estimated size 112.8 KB, free 998.0 MB)
2023-04-07 16:31:43,817 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.0 MB)
2023-04-07 16:31:43,818 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_4_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:43,822 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 4 from show at SparkController.java:58
2023-04-07 16:31:43,825 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:43,884 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:58
2023-04-07 16:31:43,889 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 2 (show at SparkController.java:58) with 1 output partitions
2023-04-07 16:31:43,890 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 2 (show at SparkController.java:58)
2023-04-07 16:31:43,890 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:43,890 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:43,891 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 2 (MapPartitionsRDD[13] at show at SparkController.java:58), which has no missing parents
2023-04-07 16:31:43,899 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_5 stored as values in memory (estimated size 10.4 KB, free 998.0 MB)
2023-04-07 16:31:43,902 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 998.0 MB)
2023-04-07 16:31:43,905 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_5_piece0 in memory on 192.168.1.125:46645 (size: 5.7 KB, free: 998.3 MB)
2023-04-07 16:31:43,907 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 5 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:43,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at show at SparkController.java:58) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:43,910 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 2.0 with 1 tasks
2023-04-07 16:31:43,912 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-07 16:31:43,913 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 2] Running task 0.0 in stage 2.0 (TID 2)
2023-04-07 16:31:43,925 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 2] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-07 16:31:43,961 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 2] Code generated in 30.4963 ms
2023-04-07 16:31:44,050 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 2] Finished task 0.0 in stage 2.0 (TID 2). 1677 bytes result sent to driver
2023-04-07 16:31:44,054 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 2.0 (TID 2) in 143 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:44,055 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 2.0, whose tasks have all completed, from pool 
2023-04-07 16:31:44,057 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 2 (show at SparkController.java:58) finished in 0.162 s
2023-04-07 16:31:44,060 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 2 finished: show at SparkController.java:58, took 0.174358 s
2023-04-07 16:31:44,096 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Csv File
2023-04-07 16:31:44,217 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 2 ms to list leaf files for 1 paths.
2023-04-07 16:31:44,319 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-07 16:31:44,430 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:44,431 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#53, None)) > 0)
2023-04-07 16:31:44,432 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:44,432 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:44,500 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_6 stored as values in memory (estimated size 112.9 KB, free 997.8 MB)
2023-04-07 16:31:44,516 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.8 MB)
2023-04-07 16:31:44,518 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_6_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:44,520 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 6 from csv at SparkController.java:66
2023-04-07 16:31:44,521 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:44,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 33
2023-04-07 16:31:44,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 6
2023-04-07 16:31:44,639 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_0_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:44,650 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 90
2023-04-07 16:31:44,650 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 61
2023-04-07 16:31:44,655 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 12
2023-04-07 16:31:44,655 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 27
2023-04-07 16:31:44,655 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 40
2023-04-07 16:31:44,655 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 5
2023-04-07 16:31:44,656 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 24
2023-04-07 16:31:44,657 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 81
2023-04-07 16:31:44,658 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 85
2023-04-07 16:31:44,658 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 83
2023-04-07 16:31:44,659 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 3
2023-04-07 16:31:44,659 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 21
2023-04-07 16:31:44,660 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 2
2023-04-07 16:31:44,660 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 74
2023-04-07 16:31:44,661 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 46
2023-04-07 16:31:44,662 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 4
2023-04-07 16:31:44,662 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 0
2023-04-07 16:31:44,663 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 64
2023-04-07 16:31:44,663 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 68
2023-04-07 16:31:44,663 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 62
2023-04-07 16:31:44,663 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 18
2023-04-07 16:31:44,664 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 32
2023-04-07 16:31:44,664 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 66
2023-04-07 16:31:44,664 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 79
2023-04-07 16:31:44,664 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 16
2023-04-07 16:31:44,665 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 19
2023-04-07 16:31:44,665 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 23
2023-04-07 16:31:44,665 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 17
2023-04-07 16:31:44,666 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 25
2023-04-07 16:31:44,666 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 14
2023-04-07 16:31:44,667 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 52
2023-04-07 16:31:44,667 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 51
2023-04-07 16:31:44,677 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:66
2023-04-07 16:31:44,679 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_4_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:44,679 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 3 (csv at SparkController.java:66) with 1 output partitions
2023-04-07 16:31:44,679 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 3 (csv at SparkController.java:66)
2023-04-07 16:31:44,680 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:44,680 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:44,681 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 3 (MapPartitionsRDD[17] at csv at SparkController.java:66), which has no missing parents
2023-04-07 16:31:44,684 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 998.1 MB)
2023-04-07 16:31:44,692 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 998.1 MB)
2023-04-07 16:31:44,692 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 15
2023-04-07 16:31:44,693 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 78
2023-04-07 16:31:44,693 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 69
2023-04-07 16:31:44,693 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 65
2023-04-07 16:31:44,693 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 9
2023-04-07 16:31:44,694 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 13
2023-04-07 16:31:44,694 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 31
2023-04-07 16:31:44,694 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 7
2023-04-07 16:31:44,694 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 49
2023-04-07 16:31:44,694 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 75
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 76
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 59
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 38
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 63
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 39
2023-04-07 16:31:44,695 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 44
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 34
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 87
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 45
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 73
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 8
2023-04-07 16:31:44,696 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 41
2023-04-07 16:31:44,697 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 11
2023-04-07 16:31:44,697 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 82
2023-04-07 16:31:44,697 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 72
2023-04-07 16:31:44,698 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_7_piece0 in memory on 192.168.1.125:46645 (size: 4.6 KB, free: 998.3 MB)
2023-04-07 16:31:44,698 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 77
2023-04-07 16:31:44,699 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 57
2023-04-07 16:31:44,699 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 58
2023-04-07 16:31:44,699 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 50
2023-04-07 16:31:44,700 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 26
2023-04-07 16:31:44,700 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 1
2023-04-07 16:31:44,700 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 36
2023-04-07 16:31:44,700 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 47
2023-04-07 16:31:44,700 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 35
2023-04-07 16:31:44,701 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 30
2023-04-07 16:31:44,701 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 56
2023-04-07 16:31:44,701 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 84
2023-04-07 16:31:44,706 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 7 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:44,708 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at csv at SparkController.java:66) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:44,710 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 3.0 with 1 tasks
2023-04-07 16:31:44,713 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-07 16:31:44,714 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 3] Running task 0.0 in stage 3.0 (TID 3)
2023-04-07 16:31:44,716 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_5_piece0 on 192.168.1.125:46645 in memory (size: 5.7 KB, free: 998.3 MB)
2023-04-07 16:31:44,719 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 3] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-07 16:31:44,727 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 22
2023-04-07 16:31:44,727 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 54
2023-04-07 16:31:44,727 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 67
2023-04-07 16:31:44,727 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 37
2023-04-07 16:31:44,727 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 48
2023-04-07 16:31:44,728 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 70
2023-04-07 16:31:44,728 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 43
2023-04-07 16:31:44,728 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 20
2023-04-07 16:31:44,731 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_1_piece0 on 192.168.1.125:46645 in memory (size: 4.6 KB, free: 998.3 MB)
2023-04-07 16:31:44,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 29
2023-04-07 16:31:44,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 60
2023-04-07 16:31:44,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 71
2023-04-07 16:31:44,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 88
2023-04-07 16:31:44,735 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 42
2023-04-07 16:31:44,735 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 53
2023-04-07 16:31:44,739 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_2_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:44,743 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 3] Finished task 0.0 in stage 3.0 (TID 3). 1315 bytes result sent to driver
2023-04-07 16:31:44,749 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_3_piece0 on 192.168.1.125:46645 in memory (size: 7.6 KB, free: 998.4 MB)
2023-04-07 16:31:44,750 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 3.0 (TID 3) in 38 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:44,750 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 3.0, whose tasks have all completed, from pool 
2023-04-07 16:31:44,751 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 3 (csv at SparkController.java:66) finished in 0.069 s
2023-04-07 16:31:44,753 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 3 finished: csv at SparkController.java:66, took 0.074608 s
2023-04-07 16:31:44,754 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 89
2023-04-07 16:31:44,755 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 28
2023-04-07 16:31:44,755 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 10
2023-04-07 16:31:44,755 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 86
2023-04-07 16:31:44,755 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 80
2023-04-07 16:31:44,755 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 55
2023-04-07 16:31:44,792 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:44,792 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:44,793 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:44,793 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:44,845 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_8 stored as values in memory (estimated size 112.9 KB, free 998.1 MB)
2023-04-07 16:31:44,860 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.1 MB)
2023-04-07 16:31:44,862 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_8_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:44,864 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 8 from csv at SparkController.java:66
2023-04-07 16:31:44,865 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:44,907 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:66
2023-04-07 16:31:44,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 4 (csv at SparkController.java:66) with 1 output partitions
2023-04-07 16:31:44,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 4 (csv at SparkController.java:66)
2023-04-07 16:31:44,910 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:44,911 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:44,913 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 4 (MapPartitionsRDD[23] at csv at SparkController.java:66), which has no missing parents
2023-04-07 16:31:44,918 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_9 stored as values in memory (estimated size 13.9 KB, free 998.1 MB)
2023-04-07 16:31:44,922 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.6 KB, free 998.1 MB)
2023-04-07 16:31:44,924 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_9_piece0 in memory on 192.168.1.125:46645 (size: 7.6 KB, free: 998.3 MB)
2023-04-07 16:31:44,926 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 9 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:44,927 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at csv at SparkController.java:66) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:44,928 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 4.0 with 1 tasks
2023-04-07 16:31:44,930 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-07 16:31:44,931 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 4] Running task 0.0 in stage 4.0 (TID 4)
2023-04-07 16:31:44,942 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 4] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-07 16:31:44,955 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 4] Finished task 0.0 in stage 4.0 (TID 4). 1586 bytes result sent to driver
2023-04-07 16:31:44,959 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 4.0 (TID 4) in 30 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:44,959 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 4.0, whose tasks have all completed, from pool 
2023-04-07 16:31:44,960 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 4 (csv at SparkController.java:66) finished in 0.044 s
2023-04-07 16:31:44,961 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 4 finished: csv at SparkController.java:66, took 0.053083 s
2023-04-07 16:31:45,038 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:45,039 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:45,040 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:45,041 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:45,214 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 32.512198 ms
2023-04-07 16:31:45,260 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_10 stored as values in memory (estimated size 112.9 KB, free 998.0 MB)
2023-04-07 16:31:45,278 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.0 MB)
2023-04-07 16:31:45,279 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_10_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:45,280 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 10 from show at SparkController.java:69
2023-04-07 16:31:45,281 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:45,332 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:69
2023-04-07 16:31:45,333 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 5 (show at SparkController.java:69) with 1 output partitions
2023-04-07 16:31:45,333 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 5 (show at SparkController.java:69)
2023-04-07 16:31:45,334 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:45,334 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:45,335 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 5 (MapPartitionsRDD[27] at show at SparkController.java:69), which has no missing parents
2023-04-07 16:31:45,339 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_11 stored as values in memory (estimated size 12.6 KB, free 998.0 MB)
2023-04-07 16:31:45,344 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.3 KB, free 998.0 MB)
2023-04-07 16:31:45,345 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_11_piece0 in memory on 192.168.1.125:46645 (size: 6.3 KB, free: 998.3 MB)
2023-04-07 16:31:45,346 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 11 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:45,347 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at show at SparkController.java:69) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:45,347 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 5.0 with 1 tasks
2023-04-07 16:31:45,348 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-07 16:31:45,349 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 5] Running task 0.0 in stage 5.0 (TID 5)
2023-04-07 16:31:45,356 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 5] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-07 16:31:45,383 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 5] Code generated in 21.226484 ms
2023-04-07 16:31:45,399 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 5] Finished task 0.0 in stage 5.0 (TID 5). 1695 bytes result sent to driver
2023-04-07 16:31:45,401 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 5.0 (TID 5) in 53 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:45,401 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 5.0, whose tasks have all completed, from pool 
2023-04-07 16:31:45,405 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 5 (show at SparkController.java:69) finished in 0.067 s
2023-04-07 16:31:45,410 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 5 finished: show at SparkController.java:69, took 0.077439 s
2023-04-07 16:31:45,413 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Psv File
2023-04-07 16:31:45,530 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-07 16:31:45,636 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 2 ms to list leaf files for 1 paths.
2023-04-07 16:31:45,830 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:45,831 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#106, None)) > 0)
2023-04-07 16:31:45,832 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:45,832 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:45,881 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_12 stored as values in memory (estimated size 112.9 KB, free 997.8 MB)
2023-04-07 16:31:45,894 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.8 MB)
2023-04-07 16:31:45,895 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_12_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:45,896 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 12 from csv at SparkController.java:76
2023-04-07 16:31:45,897 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:45,961 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:76
2023-04-07 16:31:45,962 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 6 (csv at SparkController.java:76) with 1 output partitions
2023-04-07 16:31:45,963 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 6 (csv at SparkController.java:76)
2023-04-07 16:31:45,963 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:45,963 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:45,964 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 6 (MapPartitionsRDD[31] at csv at SparkController.java:76), which has no missing parents
2023-04-07 16:31:45,970 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_13 stored as values in memory (estimated size 8.9 KB, free 997.8 MB)
2023-04-07 16:31:45,974 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KB, free 997.8 MB)
2023-04-07 16:31:45,978 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_13_piece0 in memory on 192.168.1.125:46645 (size: 4.6 KB, free: 998.3 MB)
2023-04-07 16:31:45,983 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 13 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:45,985 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at csv at SparkController.java:76) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:45,986 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 6.0 with 1 tasks
2023-04-07 16:31:45,993 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-07 16:31:45,994 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 6] Running task 0.0 in stage 6.0 (TID 6)
2023-04-07 16:31:45,999 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 6] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-07 16:31:46,034 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 6] Finished task 0.0 in stage 6.0 (TID 6). 1325 bytes result sent to driver
2023-04-07 16:31:46,035 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 6.0 (TID 6) in 43 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:46,036 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 6.0, whose tasks have all completed, from pool 
2023-04-07 16:31:46,039 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 6 (csv at SparkController.java:76) finished in 0.074 s
2023-04-07 16:31:46,040 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 6 finished: csv at SparkController.java:76, took 0.078360 s
2023-04-07 16:31:46,076 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:46,077 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:46,077 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-07 16:31:46,077 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:46,120 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_14 stored as values in memory (estimated size 112.9 KB, free 997.7 MB)
2023-04-07 16:31:46,135 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.7 MB)
2023-04-07 16:31:46,137 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_14_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:46,139 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 14 from csv at SparkController.java:76
2023-04-07 16:31:46,139 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:46,174 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:76
2023-04-07 16:31:46,176 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 7 (csv at SparkController.java:76) with 1 output partitions
2023-04-07 16:31:46,176 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 7 (csv at SparkController.java:76)
2023-04-07 16:31:46,176 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:46,177 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:46,177 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 7 (MapPartitionsRDD[37] at csv at SparkController.java:76), which has no missing parents
2023-04-07 16:31:46,181 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 997.7 MB)
2023-04-07 16:31:46,183 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KB, free 997.7 MB)
2023-04-07 16:31:46,184 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_15_piece0 in memory on 192.168.1.125:46645 (size: 7.6 KB, free: 998.3 MB)
2023-04-07 16:31:46,189 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 15 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:46,191 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at csv at SparkController.java:76) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:46,192 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 7.0 with 1 tasks
2023-04-07 16:31:46,193 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-07 16:31:46,194 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 7] Running task 0.0 in stage 7.0 (TID 7)
2023-04-07 16:31:46,201 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 7] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-07 16:31:46,314 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 7] Finished task 0.0 in stage 7.0 (TID 7). 1637 bytes result sent to driver
2023-04-07 16:31:46,316 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 7.0 (TID 7) in 123 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:46,316 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 7.0, whose tasks have all completed, from pool 
2023-04-07 16:31:46,318 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 7 (csv at SparkController.java:76) finished in 0.138 s
2023-04-07 16:31:46,319 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 7 finished: csv at SparkController.java:76, took 0.144113 s
2023-04-07 16:31:46,412 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:46,414 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:46,415 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-07 16:31:46,415 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:46,500 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 32.837414 ms
2023-04-07 16:31:46,544 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_16 stored as values in memory (estimated size 112.9 KB, free 997.6 MB)
2023-04-07 16:31:46,558 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.5 MB)
2023-04-07 16:31:46,561 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_16_piece0 in memory on 192.168.1.125:46645 (size: 20.7 KB, free: 998.2 MB)
2023-04-07 16:31:46,562 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 16 from show at SparkController.java:79
2023-04-07 16:31:46,563 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:46,632 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:79
2023-04-07 16:31:46,633 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 8 (show at SparkController.java:79) with 1 output partitions
2023-04-07 16:31:46,634 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 8 (show at SparkController.java:79)
2023-04-07 16:31:46,634 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:46,634 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:46,638 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 8 (MapPartitionsRDD[41] at show at SparkController.java:79), which has no missing parents
2023-04-07 16:31:46,645 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_17 stored as values in memory (estimated size 12.8 KB, free 997.5 MB)
2023-04-07 16:31:46,647 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.5 KB, free 997.5 MB)
2023-04-07 16:31:46,648 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_17_piece0 in memory on 192.168.1.125:46645 (size: 6.5 KB, free: 998.2 MB)
2023-04-07 16:31:46,648 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 17 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:46,649 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[41] at show at SparkController.java:79) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:46,649 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 8.0 with 1 tasks
2023-04-07 16:31:46,650 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-07 16:31:46,651 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 8] Running task 0.0 in stage 8.0 (TID 8)
2023-04-07 16:31:46,660 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 8] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-07 16:31:46,698 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 8] Code generated in 34.497023 ms
2023-04-07 16:31:46,715 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 8] Finished task 0.0 in stage 8.0 (TID 8). 2219 bytes result sent to driver
2023-04-07 16:31:46,717 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 8.0 (TID 8) in 66 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:46,717 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 8.0, whose tasks have all completed, from pool 
2023-04-07 16:31:46,718 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 8 (show at SparkController.java:79) finished in 0.078 s
2023-04-07 16:31:46,721 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 8 finished: show at SparkController.java:79, took 0.088769 s
2023-04-07 16:31:46,725 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Psv File
2023-04-07 16:31:46,866 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-07 16:31:46,974 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_18 stored as values in memory (estimated size 168.0 KB, free 997.3 MB)
2023-04-07 16:31:46,990 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.3 MB)
2023-04-07 16:31:46,993 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_18_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.2 MB)
2023-04-07 16:31:46,996 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 18 from json at SparkController.java:87
2023-04-07 16:31:47,065 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat [http-nio-8080-exec-1] Total input paths to process : 1
2023-04-07 16:31:47,067 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat [http-nio-8080-exec-1] Total input paths to process : 1
2023-04-07 16:31:47,108 INFO org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat [http-nio-8080-exec-1] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 308
2023-04-07 16:31:47,115 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: json at SparkController.java:87
2023-04-07 16:31:47,116 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 9 (json at SparkController.java:87) with 1 output partitions
2023-04-07 16:31:47,116 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 9 (json at SparkController.java:87)
2023-04-07 16:31:47,117 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:47,117 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:47,118 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 9 (MapPartitionsRDD[44] at json at SparkController.java:87), which has no missing parents
2023-04-07 16:31:47,130 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_19 stored as values in memory (estimated size 6.0 KB, free 997.3 MB)
2023-04-07 16:31:47,132 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.6 KB, free 997.3 MB)
2023-04-07 16:31:47,134 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_19_piece0 in memory on 192.168.1.125:46645 (size: 3.6 KB, free: 998.2 MB)
2023-04-07 16:31:47,135 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 19 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:47,140 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at json at SparkController.java:87) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:47,141 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 9.0 with 1 tasks
2023-04-07 16:31:47,172 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7982 bytes)
2023-04-07 16:31:47,175 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 9] Running task 0.0 in stage 9.0 (TID 9)
2023-04-07 16:31:47,202 INFO org.apache.spark.rdd.BinaryFileRDD [Executor task launch worker for task 9] Input split: Paths:/home/inferyx/Documents/Files/sample.json:0+308
2023-04-07 16:31:47,334 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 9] Finished task 0.0 in stage 9.0 (TID 9). 2005 bytes result sent to driver
2023-04-07 16:31:47,338 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 9.0 (TID 9) in 196 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:47,339 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 9.0, whose tasks have all completed, from pool 
2023-04-07 16:31:47,340 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 9 (json at SparkController.java:87) finished in 0.216 s
2023-04-07 16:31:47,343 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 9 finished: json at SparkController.java:87, took 0.227749 s
2023-04-07 16:31:47,470 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:47,471 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:47,473 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-07 16:31:47,473 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:47,592 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 65.562235 ms
2023-04-07 16:31:47,633 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_20 stored as values in memory (estimated size 112.4 KB, free 997.2 MB)
2023-04-07 16:31:47,653 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.8 KB, free 997.2 MB)
2023-04-07 16:31:47,658 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_20_piece0 in memory on 192.168.1.125:46645 (size: 20.8 KB, free: 998.2 MB)
2023-04-07 16:31:47,660 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 20 from show at SparkController.java:89
2023-04-07 16:31:47,664 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:47,678 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:89
2023-04-07 16:31:47,679 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 10 (show at SparkController.java:89) with 1 output partitions
2023-04-07 16:31:47,680 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 10 (show at SparkController.java:89)
2023-04-07 16:31:47,680 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:47,680 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:47,681 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 10 (MapPartitionsRDD[48] at show at SparkController.java:89), which has no missing parents
2023-04-07 16:31:47,687 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_21 stored as values in memory (estimated size 16.4 KB, free 997.2 MB)
2023-04-07 16:31:47,693 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.3 KB, free 997.2 MB)
2023-04-07 16:31:47,695 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_21_piece0 in memory on 192.168.1.125:46645 (size: 7.3 KB, free: 998.2 MB)
2023-04-07 16:31:47,697 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 21 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:47,698 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at show at SparkController.java:89) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:47,698 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 10.0 with 1 tasks
2023-04-07 16:31:47,700 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-07 16:31:47,700 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 10] Running task 0.0 in stage 10.0 (TID 10)
2023-04-07 16:31:47,712 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 10] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-07 16:31:47,782 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 10] Code generated in 51.430337 ms
2023-04-07 16:31:47,829 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 10] Finished task 0.0 in stage 10.0 (TID 10). 1321 bytes result sent to driver
2023-04-07 16:31:47,830 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 10.0 (TID 10) in 131 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:47,831 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 10.0, whose tasks have all completed, from pool 
2023-04-07 16:31:47,832 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 10 (show at SparkController.java:89) finished in 0.149 s
2023-04-07 16:31:47,832 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 10 finished: show at SparkController.java:89, took 0.153289 s
2023-04-07 16:31:47,834 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Json File
2023-04-07 16:31:48,701 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 17.802925 ms
2023-04-07 16:31:48,732 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 19.312706 ms
2023-04-07 16:31:48,757 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:106
2023-04-07 16:31:48,758 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 11 (show at SparkController.java:106) with 1 output partitions
2023-04-07 16:31:48,759 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 11 (show at SparkController.java:106)
2023-04-07 16:31:48,760 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:48,760 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:48,760 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 11 (MapPartitionsRDD[53] at show at SparkController.java:106), which has no missing parents
2023-04-07 16:31:48,766 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_22 stored as values in memory (estimated size 7.5 KB, free 997.2 MB)
2023-04-07 16:31:48,774 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.2 MB)
2023-04-07 16:31:48,775 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_22_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.2 MB)
2023-04-07 16:31:48,777 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 22 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:48,779 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at show at SparkController.java:106) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:48,779 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 11.0 with 1 tasks
2023-04-07 16:31:48,787 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8696 bytes)
2023-04-07 16:31:48,788 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 11] Running task 0.0 in stage 11.0 (TID 11)
2023-04-07 16:31:48,801 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 11] Finished task 0.0 in stage 11.0 (TID 11). 1818 bytes result sent to driver
2023-04-07 16:31:48,804 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 11.0 (TID 11) in 23 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:48,806 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 11 (show at SparkController.java:106) finished in 0.043 s
2023-04-07 16:31:48,805 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 11.0, whose tasks have all completed, from pool 
2023-04-07 16:31:48,807 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 11 finished: show at SparkController.java:106, took 0.049616 s
2023-04-07 16:31:48,813 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:106
2023-04-07 16:31:48,814 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 12 (show at SparkController.java:106) with 2 output partitions
2023-04-07 16:31:48,814 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 12 (show at SparkController.java:106)
2023-04-07 16:31:48,814 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:48,814 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:48,815 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 12 (MapPartitionsRDD[53] at show at SparkController.java:106), which has no missing parents
2023-04-07 16:31:48,819 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_23 stored as values in memory (estimated size 7.5 KB, free 997.1 MB)
2023-04-07 16:31:48,827 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.1 MB)
2023-04-07 16:31:48,829 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_23_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.2 MB)
2023-04-07 16:31:48,830 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 23 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:48,831 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[53] at show at SparkController.java:106) (first 15 tasks are for partitions Vector(1, 2))
2023-04-07 16:31:48,832 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 12.0 with 2 tasks
2023-04-07 16:31:48,833 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 8295 bytes)
2023-04-07 16:31:48,834 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 1.0 in stage 12.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-07 16:31:48,835 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 12] Running task 0.0 in stage 12.0 (TID 12)
2023-04-07 16:31:48,837 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 13] Running task 1.0 in stage 12.0 (TID 13)
2023-04-07 16:31:48,843 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 12] Finished task 0.0 in stage 12.0 (TID 12). 1112 bytes result sent to driver
2023-04-07 16:31:48,843 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 13] Finished task 1.0 in stage 12.0 (TID 13). 1112 bytes result sent to driver
2023-04-07 16:31:48,845 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 12.0 (TID 12) in 12 ms on localhost (executor driver) (1/2)
2023-04-07 16:31:48,846 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 1.0 in stage 12.0 (TID 13) in 13 ms on localhost (executor driver) (2/2)
2023-04-07 16:31:48,846 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 12.0, whose tasks have all completed, from pool 
2023-04-07 16:31:48,848 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 12 (show at SparkController.java:106) finished in 0.031 s
2023-04-07 16:31:48,848 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 12 finished: show at SparkController.java:106, took 0.034934 s
2023-04-07 16:31:48,853 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Excel File
2023-04-07 16:31:49,060 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 147
2023-04-07 16:31:49,061 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 104
2023-04-07 16:31:49,061 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 352
2023-04-07 16:31:49,061 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 191
2023-04-07 16:31:49,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 141
2023-04-07 16:31:49,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 233
2023-04-07 16:31:49,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 153
2023-04-07 16:31:49,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 103
2023-04-07 16:31:49,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 113
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 314
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 234
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 243
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 99
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 376
2023-04-07 16:31:49,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 362
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 356
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 265
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 120
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 171
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 209
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 276
2023-04-07 16:31:49,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 325
2023-04-07 16:31:49,065 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 280
2023-04-07 16:31:49,065 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 98
2023-04-07 16:31:49,065 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 139
2023-04-07 16:31:49,066 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 289
2023-04-07 16:31:49,066 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 346
2023-04-07 16:31:49,070 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 246
2023-04-07 16:31:49,070 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 260
2023-04-07 16:31:49,070 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 286
2023-04-07 16:31:49,071 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 297
2023-04-07 16:31:49,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 371
2023-04-07 16:31:49,082 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_7_piece0 on 192.168.1.125:46645 in memory (size: 4.6 KB, free: 998.2 MB)
2023-04-07 16:31:49,133 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 264
2023-04-07 16:31:49,133 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 375
2023-04-07 16:31:49,134 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 341
2023-04-07 16:31:49,134 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 194
2023-04-07 16:31:49,134 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 170
2023-04-07 16:31:49,134 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 187
2023-04-07 16:31:49,136 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 323
2023-04-07 16:31:49,136 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 183
2023-04-07 16:31:49,136 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 303
2023-04-07 16:31:49,136 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 221
2023-04-07 16:31:49,136 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 278
2023-04-07 16:31:49,137 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 279
2023-04-07 16:31:49,137 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 132
2023-04-07 16:31:49,162 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_23_piece0 on 192.168.1.125:46645 in memory (size: 3.5 KB, free: 998.2 MB)
2023-04-07 16:31:49,167 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 106
2023-04-07 16:31:49,168 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 307
2023-04-07 16:31:49,169 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 299
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 119
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 357
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 112
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 373
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 204
2023-04-07 16:31:49,170 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 222
2023-04-07 16:31:49,174 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 111
2023-04-07 16:31:49,175 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 208
2023-04-07 16:31:49,175 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 114
2023-04-07 16:31:49,175 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 149
2023-04-07 16:31:49,188 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_14_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.2 MB)
2023-04-07 16:31:49,195 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 116
2023-04-07 16:31:49,195 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 155
2023-04-07 16:31:49,195 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 129
2023-04-07 16:31:49,196 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 281
2023-04-07 16:31:49,196 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 215
2023-04-07 16:31:49,197 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 355
2023-04-07 16:31:49,198 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 124
2023-04-07 16:31:49,198 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 160
2023-04-07 16:31:49,198 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 214
2023-04-07 16:31:49,198 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 143
2023-04-07 16:31:49,199 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 263
2023-04-07 16:31:49,199 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 358
2023-04-07 16:31:49,199 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 312
2023-04-07 16:31:49,199 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 328
2023-04-07 16:31:49,199 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 271
2023-04-07 16:31:49,200 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 152
2023-04-07 16:31:49,200 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 348
2023-04-07 16:31:49,200 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 283
2023-04-07 16:31:49,216 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_18_piece0 on 192.168.1.125:46645 in memory (size: 20.9 KB, free: 998.2 MB)
2023-04-07 16:31:49,219 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 198
2023-04-07 16:31:49,220 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 329
2023-04-07 16:31:49,227 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_20_piece0 on 192.168.1.125:46645 in memory (size: 20.8 KB, free: 998.3 MB)
2023-04-07 16:31:49,233 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 244
2023-04-07 16:31:49,234 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 301
2023-04-07 16:31:49,234 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 337
2023-04-07 16:31:49,235 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 207
2023-04-07 16:31:49,235 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 270
2023-04-07 16:31:49,235 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 235
2023-04-07 16:31:49,235 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 245
2023-04-07 16:31:49,236 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 232
2023-04-07 16:31:49,237 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 225
2023-04-07 16:31:49,238 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 145
2023-04-07 16:31:49,243 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 175
2023-04-07 16:31:49,243 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 176
2023-04-07 16:31:49,243 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 210
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 94
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 336
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 361
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 218
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 100
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 266
2023-04-07 16:31:49,244 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 365
2023-04-07 16:31:49,245 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 130
2023-04-07 16:31:49,245 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 196
2023-04-07 16:31:49,245 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 219
2023-04-07 16:31:49,245 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 156
2023-04-07 16:31:49,246 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 369
2023-04-07 16:31:49,246 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 359
2023-04-07 16:31:49,246 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 257
2023-04-07 16:31:49,247 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 378
2023-04-07 16:31:49,250 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_19_piece0 on 192.168.1.125:46645 in memory (size: 3.6 KB, free: 998.3 MB)
2023-04-07 16:31:49,269 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 177
2023-04-07 16:31:49,270 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 228
2023-04-07 16:31:49,270 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 224
2023-04-07 16:31:49,270 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 237
2023-04-07 16:31:49,271 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 128
2023-04-07 16:31:49,271 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 275
2023-04-07 16:31:49,271 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 227
2023-04-07 16:31:49,271 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 306
2023-04-07 16:31:49,272 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 146
2023-04-07 16:31:49,272 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 220
2023-04-07 16:31:49,272 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 226
2023-04-07 16:31:49,273 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 144
2023-04-07 16:31:49,273 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 151
2023-04-07 16:31:49,273 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 148
2023-04-07 16:31:49,273 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 259
2023-04-07 16:31:49,273 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 349
2023-04-07 16:31:49,274 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 179
2023-04-07 16:31:49,274 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 229
2023-04-07 16:31:49,274 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 258
2023-04-07 16:31:49,276 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 345
2023-04-07 16:31:49,277 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 223
2023-04-07 16:31:49,282 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_6_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:49,312 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 261
2023-04-07 16:31:49,312 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 285
2023-04-07 16:31:49,312 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 164
2023-04-07 16:31:49,312 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 251
2023-04-07 16:31:49,312 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 273
2023-04-07 16:31:49,313 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 372
2023-04-07 16:31:49,313 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 150
2023-04-07 16:31:49,313 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 216
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 277
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 136
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 123
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 333
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 142
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 161
2023-04-07 16:31:49,314 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 255
2023-04-07 16:31:49,315 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 205
2023-04-07 16:31:49,315 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 319
2023-04-07 16:31:49,315 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 206
2023-04-07 16:31:49,315 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 268
2023-04-07 16:31:49,316 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 200
2023-04-07 16:31:49,316 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 231
2023-04-07 16:31:49,317 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 363
2023-04-07 16:31:49,317 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 292
2023-04-07 16:31:49,318 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 296
2023-04-07 16:31:49,322 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 105
2023-04-07 16:31:49,322 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 249
2023-04-07 16:31:49,323 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 347
2023-04-07 16:31:49,323 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 240
2023-04-07 16:31:49,323 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 117
2023-04-07 16:31:49,323 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 97
2023-04-07 16:31:49,323 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 134
2023-04-07 16:31:49,324 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 195
2023-04-07 16:31:49,325 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 368
2023-04-07 16:31:49,326 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 202
2023-04-07 16:31:49,327 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 364
2023-04-07 16:31:49,333 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_8_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:49,380 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 367
2023-04-07 16:31:49,380 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 121
2023-04-07 16:31:49,380 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 135
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 122
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 269
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 318
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 201
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 168
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 321
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 238
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 159
2023-04-07 16:31:49,381 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 302
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 351
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 173
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 313
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 158
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 182
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 253
2023-04-07 16:31:49,382 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 163
2023-04-07 16:31:49,400 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_9_piece0 on 192.168.1.125:46645 in memory (size: 7.6 KB, free: 998.3 MB)
2023-04-07 16:31:49,431 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 284
2023-04-07 16:31:49,431 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 248
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 311
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 335
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 185
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 127
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 230
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 217
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 267
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 211
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 290
2023-04-07 16:31:49,432 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 377
2023-04-07 16:31:49,433 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 320
2023-04-07 16:31:49,433 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 110
2023-04-07 16:31:49,438 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_10_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-07 16:31:49,452 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 190
2023-04-07 16:31:49,490 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_22_piece0 on 192.168.1.125:46645 in memory (size: 3.5 KB, free: 998.3 MB)
2023-04-07 16:31:49,497 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 96
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 287
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 310
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 374
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 193
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 293
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 308
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 172
2023-04-07 16:31:49,498 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 326
2023-04-07 16:31:49,499 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 108
2023-04-07 16:31:49,499 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 350
2023-04-07 16:31:49,515 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_13_piece0 on 192.168.1.125:46645 in memory (size: 4.6 KB, free: 998.3 MB)
2023-04-07 16:31:49,525 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 353
2023-04-07 16:31:49,525 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 154
2023-04-07 16:31:49,525 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 95
2023-04-07 16:31:49,525 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 379
2023-04-07 16:31:49,525 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 93
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 295
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 331
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 334
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 197
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 250
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 115
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 354
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 309
2023-04-07 16:31:49,526 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 327
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 324
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 343
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 181
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 274
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 338
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 213
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 199
2023-04-07 16:31:49,527 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 101
2023-04-07 16:31:49,528 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 298
2023-04-07 16:31:49,528 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 247
2023-04-07 16:31:49,534 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_17_piece0 on 192.168.1.125:46645 in memory (size: 6.5 KB, free: 998.3 MB)
2023-04-07 16:31:49,546 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_21_piece0 on 192.168.1.125:46645 in memory (size: 7.3 KB, free: 998.3 MB)
2023-04-07 16:31:49,555 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 189
2023-04-07 16:31:49,555 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 186
2023-04-07 16:31:49,560 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_15_piece0 on 192.168.1.125:46645 in memory (size: 7.6 KB, free: 998.4 MB)
2023-04-07 16:31:49,567 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 252
2023-04-07 16:31:49,568 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 212
2023-04-07 16:31:49,568 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 137
2023-04-07 16:31:49,568 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 370
2023-04-07 16:31:49,568 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 131
2023-04-07 16:31:49,568 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 133
2023-04-07 16:31:49,569 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 360
2023-04-07 16:31:49,570 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 262
2023-04-07 16:31:49,571 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 178
2023-04-07 16:31:49,571 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 180
2023-04-07 16:31:49,571 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 254
2023-04-07 16:31:49,574 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 282
2023-04-07 16:31:49,574 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 169
2023-04-07 16:31:49,575 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 91
2023-04-07 16:31:49,575 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 332
2023-04-07 16:31:49,575 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 203
2023-04-07 16:31:49,575 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 109
2023-04-07 16:31:49,576 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 140
2023-04-07 16:31:49,576 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 242
2023-04-07 16:31:49,576 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 288
2023-04-07 16:31:49,576 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 291
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 322
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 184
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 344
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 138
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 236
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 162
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 304
2023-04-07 16:31:49,577 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 272
2023-04-07 16:31:49,578 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 167
2023-04-07 16:31:49,580 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_11_piece0 on 192.168.1.125:46645 in memory (size: 6.3 KB, free: 998.4 MB)
2023-04-07 16:31:49,582 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 241
2023-04-07 16:31:49,584 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_16_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:49,591 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 256
2023-04-07 16:31:49,592 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 317
2023-04-07 16:31:49,592 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 366
2023-04-07 16:31:49,592 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 294
2023-04-07 16:31:49,593 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 118
2023-04-07 16:31:49,593 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 315
2023-04-07 16:31:49,593 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 330
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 340
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 188
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 125
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 174
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 192
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 126
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 305
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 107
2023-04-07 16:31:49,594 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 165
2023-04-07 16:31:49,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 339
2023-04-07 16:31:49,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 102
2023-04-07 16:31:49,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 92
2023-04-07 16:31:49,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 316
2023-04-07 16:31:49,595 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 300
2023-04-07 16:31:49,597 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_12_piece0 on 192.168.1.125:46645 in memory (size: 20.7 KB, free: 998.4 MB)
2023-04-07 16:31:49,603 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 342
2023-04-07 16:31:49,603 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 157
2023-04-07 16:31:49,604 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 166
2023-04-07 16:31:49,604 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 239
2023-04-07 16:31:51,662 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:51,663 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:51,664 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:51,664 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:51,678 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_24 stored as values in memory (estimated size 167.6 KB, free 998.2 MB)
2023-04-07 16:31:51,695 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.8 KB, free 998.2 MB)
2023-04-07 16:31:51,697 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_24_piece0 in memory on 192.168.1.125:46645 (size: 20.8 KB, free: 998.4 MB)
2023-04-07 16:31:51,699 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 24 from jdbc at SparkController.java:125
2023-04-07 16:31:51,699 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:51,736 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:125
2023-04-07 16:31:51,738 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 13 (jdbc at SparkController.java:125) with 1 output partitions
2023-04-07 16:31:51,738 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 13 (jdbc at SparkController.java:125)
2023-04-07 16:31:51,738 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:51,738 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:51,739 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 13 (MapPartitionsRDD[58] at jdbc at SparkController.java:125), which has no missing parents
2023-04-07 16:31:51,746 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_25 stored as values in memory (estimated size 15.9 KB, free 998.2 MB)
2023-04-07 16:31:51,748 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.5 KB, free 998.2 MB)
2023-04-07 16:31:51,749 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_25_piece0 in memory on 192.168.1.125:46645 (size: 8.5 KB, free: 998.4 MB)
2023-04-07 16:31:51,750 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 25 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:51,751 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[58] at jdbc at SparkController.java:125) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:51,751 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 13.0 with 1 tasks
2023-04-07 16:31:51,753 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-07 16:31:51,754 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 14] Running task 0.0 in stage 13.0 (TID 14)
2023-04-07 16:31:51,909 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 14] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-07 16:31:52,605 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 14] Finished task 0.0 in stage 13.0 (TID 14). 1437 bytes result sent to driver
2023-04-07 16:31:52,606 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 13.0 (TID 14) in 853 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:52,607 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 13.0, whose tasks have all completed, from pool 
2023-04-07 16:31:52,608 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 13 (jdbc at SparkController.java:125) finished in 0.868 s
2023-04-07 16:31:52,609 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 13 finished: jdbc at SparkController.java:125, took 0.871847 s
2023-04-07 16:31:52,853 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:52,855 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:52,855 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:52,856 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:52,881 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_26 stored as values in memory (estimated size 167.6 KB, free 998.0 MB)
2023-04-07 16:31:52,896 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_26_piece0 stored as bytes in memory (estimated size 20.8 KB, free 998.0 MB)
2023-04-07 16:31:52,898 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_26_piece0 in memory on 192.168.1.125:46645 (size: 20.8 KB, free: 998.4 MB)
2023-04-07 16:31:52,899 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 26 from show at SparkController.java:127
2023-04-07 16:31:52,900 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:52,917 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:127
2023-04-07 16:31:52,920 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 14 (show at SparkController.java:127) with 1 output partitions
2023-04-07 16:31:52,920 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 14 (show at SparkController.java:127)
2023-04-07 16:31:52,920 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:52,921 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:52,921 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 14 (MapPartitionsRDD[64] at show at SparkController.java:127), which has no missing parents
2023-04-07 16:31:52,925 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_27 stored as values in memory (estimated size 10.4 KB, free 998.0 MB)
2023-04-07 16:31:52,928 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.7 KB, free 998.0 MB)
2023-04-07 16:31:52,929 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_27_piece0 in memory on 192.168.1.125:46645 (size: 5.7 KB, free: 998.3 MB)
2023-04-07 16:31:52,930 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 27 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:52,930 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at show at SparkController.java:127) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:52,931 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 14.0 with 1 tasks
2023-04-07 16:31:52,932 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-07 16:31:52,933 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 15] Running task 0.0 in stage 14.0 (TID 15)
2023-04-07 16:31:52,942 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 15] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-07 16:31:52,950 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 15] Finished task 0.0 in stage 14.0 (TID 15). 1677 bytes result sent to driver
2023-04-07 16:31:52,952 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 14.0 (TID 15) in 20 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:52,953 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 14.0, whose tasks have all completed, from pool 
2023-04-07 16:31:52,954 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 14 (show at SparkController.java:127) finished in 0.032 s
2023-04-07 16:31:52,955 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 14 finished: show at SparkController.java:127, took 0.036292 s
2023-04-07 16:31:52,959 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Csv File
2023-04-07 16:31:53,357 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:53,358 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:53,359 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:53,360 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:53,367 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_28 stored as values in memory (estimated size 167.8 KB, free 997.8 MB)
2023-04-07 16:31:53,380 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.8 MB)
2023-04-07 16:31:53,381 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_28_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:53,382 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 28 from jdbc at SparkController.java:134
2023-04-07 16:31:53,383 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:53,401 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:134
2023-04-07 16:31:53,402 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 15 (jdbc at SparkController.java:134) with 1 output partitions
2023-04-07 16:31:53,403 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 15 (jdbc at SparkController.java:134)
2023-04-07 16:31:53,403 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:53,403 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:53,404 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 15 (MapPartitionsRDD[69] at jdbc at SparkController.java:134), which has no missing parents
2023-04-07 16:31:53,408 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_29 stored as values in memory (estimated size 16.0 KB, free 997.8 MB)
2023-04-07 16:31:53,411 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.6 KB, free 997.8 MB)
2023-04-07 16:31:53,412 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_29_piece0 in memory on 192.168.1.125:46645 (size: 8.6 KB, free: 998.3 MB)
2023-04-07 16:31:53,413 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 29 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:53,416 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[69] at jdbc at SparkController.java:134) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:53,416 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 15.0 with 1 tasks
2023-04-07 16:31:53,419 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-07 16:31:53,421 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 16] Running task 0.0 in stage 15.0 (TID 16)
2023-04-07 16:31:53,454 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 16] Code generated in 19.322717 ms
2023-04-07 16:31:53,546 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 16] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-07 16:31:53,693 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 16] Finished task 0.0 in stage 15.0 (TID 16). 1394 bytes result sent to driver
2023-04-07 16:31:53,694 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 15.0 (TID 16) in 276 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:53,695 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 15.0, whose tasks have all completed, from pool 
2023-04-07 16:31:53,696 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 15 (jdbc at SparkController.java:134) finished in 0.290 s
2023-04-07 16:31:53,696 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 15 finished: jdbc at SparkController.java:134, took 0.295054 s
2023-04-07 16:31:53,901 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:53,903 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:53,904 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-07 16:31:53,906 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:53,947 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_30 stored as values in memory (estimated size 167.8 KB, free 997.6 MB)
2023-04-07 16:31:53,966 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.6 MB)
2023-04-07 16:31:53,967 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_30_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:53,968 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 30 from show at SparkController.java:136
2023-04-07 16:31:53,970 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:53,984 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:136
2023-04-07 16:31:53,987 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 16 (show at SparkController.java:136) with 1 output partitions
2023-04-07 16:31:53,987 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 16 (show at SparkController.java:136)
2023-04-07 16:31:53,987 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:53,987 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:53,991 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 16 (MapPartitionsRDD[75] at show at SparkController.java:136), which has no missing parents
2023-04-07 16:31:53,996 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_31 stored as values in memory (estimated size 12.6 KB, free 997.6 MB)
2023-04-07 16:31:54,016 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.3 KB, free 997.6 MB)
2023-04-07 16:31:54,017 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_31_piece0 in memory on 192.168.1.125:46645 (size: 6.3 KB, free: 998.3 MB)
2023-04-07 16:31:54,019 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 31 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:54,020 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at show at SparkController.java:136) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:54,021 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 16.0 with 1 tasks
2023-04-07 16:31:54,022 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-07 16:31:54,023 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 17] Running task 0.0 in stage 16.0 (TID 17)
2023-04-07 16:31:54,028 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 17] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-07 16:31:54,041 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 17] Finished task 0.0 in stage 16.0 (TID 17). 1695 bytes result sent to driver
2023-04-07 16:31:54,042 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 16.0 (TID 17) in 20 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:54,043 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 16.0, whose tasks have all completed, from pool 
2023-04-07 16:31:54,044 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 16 (show at SparkController.java:136) finished in 0.050 s
2023-04-07 16:31:54,045 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 16 finished: show at SparkController.java:136, took 0.058782 s
2023-04-07 16:31:54,048 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Psv File
2023-04-07 16:31:54,186 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:54,187 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:54,188 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-07 16:31:54,188 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:54,201 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_32 stored as values in memory (estimated size 167.8 KB, free 997.4 MB)
2023-04-07 16:31:54,216 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_32_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.4 MB)
2023-04-07 16:31:54,217 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_32_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:54,218 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 32 from jdbc at SparkController.java:142
2023-04-07 16:31:54,220 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:54,241 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:142
2023-04-07 16:31:54,242 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 17 (jdbc at SparkController.java:142) with 1 output partitions
2023-04-07 16:31:54,243 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 17 (jdbc at SparkController.java:142)
2023-04-07 16:31:54,243 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:54,243 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:54,244 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 17 (MapPartitionsRDD[80] at jdbc at SparkController.java:142), which has no missing parents
2023-04-07 16:31:54,248 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_33 stored as values in memory (estimated size 16.0 KB, free 997.4 MB)
2023-04-07 16:31:54,250 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.6 KB, free 997.4 MB)
2023-04-07 16:31:54,251 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_33_piece0 in memory on 192.168.1.125:46645 (size: 8.6 KB, free: 998.3 MB)
2023-04-07 16:31:54,253 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 33 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:54,254 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[80] at jdbc at SparkController.java:142) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:54,254 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 17.0 with 1 tasks
2023-04-07 16:31:54,257 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-07 16:31:54,259 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 18] Running task 0.0 in stage 17.0 (TID 18)
2023-04-07 16:31:54,297 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 18] Code generated in 24.086759 ms
2023-04-07 16:31:54,357 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 18] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-07 16:31:55,416 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 18] Finished task 0.0 in stage 17.0 (TID 18). 1394 bytes result sent to driver
2023-04-07 16:31:55,418 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 17.0 (TID 18) in 1160 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:55,418 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 17.0, whose tasks have all completed, from pool 
2023-04-07 16:31:55,419 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 17 (jdbc at SparkController.java:142) finished in 1.174 s
2023-04-07 16:31:55,420 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 17 finished: jdbc at SparkController.java:142, took 1.178736 s
2023-04-07 16:31:55,990 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:55,991 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:55,992 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-07 16:31:55,992 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:56,023 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_34 stored as values in memory (estimated size 167.8 KB, free 997.2 MB)
2023-04-07 16:31:56,040 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.2 MB)
2023-04-07 16:31:56,042 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_34_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.2 MB)
2023-04-07 16:31:56,044 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 34 from show at SparkController.java:144
2023-04-07 16:31:56,045 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:56,062 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:144
2023-04-07 16:31:56,064 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 18 (show at SparkController.java:144) with 1 output partitions
2023-04-07 16:31:56,064 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 18 (show at SparkController.java:144)
2023-04-07 16:31:56,064 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:56,064 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:56,064 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 18 (MapPartitionsRDD[86] at show at SparkController.java:144), which has no missing parents
2023-04-07 16:31:56,069 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_35 stored as values in memory (estimated size 12.8 KB, free 997.2 MB)
2023-04-07 16:31:56,075 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_35_piece0 stored as bytes in memory (estimated size 6.5 KB, free 997.2 MB)
2023-04-07 16:31:56,077 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_35_piece0 in memory on 192.168.1.125:46645 (size: 6.5 KB, free: 998.2 MB)
2023-04-07 16:31:56,078 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 35 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:56,078 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[86] at show at SparkController.java:144) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:56,078 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 18.0 with 1 tasks
2023-04-07 16:31:56,080 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 18.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-07 16:31:56,080 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 19] Running task 0.0 in stage 18.0 (TID 19)
2023-04-07 16:31:56,085 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 19] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-07 16:31:56,095 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 19] Finished task 0.0 in stage 18.0 (TID 19). 2219 bytes result sent to driver
2023-04-07 16:31:56,096 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 18.0 (TID 19) in 17 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:56,096 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 18.0, whose tasks have all completed, from pool 
2023-04-07 16:31:56,097 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 18 (show at SparkController.java:144) finished in 0.031 s
2023-04-07 16:31:56,098 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 18 finished: show at SparkController.java:144, took 0.035060 s
2023-04-07 16:31:56,107 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Tsv File
2023-04-07 16:31:56,345 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:56,346 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:56,347 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-07 16:31:56,347 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:56,392 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 12.464084 ms
2023-04-07 16:31:56,421 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 19.418031 ms
2023-04-07 16:31:56,430 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_36 stored as values in memory (estimated size 167.5 KB, free 997.0 MB)
2023-04-07 16:31:56,448 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.0 MB)
2023-04-07 16:31:56,449 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_36_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.2 MB)
2023-04-07 16:31:56,452 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 36 from show at SparkController.java:155
2023-04-07 16:31:56,453 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:56,480 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:155
2023-04-07 16:31:56,481 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 19 (show at SparkController.java:155) with 1 output partitions
2023-04-07 16:31:56,481 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 19 (show at SparkController.java:155)
2023-04-07 16:31:56,482 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:56,482 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:56,484 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 19 (MapPartitionsRDD[93] at show at SparkController.java:155), which has no missing parents
2023-04-07 16:31:56,544 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_37 stored as values in memory (estimated size 27.6 KB, free 997.0 MB)
2023-04-07 16:31:56,546 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.1 KB, free 996.9 MB)
2023-04-07 16:31:56,547 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_37_piece0 in memory on 192.168.1.125:46645 (size: 12.1 KB, free: 998.2 MB)
2023-04-07 16:31:56,548 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 37 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:56,549 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[93] at show at SparkController.java:155) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:56,549 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 19.0 with 1 tasks
2023-04-07 16:31:56,550 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 19.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-07 16:31:56,560 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 20] Running task 0.0 in stage 19.0 (TID 20)
2023-04-07 16:31:56,731 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 20] Code generated in 109.34635 ms
2023-04-07 16:31:56,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 480
2023-04-07 16:31:56,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 489
2023-04-07 16:31:56,734 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 420
2023-04-07 16:31:56,735 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 436
2023-04-07 16:31:56,735 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 522
2023-04-07 16:31:56,736 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 413
2023-04-07 16:31:56,737 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 455
2023-04-07 16:31:56,737 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 506
2023-04-07 16:31:56,737 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 467
2023-04-07 16:31:56,738 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 393
2023-04-07 16:31:56,740 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 453
2023-04-07 16:31:56,740 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 418
2023-04-07 16:31:56,741 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 444
2023-04-07 16:31:56,741 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 551
2023-04-07 16:31:56,741 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 405
2023-04-07 16:31:56,741 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 505
2023-04-07 16:31:56,744 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 451
2023-04-07 16:31:56,744 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 555
2023-04-07 16:31:56,744 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 401
2023-04-07 16:31:56,745 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 516
2023-04-07 16:31:56,745 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 523
2023-04-07 16:31:56,745 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 390
2023-04-07 16:31:56,746 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 385
2023-04-07 16:31:56,752 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_26_piece0 on 192.168.1.125:46645 in memory (size: 20.8 KB, free: 998.2 MB)
2023-04-07 16:31:56,766 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 457
2023-04-07 16:31:56,766 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 527
2023-04-07 16:31:56,766 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 20] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-07 16:31:56,766 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 415
2023-04-07 16:31:56,771 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_30_piece0 on 192.168.1.125:46645 in memory (size: 20.9 KB, free: 998.2 MB)
2023-04-07 16:31:56,780 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 383
2023-04-07 16:31:56,780 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 439
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 542
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 394
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 397
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 559
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 424
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 526
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 545
2023-04-07 16:31:56,781 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 479
2023-04-07 16:31:56,782 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 509
2023-04-07 16:31:56,784 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_33_piece0 on 192.168.1.125:46645 in memory (size: 8.6 KB, free: 998.3 MB)
2023-04-07 16:31:56,793 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 558
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 398
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 485
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 494
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 380
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 454
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 381
2023-04-07 16:31:56,794 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 491
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 473
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 503
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 507
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 477
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 547
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 512
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 553
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 533
2023-04-07 16:31:56,795 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 502
2023-04-07 16:31:56,809 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_28_piece0 on 192.168.1.125:46645 in memory (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:56,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 395
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 384
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 524
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 511
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 519
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 472
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 536
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 442
2023-04-07 16:31:56,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 543
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 441
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 463
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 460
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 470
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 404
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 422
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 447
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 403
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 540
2023-04-07 16:31:56,863 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 411
2023-04-07 16:31:56,864 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 483
2023-04-07 16:31:56,864 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 487
2023-04-07 16:31:56,880 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_25_piece0 on 192.168.1.125:46645 in memory (size: 8.5 KB, free: 998.3 MB)
2023-04-07 16:31:56,883 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 443
2023-04-07 16:31:56,883 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 388
2023-04-07 16:31:56,883 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 432
2023-04-07 16:31:56,884 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 514
2023-04-07 16:31:56,884 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 391
2023-04-07 16:31:56,888 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_29_piece0 on 192.168.1.125:46645 in memory (size: 8.6 KB, free: 998.3 MB)
2023-04-07 16:31:56,891 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 482
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 546
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 508
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 544
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 492
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 419
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 513
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 396
2023-04-07 16:31:56,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 539
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 382
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 557
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 493
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 529
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 448
2023-04-07 16:31:56,893 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 437
2023-04-07 16:31:56,894 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 496
2023-04-07 16:31:56,900 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_32_piece0 on 192.168.1.125:46645 in memory (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:56,908 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 554
2023-04-07 16:31:56,909 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 386
2023-04-07 16:31:56,909 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 520
2023-04-07 16:31:56,909 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 490
2023-04-07 16:31:56,909 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 484
2023-04-07 16:31:56,909 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 541
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 466
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 461
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 501
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 517
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 434
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 518
2023-04-07 16:31:56,910 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 497
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 445
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 412
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 528
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 435
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 449
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 521
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 549
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 416
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 500
2023-04-07 16:31:56,911 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 537
2023-04-07 16:31:56,912 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 464
2023-04-07 16:31:56,912 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 426
2023-04-07 16:31:56,914 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_27_piece0 on 192.168.1.125:46645 in memory (size: 5.7 KB, free: 998.3 MB)
2023-04-07 16:31:56,917 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 417
2023-04-07 16:31:56,918 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 456
2023-04-07 16:31:56,918 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 387
2023-04-07 16:31:56,918 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 407
2023-04-07 16:31:56,918 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 427
2023-04-07 16:31:56,918 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 556
2023-04-07 16:31:56,919 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 452
2023-04-07 16:31:56,919 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 531
2023-04-07 16:31:56,919 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 462
2023-04-07 16:31:56,919 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 552
2023-04-07 16:31:56,919 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 438
2023-04-07 16:31:56,926 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_31_piece0 on 192.168.1.125:46645 in memory (size: 6.3 KB, free: 998.3 MB)
2023-04-07 16:31:56,929 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 498
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 548
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 431
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 538
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 389
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 465
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 550
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 476
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 392
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 510
2023-04-07 16:31:56,930 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 478
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 535
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 402
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 481
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 433
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 425
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 471
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 421
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 475
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 430
2023-04-07 16:31:56,931 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 408
2023-04-07 16:31:56,932 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 428
2023-04-07 16:31:56,938 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_24_piece0 on 192.168.1.125:46645 in memory (size: 20.8 KB, free: 998.3 MB)
2023-04-07 16:31:56,939 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 399
2023-04-07 16:31:56,939 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 534
2023-04-07 16:31:56,939 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 515
2023-04-07 16:31:56,941 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_35_piece0 on 192.168.1.125:46645 in memory (size: 6.5 KB, free: 998.3 MB)
2023-04-07 16:31:56,942 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 495
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 504
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 532
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 406
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 468
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 499
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 486
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 450
2023-04-07 16:31:56,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 446
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 414
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 459
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 409
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 530
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 429
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 440
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 423
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 400
2023-04-07 16:31:56,944 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 474
2023-04-07 16:31:56,945 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 410
2023-04-07 16:31:56,945 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 488
2023-04-07 16:31:56,946 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_34_piece0 on 192.168.1.125:46645 in memory (size: 20.9 KB, free: 998.4 MB)
2023-04-07 16:31:56,947 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 458
2023-04-07 16:31:56,948 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 469
2023-04-07 16:31:56,948 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 525
2023-04-07 16:31:57,017 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 20] Code generated in 128.470875 ms
2023-04-07 16:31:57,037 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 20] Finished task 0.0 in stage 19.0 (TID 20). 1813 bytes result sent to driver
2023-04-07 16:31:57,040 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 19.0 (TID 20) in 490 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:57,040 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 19.0, whose tasks have all completed, from pool 
2023-04-07 16:31:57,043 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 19 (show at SparkController.java:155) finished in 0.556 s
2023-04-07 16:31:57,044 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 19 finished: show at SparkController.java:155, took 0.563907 s
2023-04-07 16:31:57,251 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-07 16:31:57,253 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-07 16:31:57,254 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-07 16:31:57,254 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-07 16:31:57,269 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_38 stored as values in memory (estimated size 167.5 KB, free 998.0 MB)
2023-04-07 16:31:57,281 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_38_piece0 stored as bytes in memory (estimated size 20.9 KB, free 998.0 MB)
2023-04-07 16:31:57,283 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_38_piece0 in memory on 192.168.1.125:46645 (size: 20.9 KB, free: 998.3 MB)
2023-04-07 16:31:57,284 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 38 from jdbc at SparkController.java:160
2023-04-07 16:31:57,287 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-07 16:31:57,322 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:160
2023-04-07 16:31:57,324 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 20 (jdbc at SparkController.java:160) with 1 output partitions
2023-04-07 16:31:57,324 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 20 (jdbc at SparkController.java:160)
2023-04-07 16:31:57,324 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:57,324 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:57,326 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 20 (MapPartitionsRDD[101] at jdbc at SparkController.java:160), which has no missing parents
2023-04-07 16:31:57,331 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_39 stored as values in memory (estimated size 30.0 KB, free 998.0 MB)
2023-04-07 16:31:57,333 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_39_piece0 stored as bytes in memory (estimated size 13.5 KB, free 998.0 MB)
2023-04-07 16:31:57,333 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_39_piece0 in memory on 192.168.1.125:46645 (size: 13.5 KB, free: 998.3 MB)
2023-04-07 16:31:57,334 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 39 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:57,335 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[101] at jdbc at SparkController.java:160) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:57,336 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 20.0 with 1 tasks
2023-04-07 16:31:57,339 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 20.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-07 16:31:57,340 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 21] Running task 0.0 in stage 20.0 (TID 21)
2023-04-07 16:31:57,437 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 21] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-07 16:31:57,655 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 21] Finished task 0.0 in stage 20.0 (TID 21). 1484 bytes result sent to driver
2023-04-07 16:31:57,657 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 20.0 (TID 21) in 317 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:57,657 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 20.0, whose tasks have all completed, from pool 
2023-04-07 16:31:57,658 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 20 (jdbc at SparkController.java:160) finished in 0.331 s
2023-04-07 16:31:57,659 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 20 finished: jdbc at SparkController.java:160, took 0.335988 s
2023-04-07 16:31:57,848 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:162
2023-04-07 16:31:57,850 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 21 (show at SparkController.java:162) with 1 output partitions
2023-04-07 16:31:57,850 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 21 (show at SparkController.java:162)
2023-04-07 16:31:57,850 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:57,850 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:57,851 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 21 (MapPartitionsRDD[108] at show at SparkController.java:162), which has no missing parents
2023-04-07 16:31:57,854 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_40 stored as values in memory (estimated size 7.5 KB, free 997.9 MB)
2023-04-07 16:31:57,857 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.9 MB)
2023-04-07 16:31:57,858 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_40_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.3 MB)
2023-04-07 16:31:57,859 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 40 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:57,859 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[108] at show at SparkController.java:162) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:57,859 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 21.0 with 1 tasks
2023-04-07 16:31:57,861 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 21.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8696 bytes)
2023-04-07 16:31:57,861 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 22] Running task 0.0 in stage 21.0 (TID 22)
2023-04-07 16:31:57,868 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 22] Finished task 0.0 in stage 21.0 (TID 22). 1818 bytes result sent to driver
2023-04-07 16:31:57,870 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 21.0 (TID 22) in 10 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:57,870 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 21.0, whose tasks have all completed, from pool 
2023-04-07 16:31:57,873 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 21 (show at SparkController.java:162) finished in 0.020 s
2023-04-07 16:31:57,873 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 21 finished: show at SparkController.java:162, took 0.024595 s
2023-04-07 16:31:57,879 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:162
2023-04-07 16:31:57,880 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 22 (show at SparkController.java:162) with 2 output partitions
2023-04-07 16:31:57,880 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 22 (show at SparkController.java:162)
2023-04-07 16:31:57,880 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:57,881 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:57,881 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 22 (MapPartitionsRDD[108] at show at SparkController.java:162), which has no missing parents
2023-04-07 16:31:57,883 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_41 stored as values in memory (estimated size 7.5 KB, free 997.9 MB)
2023-04-07 16:31:57,885 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.9 MB)
2023-04-07 16:31:57,887 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_41_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.3 MB)
2023-04-07 16:31:57,888 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 41 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:57,889 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 22 (MapPartitionsRDD[108] at show at SparkController.java:162) (first 15 tasks are for partitions Vector(1, 2))
2023-04-07 16:31:57,889 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 22.0 with 2 tasks
2023-04-07 16:31:57,890 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 22.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 8295 bytes)
2023-04-07 16:31:57,891 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 1.0 in stage 22.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-07 16:31:57,891 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 23] Running task 0.0 in stage 22.0 (TID 23)
2023-04-07 16:31:57,893 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 24] Running task 1.0 in stage 22.0 (TID 24)
2023-04-07 16:31:57,898 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 24] Finished task 1.0 in stage 22.0 (TID 24). 1112 bytes result sent to driver
2023-04-07 16:31:57,899 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 1.0 in stage 22.0 (TID 24) in 9 ms on localhost (executor driver) (1/2)
2023-04-07 16:31:57,901 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 23] Finished task 0.0 in stage 22.0 (TID 23). 1112 bytes result sent to driver
2023-04-07 16:31:57,903 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 22.0 (TID 23) in 13 ms on localhost (executor driver) (2/2)
2023-04-07 16:31:57,903 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 22.0, whose tasks have all completed, from pool 
2023-04-07 16:31:57,905 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 22 (show at SparkController.java:162) finished in 0.023 s
2023-04-07 16:31:57,906 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 22 finished: show at SparkController.java:162, took 0.026179 s
2023-04-07 16:31:57,909 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Json File
2023-04-07 16:31:58,136 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:170
2023-04-07 16:31:58,139 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 23 (jdbc at SparkController.java:170) with 4 output partitions
2023-04-07 16:31:58,140 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 23 (jdbc at SparkController.java:170)
2023-04-07 16:31:58,140 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:58,140 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:58,141 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 23 (MapPartitionsRDD[114] at jdbc at SparkController.java:170), which has no missing parents
2023-04-07 16:31:58,156 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_42 stored as values in memory (estimated size 13.9 KB, free 997.9 MB)
2023-04-07 16:31:58,158 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_42_piece0 stored as bytes in memory (estimated size 6.8 KB, free 997.9 MB)
2023-04-07 16:31:58,159 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_42_piece0 in memory on 192.168.1.125:46645 (size: 6.8 KB, free: 998.3 MB)
2023-04-07 16:31:58,161 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 42 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:58,163 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[114] at jdbc at SparkController.java:170) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2023-04-07 16:31:58,163 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 23.0 with 4 tasks
2023-04-07 16:31:58,165 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 23.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8696 bytes)
2023-04-07 16:31:58,166 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 1.0 in stage 23.0 (TID 26, localhost, executor driver, partition 1, PROCESS_LOCAL, 8295 bytes)
2023-04-07 16:31:58,168 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 2.0 in stage 23.0 (TID 27, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-07 16:31:58,172 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 3.0 in stage 23.0 (TID 28, localhost, executor driver, partition 3, PROCESS_LOCAL, 8295 bytes)
2023-04-07 16:31:58,173 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 26] Running task 1.0 in stage 23.0 (TID 26)
2023-04-07 16:31:58,173 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 25] Running task 0.0 in stage 23.0 (TID 25)
2023-04-07 16:31:58,182 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 27] Running task 2.0 in stage 23.0 (TID 27)
2023-04-07 16:31:58,183 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 28] Running task 3.0 in stage 23.0 (TID 28)
2023-04-07 16:31:58,923 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 26] Finished task 1.0 in stage 23.0 (TID 26). 1064 bytes result sent to driver
2023-04-07 16:31:58,925 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 1.0 in stage 23.0 (TID 26) in 759 ms on localhost (executor driver) (1/4)
2023-04-07 16:31:59,055 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 28] Finished task 3.0 in stage 23.0 (TID 28). 1064 bytes result sent to driver
2023-04-07 16:31:59,059 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 3.0 in stage 23.0 (TID 28) in 887 ms on localhost (executor driver) (2/4)
2023-04-07 16:31:59,236 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 27] Finished task 2.0 in stage 23.0 (TID 27). 1064 bytes result sent to driver
2023-04-07 16:31:59,236 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 25] Finished task 0.0 in stage 23.0 (TID 25). 1064 bytes result sent to driver
2023-04-07 16:31:59,237 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 2.0 in stage 23.0 (TID 27) in 1070 ms on localhost (executor driver) (3/4)
2023-04-07 16:31:59,238 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 23.0 (TID 25) in 1074 ms on localhost (executor driver) (4/4)
2023-04-07 16:31:59,238 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 23.0, whose tasks have all completed, from pool 
2023-04-07 16:31:59,239 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 23 (jdbc at SparkController.java:170) finished in 1.097 s
2023-04-07 16:31:59,240 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 23 finished: jdbc at SparkController.java:170, took 1.102610 s
2023-04-07 16:31:59,774 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:172
2023-04-07 16:31:59,775 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 24 (show at SparkController.java:172) with 1 output partitions
2023-04-07 16:31:59,775 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 24 (show at SparkController.java:172)
2023-04-07 16:31:59,775 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:59,776 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:59,776 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 24 (MapPartitionsRDD[121] at show at SparkController.java:172), which has no missing parents
2023-04-07 16:31:59,778 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_43 stored as values in memory (estimated size 7.5 KB, free 997.9 MB)
2023-04-07 16:31:59,780 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.9 MB)
2023-04-07 16:31:59,781 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_43_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.3 MB)
2023-04-07 16:31:59,782 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 43 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:59,782 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[121] at show at SparkController.java:172) (first 15 tasks are for partitions Vector(0))
2023-04-07 16:31:59,782 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 24.0 with 1 tasks
2023-04-07 16:31:59,784 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 24.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 8696 bytes)
2023-04-07 16:31:59,785 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 29] Running task 0.0 in stage 24.0 (TID 29)
2023-04-07 16:31:59,790 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 29] Finished task 0.0 in stage 24.0 (TID 29). 1818 bytes result sent to driver
2023-04-07 16:31:59,791 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 24.0 (TID 29) in 8 ms on localhost (executor driver) (1/1)
2023-04-07 16:31:59,792 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 24.0, whose tasks have all completed, from pool 
2023-04-07 16:31:59,792 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 24 (show at SparkController.java:172) finished in 0.015 s
2023-04-07 16:31:59,793 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 24 finished: show at SparkController.java:172, took 0.019054 s
2023-04-07 16:31:59,798 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:172
2023-04-07 16:31:59,799 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 25 (show at SparkController.java:172) with 2 output partitions
2023-04-07 16:31:59,799 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 25 (show at SparkController.java:172)
2023-04-07 16:31:59,799 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-07 16:31:59,799 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-07 16:31:59,801 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 25 (MapPartitionsRDD[121] at show at SparkController.java:172), which has no missing parents
2023-04-07 16:31:59,805 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_44 stored as values in memory (estimated size 7.5 KB, free 997.9 MB)
2023-04-07 16:31:59,807 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.5 KB, free 997.9 MB)
2023-04-07 16:31:59,807 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_44_piece0 in memory on 192.168.1.125:46645 (size: 3.5 KB, free: 998.3 MB)
2023-04-07 16:31:59,808 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 44 from broadcast at DAGScheduler.scala:1163
2023-04-07 16:31:59,808 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 25 (MapPartitionsRDD[121] at show at SparkController.java:172) (first 15 tasks are for partitions Vector(1, 2))
2023-04-07 16:31:59,809 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 25.0 with 2 tasks
2023-04-07 16:31:59,810 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 25.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 8295 bytes)
2023-04-07 16:31:59,810 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 1.0 in stage 25.0 (TID 31, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-07 16:31:59,811 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 30] Running task 0.0 in stage 25.0 (TID 30)
2023-04-07 16:31:59,811 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 31] Running task 1.0 in stage 25.0 (TID 31)
2023-04-07 16:31:59,814 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 30] Finished task 0.0 in stage 25.0 (TID 30). 1112 bytes result sent to driver
2023-04-07 16:31:59,815 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 25.0 (TID 30) in 6 ms on localhost (executor driver) (1/2)
2023-04-07 16:31:59,815 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 31] Finished task 1.0 in stage 25.0 (TID 31). 1112 bytes result sent to driver
2023-04-07 16:31:59,816 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 1.0 in stage 25.0 (TID 31) in 6 ms on localhost (executor driver) (2/2)
2023-04-07 16:31:59,816 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 25.0, whose tasks have all completed, from pool 
2023-04-07 16:31:59,817 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 25 (show at SparkController.java:172) finished in 0.014 s
2023-04-07 16:31:59,818 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 25 finished: show at SparkController.java:172, took 0.019274 s
2023-04-07 16:31:59,821 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Excel File
2023-04-07 16:34:08,847 INFO com.example.spring.jwt.mongodb.entity.FileUploadHelperTest [main] Starting FileUploadHelperTest using Java 17.0.6 on wks-012 with PID 9477 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:34:08,851 INFO com.example.spring.jwt.mongodb.entity.FileUploadHelperTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:34:12,162 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@52d0f583]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:34:12,205 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff8ac6d26da7ab472e694', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:13}] to localhost:27017
2023-04-07 16:34:12,208 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff8ac6d26da7ab472e694', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:14}] to localhost:27017
2023-04-07 16:34:12,209 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff8ac6d26da7ab472e694', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=52952009}
2023-04-07 16:34:13,624 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:34:13,626 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:34:13,750 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:34:14,116 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:34:14,298 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:34:14,394 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:34:14,396 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:34:14,398 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:34:14,400 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:34:14,402 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:34:15,074 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 37377.
2023-04-07 16:34:15,125 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:34:15,154 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:34:15,159 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:34:15,160 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:34:15,179 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-8d724da6-fc26-43fd-b5d1-23e09723b77f
2023-04-07 16:34:15,210 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:34:15,234 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:34:15,340 INFO org.spark_project.jetty.util.log [main] Logging initialized @9654ms
2023-04-07 16:34:15,410 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:34:15,433 INFO org.spark_project.jetty.server.Server [main] Started @9749ms
2023-04-07 16:34:15,453 WARN org.apache.spark.util.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2023-04-07 16:34:15,463 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@1041ebba{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:34:15,464 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4041.
2023-04-07 16:34:15,495 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@632dc41{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,497 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c23e369{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,499 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@38445703{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,502 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58b5d5fc{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,503 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@42536da6{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,505 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7591cbd1{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,506 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5cdc8499{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,509 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f3aa970{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,511 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5213b887{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,512 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@40c6d1ef{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,515 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f4029e9{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,517 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@257b6c58{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,519 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6ae32ff0{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,522 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c5cd2ea{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,524 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@72bdbfe9{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,527 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@cda144a{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,529 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7fb5368e{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,531 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5847010{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,533 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1ad9d5be{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,535 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@46fdfaeb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,546 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@102aa5fc{/static,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,548 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@74844216{/,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,550 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5b0575d0{/api,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,552 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@446f3a53{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,554 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4c3fcbe7{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:34:15,558 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4041
2023-04-07 16:34:15,701 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:34:15,878 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33959.
2023-04-07 16:34:15,879 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:33959
2023-04-07 16:34:15,883 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:34:15,927 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 33959, None)
2023-04-07 16:34:15,932 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:33959 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 33959, None)
2023-04-07 16:34:15,937 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 33959, None)
2023-04-07 16:34:15,939 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 33959, None)
2023-04-07 16:34:15,959 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@97cb8dc{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:34:28,141 INFO com.example.spring.jwt.mongodb.entity.FileUploadHelperTest [main] Started FileUploadHelperTest in 19.915 seconds (JVM running for 22.457)
2023-04-07 16:34:29,903 INFO org.apache.spark.storage.DiskBlockManager [Thread-2] Shutdown hook called
2023-04-07 16:34:29,960 INFO org.spark_project.jetty.server.AbstractConnector [SpringApplicationShutdownHook] Stopped Spark@1041ebba{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:34:29,994 INFO org.apache.spark.ui.SparkUI [SpringApplicationShutdownHook] Stopped Spark web UI at http://192.168.1.125:4041
2023-04-07 16:34:30,453 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Shutdown hook called
2023-04-07 16:34:30,568 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-67700d49-d018-4582-94f3-728cc32adfb4/userFiles-7f1fe618-b570-4561-8c27-90809828ed1c
2023-04-07 16:34:30,574 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-67700d49-d018-4582-94f3-728cc32adfb4
2023-04-07 16:34:30,594 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:34:30,651 INFO org.apache.spark.storage.memory.MemoryStore [SpringApplicationShutdownHook] MemoryStore cleared
2023-04-07 16:34:30,655 INFO org.apache.spark.storage.BlockManager [SpringApplicationShutdownHook] BlockManager stopped
2023-04-07 16:34:30,749 INFO org.apache.spark.storage.BlockManagerMaster [SpringApplicationShutdownHook] BlockManagerMaster stopped
2023-04-07 16:34:30,815 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-07 16:34:30,832 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] Successfully stopped SparkContext
2023-04-07 16:34:30,835 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:39:36,319 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Starting EmailControllerTest using Java 17.0.6 on wks-012 with PID 10014 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:39:36,323 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:39:41,463 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@193eb1ba]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:39:41,527 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ff9f53fc48737a7ad4f88', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:15}] to localhost:27017
2023-04-07 16:39:41,527 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ff9f53fc48737a7ad4f88', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:16}] to localhost:27017
2023-04-07 16:39:41,529 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ff9f53fc48737a7ad4f88', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=73678108}
2023-04-07 16:39:43,810 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:39:43,811 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:39:44,230 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:39:45,040 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:39:45,619 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:39:46,007 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:39:46,009 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:39:46,022 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:39:46,023 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:39:46,025 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:39:47,018 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 37501.
2023-04-07 16:39:47,177 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:39:47,346 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:39:47,363 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:39:47,365 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:39:47,424 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-a0ce2ebf-16d4-47cb-ad55-7b095265d8d8
2023-04-07 16:39:47,515 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:39:47,570 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:39:47,813 INFO org.spark_project.jetty.util.log [main] Logging initialized @16291ms
2023-04-07 16:39:48,031 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:39:48,054 INFO org.spark_project.jetty.server.Server [main] Started @16535ms
2023-04-07 16:39:48,073 WARN org.apache.spark.util.Utils [main] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2023-04-07 16:39:48,080 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@35f6f105{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:39:48,081 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4041.
2023-04-07 16:39:48,110 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5847010{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,112 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4c3fcbe7{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,114 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1e592ef2{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,117 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6bf77ee{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,119 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@51c6e775{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,121 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@372841d2{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,123 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c8d638a{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,125 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@17034458{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,127 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3e0e0ba7{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,129 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7df5549e{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,130 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@cbdc0f4{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,132 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@11174bf{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,134 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4f0c1409{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,136 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@188ae8d2{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,142 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a522157{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,144 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@706c062e{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,146 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5feff876{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,148 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@10ec4721{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,150 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7bdf94f2{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,152 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6b92a0d1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,162 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4b9ed99d{/static,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,164 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1ca0aa40{/,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,167 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@626766fd{/api,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,169 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@301770d9{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,171 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@40edc64e{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:39:48,189 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4041
2023-04-07 16:39:49,451 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:39:49,788 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41853.
2023-04-07 16:39:49,789 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:41853
2023-04-07 16:39:49,791 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:39:49,874 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 41853, None)
2023-04-07 16:39:49,879 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:41853 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 41853, None)
2023-04-07 16:39:49,898 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 41853, None)
2023-04-07 16:39:49,899 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 41853, None)
2023-04-07 16:39:50,054 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@59c00010{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:40:02,536 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Started EmailControllerTest in 27.303 seconds (JVM running for 31.016)
2023-04-07 16:40:04,787 INFO org.apache.spark.storage.DiskBlockManager [Thread-2] Shutdown hook called
2023-04-07 16:40:04,976 INFO org.spark_project.jetty.server.AbstractConnector [SpringApplicationShutdownHook] Stopped Spark@35f6f105{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-07 16:40:04,999 INFO org.apache.spark.ui.SparkUI [SpringApplicationShutdownHook] Stopped Spark web UI at http://192.168.1.125:4041
2023-04-07 16:40:05,620 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Shutdown hook called
2023-04-07 16:40:05,918 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-f2a04429-8e6b-41d3-a9ee-5dd8cedab74a/userFiles-a19acdfd-ead3-49b5-9427-61c7a7bdf749
2023-04-07 16:40:06,265 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-f2a04429-8e6b-41d3-a9ee-5dd8cedab74a
2023-04-07 16:40:06,287 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-0] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:40:06,478 INFO org.apache.spark.storage.memory.MemoryStore [SpringApplicationShutdownHook] MemoryStore cleared
2023-04-07 16:40:06,479 INFO org.apache.spark.storage.BlockManager [SpringApplicationShutdownHook] BlockManager stopped
2023-04-07 16:40:06,532 INFO org.apache.spark.storage.BlockManagerMaster [SpringApplicationShutdownHook] BlockManagerMaster stopped
2023-04-07 16:40:06,820 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-07 16:40:14,938 WARN org.apache.spark.executor.Executor [driver-heartbeater] Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10000 milliseconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:846)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:875)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:875)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:875)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:875)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10000 milliseconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:223)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:227)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 13 common frames omitted
2023-04-07 16:40:14,964 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] Successfully stopped SparkContext
2023-04-07 16:40:14,974 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:54:17,123 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(34)-127.0.0.1] Stopping service [Tomcat]
2023-04-07 16:54:17,136 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(34)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-07 16:54:17,196 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:54:17,198 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='642ff7dea3386059e913bfa0', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:54:17,198 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='642ff7dea3386059e913bfa0', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:54:17,199 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:54:17,200 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [spark-listener-group-streams] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3463)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3434)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1623)
 java.base@17.0.6/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:97)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
 app//org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
 app//org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1302)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
2023-04-07 16:54:17,200 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(34)-127.0.0.1] The web application [ROOT] appears to have started a thread named [org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Object.wait(Native Method)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
 app//org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:2989)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 16:54:17,277 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 16:54:17,297 INFO org.apache.spark.SparkContext [Thread-2] SparkContext already stopped.
2023-04-07 16:54:17,346 INFO org.apache.spark.storage.DiskBlockManager [Thread-2] Shutdown hook called
2023-04-07 16:54:17,457 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(34)-127.0.0.1] Stopped Spark@411933{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:54:17,492 INFO org.apache.spark.ui.SparkUI [RMI TCP Connection(34)-127.0.0.1] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 16:54:17,657 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:54:17,790 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Shutdown hook called
2023-04-07 16:54:17,816 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-61cb814b-1994-46bb-86ef-7d8dc24cc29a
2023-04-07 16:54:17,816 INFO org.apache.spark.storage.memory.MemoryStore [RMI TCP Connection(34)-127.0.0.1] MemoryStore cleared
2023-04-07 16:54:17,820 INFO org.apache.spark.storage.BlockManager [RMI TCP Connection(34)-127.0.0.1] BlockManager stopped
2023-04-07 16:54:17,821 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-61cb814b-1994-46bb-86ef-7d8dc24cc29a/userFiles-866fd7cd-02a9-4a13-9411-5fc69f74d1b4
2023-04-07 16:54:17,836 INFO org.apache.spark.storage.BlockManagerMaster [RMI TCP Connection(34)-127.0.0.1] BlockManagerMaster stopped
2023-04-07 16:54:17,865 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-07 16:54:17,874 INFO org.apache.spark.SparkContext [RMI TCP Connection(34)-127.0.0.1] Successfully stopped SparkContext
2023-04-07 16:54:17,875 INFO org.apache.spark.SparkContext [RMI TCP Connection(34)-127.0.0.1] SparkContext already stopped.
2023-04-07 16:54:37,648 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Starting EmailControllerTest using Java 17.0.6 on wks-012 with PID 10876 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:54:37,652 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:54:42,894 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1320e68a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:54:43,167 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ffd7a255d42125338857b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:17}] to localhost:27017
2023-04-07 16:54:43,169 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ffd7a255d42125338857b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:18}] to localhost:27017
2023-04-07 16:54:43,170 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ffd7a255d42125338857b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=219523363}
2023-04-07 16:54:45,737 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:54:45,740 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:54:46,135 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:54:46,994 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:54:47,618 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:54:48,053 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:54:48,056 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:54:48,067 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:54:48,069 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:54:48,077 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:54:49,119 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 34763.
2023-04-07 16:54:49,295 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:54:49,413 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:54:49,431 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:54:49,433 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:54:49,472 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-f98d0e55-50be-49a5-bd6a-8045299fff41
2023-04-07 16:54:49,554 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:54:49,614 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:54:49,908 INFO org.spark_project.jetty.util.log [main] Logging initialized @18629ms
2023-04-07 16:54:50,130 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:54:50,156 INFO org.spark_project.jetty.server.Server [main] Started @18878ms
2023-04-07 16:54:50,191 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@7b54a0a4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:54:50,192 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 16:54:50,222 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@8e3449e{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,224 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@144dc2f7{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,226 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@403cff1c{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,229 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@71f4aeb6{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,231 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@56976b8b{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,233 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@74844216{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,235 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5b0575d0{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,238 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4c3fcbe7{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,240 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1e592ef2{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,242 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@96dfcbb{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,244 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@34ede267{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,246 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6bf77ee{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,248 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@51c6e775{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,250 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@372841d2{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,252 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c8d638a{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,270 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@117069f2{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,272 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@77ebc9e6{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,274 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2b82018{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,277 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52e92f6{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,279 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@17034458{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,293 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3e0e0ba7{/static,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,296 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3ccefe1b{/,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,299 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@a926db4{/api,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,301 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2842ef02{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,304 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7e63374b{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:54:50,322 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 16:54:50,639 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:54:50,845 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38157.
2023-04-07 16:54:50,854 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:38157
2023-04-07 16:54:50,857 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:54:50,912 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 38157, None)
2023-04-07 16:54:50,916 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:38157 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 38157, None)
2023-04-07 16:54:50,920 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 38157, None)
2023-04-07 16:54:50,922 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 38157, None)
2023-04-07 16:54:50,978 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a094f90{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:54:58,546 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Started EmailControllerTest in 22.128 seconds (JVM running for 27.268)
2023-04-07 16:54:59,613 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 16:54:59,629 INFO org.spark_project.jetty.server.AbstractConnector [Thread-2] Stopped Spark@7b54a0a4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:54:59,632 INFO org.apache.spark.ui.SparkUI [Thread-2] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 16:54:59,640 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:54:59,645 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:54:59,650 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 16:56:48,891 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Starting EmailControllerTest using Java 17.0.6 on wks-012 with PID 11169 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:56:48,896 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:56:52,425 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@23e3f5cd]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:56:52,496 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ffdfce044f2248e20fdef', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:19}] to localhost:27017
2023-04-07 16:56:52,497 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ffdfce044f2248e20fdef', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=79749951}
2023-04-07 16:56:52,501 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ffdfce044f2248e20fdef', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:20}] to localhost:27017
2023-04-07 16:56:54,299 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:56:54,301 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:56:54,455 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 16:56:54,942 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 16:56:55,180 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 16:56:55,312 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 16:56:55,317 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 16:56:55,321 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 16:56:55,325 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 16:56:55,328 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 16:56:56,008 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 40005.
2023-04-07 16:56:56,067 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 16:56:56,107 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 16:56:56,114 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 16:56:56,116 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 16:56:56,140 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-273abafe-79e2-4905-bfc4-0ed3292d2084
2023-04-07 16:56:56,192 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 16:56:56,227 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 16:56:56,408 INFO org.spark_project.jetty.util.log [main] Logging initialized @10817ms
2023-04-07 16:56:56,518 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 16:56:56,548 INFO org.spark_project.jetty.server.Server [main] Started @10960ms
2023-04-07 16:56:56,577 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@7b7ad2b8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:56:56,579 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 16:56:56,622 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58486deb{/jobs,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,626 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c5cd2ea{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,631 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@72bdbfe9{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,637 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5847010{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,642 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1ad9d5be{/stages,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,644 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@46fdfaeb{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,647 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@102aa5fc{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,652 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a0f43dc{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,654 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58a7ca42{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,659 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4f9980e1{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,663 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f6e6f50{/storage,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,666 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f7fcec2{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,673 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@796cf2b5{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,675 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a71ebf1{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,677 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@16890f00{/environment,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,681 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@77e1dacd{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,685 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@690677de{/executors,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,690 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c5d376c{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,694 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@42f2cae8{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,700 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3bbc47c9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,714 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@615e7fe7{/static,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,716 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@17034458{/,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,722 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3e0e0ba7{/api,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,724 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4f0c1409{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,727 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@188ae8d2{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 16:56:56,732 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 16:56:56,982 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 16:56:57,224 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36061.
2023-04-07 16:56:57,226 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:36061
2023-04-07 16:56:57,229 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 16:56:57,272 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 36061, None)
2023-04-07 16:56:57,278 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:36061 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 36061, None)
2023-04-07 16:56:57,286 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 36061, None)
2023-04-07 16:56:57,288 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 36061, None)
2023-04-07 16:56:57,310 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6fd2acf5{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 16:57:07,421 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Started EmailControllerTest in 19.159 seconds (JVM running for 21.833)
2023-04-07 16:57:17,197 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 16:57:17,205 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:57:17,206 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 16:57:17,218 INFO org.spark_project.jetty.server.AbstractConnector [Thread-2] Stopped Spark@7b7ad2b8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 16:59:53,762 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Starting EmailControllerTest using Java 17.0.6 on wks-012 with PID 11482 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 16:59:53,773 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 16:59:57,570 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@71560f51]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 16:59:57,615 INFO org.mongodb.driver.connection [cluster-ClusterId{value='642ffeb52b9809147f766f98', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:22}] to localhost:27017
2023-04-07 16:59:57,616 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='642ffeb52b9809147f766f98', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=49472721}
2023-04-07 16:59:57,616 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='642ffeb52b9809147f766f98', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:21}] to localhost:27017
2023-04-07 16:59:59,444 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 16:59:59,447 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 16:59:59,664 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 17:00:00,178 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 17:00:00,443 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 17:00:00,569 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 17:00:00,576 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 17:00:00,583 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 17:00:00,586 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 17:00:00,588 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 17:00:01,262 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 46559.
2023-04-07 17:00:01,300 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 17:00:01,335 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 17:00:01,342 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 17:00:01,343 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 17:00:01,366 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-b00298e3-763f-475f-b135-713d85c52da1
2023-04-07 17:00:01,416 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 17:00:01,451 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 17:00:01,587 INFO org.spark_project.jetty.util.log [main] Logging initialized @11794ms
2023-04-07 17:00:01,700 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 17:00:01,740 INFO org.spark_project.jetty.server.Server [main] Started @11949ms
2023-04-07 17:00:01,777 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@27fc5b3d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 17:00:01,780 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 17:00:01,831 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@d70dbeb{/jobs,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,835 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f3aa970{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,843 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5213b887{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,849 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@257b6c58{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,855 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6ae32ff0{/stages,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,858 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1c5cd2ea{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,869 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@72bdbfe9{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,875 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@46fdfaeb{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,879 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@102aa5fc{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,886 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@36885319{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,889 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@62a81453{/storage,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,892 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4bab804f{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,894 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@eebd983{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,897 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a0f43dc{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,906 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58a7ca42{/environment,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,909 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4f9980e1{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,915 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f6e6f50{/executors,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,922 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1f7fcec2{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,926 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@796cf2b5{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,938 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7a71ebf1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,956 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@16890f00{/static,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,958 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@372841d2{/,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,963 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6c8d638a{/api,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,966 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52e92f6{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,969 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@17034458{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 17:00:01,975 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 17:00:02,201 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 17:00:02,410 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36657.
2023-04-07 17:00:02,414 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:36657
2023-04-07 17:00:02,419 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 17:00:02,470 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 36657, None)
2023-04-07 17:00:02,478 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-3] Registering block manager 192.168.1.125:36657 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 36657, None)
2023-04-07 17:00:02,483 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 36657, None)
2023-04-07 17:00:02,486 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 36657, None)
2023-04-07 17:00:02,517 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4d71ec5b{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 17:00:09,774 INFO com.example.spring.jwt.mongodb.controllers.EmailControllerTest [main] Started EmailControllerTest in 17.093 seconds (JVM running for 19.983)
2023-04-07 17:00:19,275 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 17:00:19,283 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 17:00:19,287 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 17:00:19,303 INFO org.spark_project.jetty.server.AbstractConnector [Thread-2] Stopped Spark@27fc5b3d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 17:00:19,309 INFO org.apache.spark.ui.SparkUI [Thread-2] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 17:23:05,990 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] Starting MailControllerTest using Java 17.0.6 on wks-012 with PID 13362 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 17:23:06,021 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 17:23:12,824 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@699d96bc]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 17:23:12,970 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6430042826f98b564c24aad7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:24}] to localhost:27017
2023-04-07 17:23:12,984 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6430042826f98b564c24aad7', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=156963836}
2023-04-07 17:23:12,988 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6430042826f98b564c24aad7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:23}] to localhost:27017
2023-04-07 17:23:16,617 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 17:23:16,620 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 17:23:17,095 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 17:23:18,069 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 17:23:18,723 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 17:23:19,158 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 17:23:19,160 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 17:23:19,173 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 17:23:19,176 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 17:23:19,178 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 17:23:20,292 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 43287.
2023-04-07 17:23:20,500 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 17:23:20,702 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 17:23:20,771 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 17:23:20,773 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 17:23:20,926 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-82fac68e-0ab5-4bc6-96b2-989282e4f7e1
2023-04-07 17:23:21,016 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 17:23:21,455 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 17:23:22,262 INFO org.spark_project.jetty.util.log [main] Logging initialized @23089ms
2023-04-07 17:23:22,516 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 17:23:22,547 INFO org.spark_project.jetty.server.Server [main] Started @23375ms
2023-04-07 17:23:22,694 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@1f86f7da{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 17:23:22,695 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 17:23:22,725 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6560f387{/jobs,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,728 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@8a11a19{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,730 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@47393345{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,733 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2bf45b7c{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,735 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2559f65c{/stages,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,737 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@490704a5{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,739 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4d682397{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,742 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@62ec4146{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,745 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@362e709e{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,747 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@b0c4905{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,750 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d3a2459{/storage,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,752 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d5cbcc9{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,754 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3833897c{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,757 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@519eab1e{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,759 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d2a4598{/environment,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,761 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@65880400{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,764 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@415419a4{/executors,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,769 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@65b69ccb{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,771 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a9f0360{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,774 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f12b637{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,790 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@eea0b48{/static,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,793 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@65b7678a{/,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,803 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7699e60a{/api,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,806 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@148f94dc{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,808 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2f11d889{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 17:23:22,830 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 17:23:23,136 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 17:23:23,331 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33399.
2023-04-07 17:23:23,340 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:33399
2023-04-07 17:23:23,343 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 17:23:23,420 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 33399, None)
2023-04-07 17:23:23,426 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:33399 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 33399, None)
2023-04-07 17:23:23,464 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 33399, None)
2023-04-07 17:23:23,466 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 33399, None)
2023-04-07 17:23:23,543 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3615f8d9{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 17:23:30,892 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] Started MailControllerTest in 26.532 seconds (JVM running for 31.72)
2023-04-07 17:23:31,068 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [main] Unauthorized error: Full authentication is required to access this resource
2023-04-07 17:23:31,213 INFO org.apache.spark.storage.DiskBlockManager [Thread-3] Shutdown hook called
2023-04-07 17:23:31,270 INFO org.spark_project.jetty.server.AbstractConnector [SpringApplicationShutdownHook] Stopped Spark@1f86f7da{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 17:23:31,282 INFO org.apache.spark.ui.SparkUI [SpringApplicationShutdownHook] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 17:23:31,344 INFO org.apache.spark.util.ShutdownHookManager [Thread-3] Shutdown hook called
2023-04-07 17:23:31,346 INFO org.apache.spark.util.ShutdownHookManager [Thread-3] Deleting directory /tmp/spark-afb73c0e-cbd1-476b-a23f-549ecf1143ab
2023-04-07 17:23:31,366 INFO org.apache.spark.util.ShutdownHookManager [Thread-3] Deleting directory /tmp/spark-afb73c0e-cbd1-476b-a23f-549ecf1143ab/userFiles-a24aaf3a-f9ac-4233-a359-0d0ba32a02e6
2023-04-07 17:23:31,449 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 17:23:31,458 INFO org.apache.spark.storage.memory.MemoryStore [SpringApplicationShutdownHook] MemoryStore cleared
2023-04-07 17:23:31,479 INFO org.apache.spark.storage.BlockManager [SpringApplicationShutdownHook] BlockManager stopped
2023-04-07 17:23:31,496 INFO org.apache.spark.storage.BlockManagerMaster [SpringApplicationShutdownHook] BlockManagerMaster stopped
2023-04-07 17:23:31,522 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-07 17:23:31,534 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] Successfully stopped SparkContext
2023-04-07 17:23:31,536 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 17:28:37,766 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] Starting MailControllerTest using Java 17.0.6 on wks-012 with PID 13995 (started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 17:28:37,805 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 17:28:45,836 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@69ce14e6]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 17:28:46,088 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643005756c281b50cbbeefa2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:25}] to localhost:27017
2023-04-07 17:28:46,090 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643005756c281b50cbbeefa2', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:26}] to localhost:27017
2023-04-07 17:28:46,090 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643005756c281b50cbbeefa2', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=237390862}
2023-04-07 17:28:47,610 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 17:28:47,612 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 17:28:47,821 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 17:28:48,504 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 17:28:48,873 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 17:28:49,226 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 17:28:49,228 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 17:28:49,230 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 17:28:49,244 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 17:28:49,246 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 17:28:50,064 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 46271.
2023-04-07 17:28:50,215 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 17:28:50,295 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 17:28:50,307 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 17:28:50,309 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 17:28:50,340 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-c605268f-a0e9-4bce-bee7-e24e3acc46f4
2023-04-07 17:28:50,396 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 17:28:50,423 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 17:28:50,597 INFO org.spark_project.jetty.util.log [main] Logging initialized @20507ms
2023-04-07 17:28:50,705 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 17:28:50,733 INFO org.spark_project.jetty.server.Server [main] Started @20645ms
2023-04-07 17:28:50,760 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@280bcfb6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 17:28:50,761 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 17:28:50,795 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3f5f79d8{/jobs,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,797 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2b85edc7{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,799 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2bf45b7c{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,802 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4d682397{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,804 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@444ebefd{/stages,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,806 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2ecf4b3e{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,808 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5f1c406e{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,811 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d3a2459{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,814 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d5cbcc9{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,816 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3833897c{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,819 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@519eab1e{/storage,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,821 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d2a4598{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,824 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@65880400{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,826 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@415419a4{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,828 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@65b69ccb{/environment,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,831 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4a9f0360{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,835 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f12b637{/executors,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,838 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@eea0b48{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,841 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5feb8e9a{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,843 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6d5d1204{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,858 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1784a296{/static,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,861 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@734a2c17{/,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,864 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2d1f9ec3{/api,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,867 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5ca10d0e{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,870 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@34604b32{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 17:28:50,884 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 17:28:51,085 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 17:28:51,247 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43381.
2023-04-07 17:28:51,266 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:43381
2023-04-07 17:28:51,270 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 17:28:51,368 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 43381, None)
2023-04-07 17:28:51,374 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:43381 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 43381, None)
2023-04-07 17:28:51,378 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 43381, None)
2023-04-07 17:28:51,380 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 43381, None)
2023-04-07 17:28:51,430 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@57f6fc09{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 17:29:00,653 INFO com.example.spring.jwt.mongodb.controllers.MailControllerTest [main] Started MailControllerTest in 23.962 seconds (JVM running for 30.565)
2023-04-07 17:29:01,257 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [main] Unauthorized error: Full authentication is required to access this resource
2023-04-07 17:29:01,605 INFO org.apache.spark.SparkContext [Thread-3] Invoking stop() from shutdown hook
2023-04-07 17:29:01,622 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 17:29:01,622 INFO org.apache.spark.SparkContext [SpringApplicationShutdownHook] SparkContext already stopped.
2023-04-07 18:21:20,593 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 16057 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 18:21:20,626 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 18:21:24,805 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 18:21:24,806 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 18:21:25,032 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 18:21:25,306 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5ec88f9e]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 18:21:25,337 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643011cd50f1126785aa3db8', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:28}] to localhost:27017
2023-04-07 18:21:25,337 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643011cd50f1126785aa3db8', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:27}] to localhost:27017
2023-04-07 18:21:25,339 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643011cd50f1126785aa3db8', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=30621969}
2023-04-07 18:21:27,629 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 18:21:27,631 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 18:21:27,917 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 18:21:28,648 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 18:21:29,164 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 18:21:29,594 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 18:21:29,596 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 18:21:29,609 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 18:21:29,610 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 18:21:29,611 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 18:21:30,549 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 36183.
2023-04-07 18:21:30,758 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 18:21:30,980 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 18:21:30,996 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 18:21:30,997 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 18:21:31,053 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-a8f330b2-b391-4e07-b83a-f87d85e9242d
2023-04-07 18:21:31,142 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 18:21:31,223 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 18:21:31,576 INFO org.spark_project.jetty.util.log [main] Logging initialized @13746ms
2023-04-07 18:21:31,729 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 18:21:31,752 INFO org.spark_project.jetty.server.Server [main] Started @13923ms
2023-04-07 18:21:31,796 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@71e409f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 18:21:31,797 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 18:21:31,818 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@169d1f92{/jobs,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,820 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@75fa9254{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,821 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@6f25ed2b{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,823 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3539cf45{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,824 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7535307c{/stages,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,825 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@556a6320{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,826 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@45375bdf{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,828 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5af641d3{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,830 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@14e83c9d{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,831 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@744db9fb{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,833 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@59043741{/storage,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,834 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@31940d6b{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,835 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@64cdc310{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,836 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@7d563c13{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,838 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@510a2c7{/environment,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,839 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@14fe085b{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,841 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1ea19c97{/executors,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,843 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@525b9df4{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,845 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@52dd1be2{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,846 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@36857d32{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,854 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@24520a51{/static,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,856 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73a1a1b4{/,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,858 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@669daa93{/api,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,859 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@129aaac1{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,860 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3370be55{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 18:21:31,875 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 18:21:32,126 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 18:21:32,199 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46745.
2023-04-07 18:21:32,209 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:46745
2023-04-07 18:21:32,211 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 18:21:32,266 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 46745, None)
2023-04-07 18:21:32,270 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:46745 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 46745, None)
2023-04-07 18:21:32,287 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 46745, None)
2023-04-07 18:21:32,288 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 46745, None)
2023-04-07 18:21:32,354 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2d114d27{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 18:21:42,361 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 22.86 seconds (JVM running for 24.532)
2023-04-07 18:21:42,366 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-07 18:21:42,366 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-07 18:21:43,847 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-07 18:21:45,746 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 485 ms
2023-04-07 18:23:00,899 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-3] Unauthorized error: Full authentication is required to access this resource
2023-04-07 18:23:46,004 INFO org.mongodb.driver.connection [http-nio-8080-exec-2] Opened connection [connectionId{localValue:3, serverValue:29}] to localhost:27017
2023-04-07 18:24:03,552 INFO com.example.spring.jwt.mongodb.controllers.MailController [http-nio-8080-exec-4] Entering Method sendEmail
2023-04-07 18:24:03,554 INFO com.example.spring.jwt.mongodb.controllers.MailController [http-nio-8080-exec-4] Retrieved mail details
2023-04-07 18:24:03,555 INFO com.example.spring.jwt.mongodb.controllers.MailController [http-nio-8080-exec-4] send mail to : shital.shivajipoly@gmail.com 
2023-04-07 18:24:08,059 INFO com.example.spring.jwt.mongodb.controllers.MailController [http-nio-8080-exec-4] Mail sent successfully
2023-04-07 18:36:55,409 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(26)-127.0.0.1] Stopping service [Tomcat]
2023-04-07 18:36:55,424 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(26)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-07 18:36:55,474 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(26)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 18:36:55,476 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(26)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='643011cd50f1126785aa3db8', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 18:36:55,477 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(26)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='643011cd50f1126785aa3db8', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 18:36:55,478 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(26)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-07 18:36:55,506 INFO org.apache.spark.SparkContext [Thread-2] Invoking stop() from shutdown hook
2023-04-07 18:36:55,507 INFO org.apache.spark.SparkContext [Thread-2] SparkContext already stopped.
2023-04-07 18:36:55,514 INFO org.apache.spark.storage.DiskBlockManager [Thread-2] Shutdown hook called
2023-04-07 18:36:55,648 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(26)-127.0.0.1] Stopped Spark@71e409f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 18:36:55,682 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Shutdown hook called
2023-04-07 18:36:55,682 INFO org.apache.spark.ui.SparkUI [RMI TCP Connection(26)-127.0.0.1] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-07 18:36:55,684 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-d18457c3-9247-4a33-997e-351153b36c2b
2023-04-07 18:36:55,688 INFO org.apache.spark.util.ShutdownHookManager [Thread-2] Deleting directory /tmp/spark-d18457c3-9247-4a33-997e-351153b36c2b/userFiles-c3a838e9-e340-4934-a324-c1c26a3e1f90
2023-04-07 18:36:55,815 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-07 18:36:55,828 INFO org.apache.spark.storage.memory.MemoryStore [RMI TCP Connection(26)-127.0.0.1] MemoryStore cleared
2023-04-07 18:36:55,829 INFO org.apache.spark.storage.BlockManager [RMI TCP Connection(26)-127.0.0.1] BlockManager stopped
2023-04-07 18:36:55,831 INFO org.apache.spark.storage.BlockManagerMaster [RMI TCP Connection(26)-127.0.0.1] BlockManagerMaster stopped
2023-04-07 18:36:55,859 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-07 18:36:55,865 INFO org.apache.spark.SparkContext [RMI TCP Connection(26)-127.0.0.1] Successfully stopped SparkContext
2023-04-07 18:36:55,866 INFO org.apache.spark.SparkContext [RMI TCP Connection(26)-127.0.0.1] SparkContext already stopped.
2023-04-07 19:04:44,026 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 17518 (/home/inferyx/git/SpringApplicationWithSecurity/Spring/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity/Spring)
2023-04-07 19:04:44,057 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] No active profile set, falling back to 1 default profile: "default"
2023-04-07 19:04:47,992 INFO org.apache.catalina.core.StandardService [main] Starting service [Tomcat]
2023-04-07 19:04:47,993 INFO org.apache.catalina.core.StandardEngine [main] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-07 19:04:48,250 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [main] Initializing Spring embedded WebApplicationContext
2023-04-07 19:04:48,595 INFO org.mongodb.driver.client [main] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@11c88cca]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-07 19:04:48,753 INFO org.mongodb.driver.connection [cluster-ClusterId{value='64301bf810804a2752d061d7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:30}] to localhost:27017
2023-04-07 19:04:48,754 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='64301bf810804a2752d061d7', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=138455012}
2023-04-07 19:04:48,755 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='64301bf810804a2752d061d7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:31}] to localhost:27017
2023-04-07 19:04:50,951 WARN org.apache.spark.util.Utils [main] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-07 19:04:50,953 WARN org.apache.spark.util.Utils [main] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-07 19:04:51,616 INFO org.apache.spark.SparkContext [main] Running Spark version 2.4.5
2023-04-07 19:04:52,459 WARN org.apache.hadoop.util.NativeCodeLoader [main] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-07 19:04:53,058 INFO org.apache.spark.SparkContext [main] Submitted application: MyAppName
2023-04-07 19:04:53,548 INFO org.apache.spark.SecurityManager [main] Changing view acls to: inferyx
2023-04-07 19:04:53,550 INFO org.apache.spark.SecurityManager [main] Changing modify acls to: inferyx
2023-04-07 19:04:53,563 INFO org.apache.spark.SecurityManager [main] Changing view acls groups to: 
2023-04-07 19:04:53,565 INFO org.apache.spark.SecurityManager [main] Changing modify acls groups to: 
2023-04-07 19:04:53,566 INFO org.apache.spark.SecurityManager [main] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-07 19:04:54,673 INFO org.apache.spark.util.Utils [main] Successfully started service 'sparkDriver' on port 33355.
2023-04-07 19:04:54,880 INFO org.apache.spark.SparkEnv [main] Registering MapOutputTracker
2023-04-07 19:04:55,891 INFO org.apache.spark.SparkEnv [main] Registering BlockManagerMaster
2023-04-07 19:04:55,951 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-07 19:04:55,955 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [main] BlockManagerMasterEndpoint up
2023-04-07 19:04:56,116 INFO org.apache.spark.storage.DiskBlockManager [main] Created local directory at /tmp/blockmgr-6e272d52-7975-4ae3-9dfe-95c44d47f634
2023-04-07 19:04:56,298 INFO org.apache.spark.storage.memory.MemoryStore [main] MemoryStore started with capacity 998.4 MB
2023-04-07 19:04:56,411 INFO org.apache.spark.SparkEnv [main] Registering OutputCommitCoordinator
2023-04-07 19:04:56,743 INFO org.spark_project.jetty.util.log [main] Logging initialized @15161ms
2023-04-07 19:04:56,950 INFO org.spark_project.jetty.server.Server [main] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-07 19:04:56,969 INFO org.spark_project.jetty.server.Server [main] Started @15389ms
2023-04-07 19:04:56,998 INFO org.spark_project.jetty.server.AbstractConnector [main] Started ServerConnector@4ab11426{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-07 19:04:56,999 INFO org.apache.spark.util.Utils [main] Successfully started service 'SparkUI' on port 4040.
2023-04-07 19:04:57,036 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@147097ad{/jobs,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,038 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@530df3ab{/jobs/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,040 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@5e72c82a{/jobs/job,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,042 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58d79479{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,045 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@102c24d1{/stages,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,047 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@495f7ca4{/stages/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,049 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@700202fa{/stages/stage,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,052 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3225d950{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,054 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1be427b4{/stages/pool,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,056 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@470a446f{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,058 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@55315a00{/storage,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,059 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@4942e6af{/storage/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,061 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@73a1a1b4{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,063 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@669daa93{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,065 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@39a30d1a{/environment,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,067 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@670ae31f{/environment/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,069 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@1958524b{/executors,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,071 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@129aaac1{/executors/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,073 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3370be55{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,075 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@3d2b13f{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,084 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@58c36104{/static,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,086 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@35d3202b{/,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,088 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2dfd157b{/api,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,090 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@2fc435e9{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,091 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@bf18412{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-07 19:04:57,109 INFO org.apache.spark.ui.SparkUI [main] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-07 19:04:57,471 INFO org.apache.spark.executor.Executor [main] Starting executor ID driver on host localhost
2023-04-07 19:04:57,531 INFO org.apache.spark.util.Utils [main] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35005.
2023-04-07 19:04:57,541 INFO org.apache.spark.network.netty.NettyBlockTransferService [main] Server created on 192.168.1.125:35005
2023-04-07 19:04:57,543 INFO org.apache.spark.storage.BlockManager [main] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-07 19:04:57,599 INFO org.apache.spark.storage.BlockManagerMaster [main] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 35005, None)
2023-04-07 19:04:57,603 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:35005 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 35005, None)
2023-04-07 19:04:57,620 INFO org.apache.spark.storage.BlockManagerMaster [main] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 35005, None)
2023-04-07 19:04:57,622 INFO org.apache.spark.storage.BlockManager [main] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 35005, None)
2023-04-07 19:04:57,698 INFO org.spark_project.jetty.server.handler.ContextHandler [main] Started o.s.j.s.ServletContextHandler@69356aca{/metrics/json,null,AVAILABLE,@Spark}
2023-04-07 19:05:12,449 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] Started SpringBootSecurityJwtMongodbApplication in 29.279 seconds (JVM running for 30.869)
2023-04-07 19:05:12,455 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a info message
2023-04-07 19:05:12,455 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [main] This is a warn message
2023-04-07 19:05:14,618 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-07 19:05:15,626 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-1] JWT token is expired: JWT expired at 2023-04-07T18:53:46Z. Current time: 2023-04-07T19:05:15Z, a difference of 689624 milliseconds.  Allowed clock skew: 0 milliseconds.
2023-04-07 19:05:15,639 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-1] Unauthorized error: Full authentication is required to access this resource
2023-04-07 19:05:22,323 ERROR com.example.spring.jwt.mongodb.security.jwt.JwtUtils [http-nio-8080-exec-2] JWT token is expired: JWT expired at 2023-04-07T18:53:46Z. Current time: 2023-04-07T19:05:22Z, a difference of 696323 milliseconds.  Allowed clock skew: 0 milliseconds.
2023-04-07 19:05:23,127 INFO org.mongodb.driver.connection [http-nio-8080-exec-2] Opened connection [connectionId{localValue:3, serverValue:32}] to localhost:27017
2023-04-07 19:05:58,024 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to shitalpatil1219@gmail.com
2023-04-07 19:06:03,170 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to shitalpatil1219@gmail.com
2023-04-07 19:06:03,171 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Mail sent successfully to: shitalpatil1219@gmail.com
2023-04-07 19:06:03,527 INFO com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Sending mail to "shital.gmail.com"
2023-04-07 19:06:06,795 ERROR com.example.spring.jwt.mongodb.service.ThreadService [ForkJoinPool.commonPool-worker-1] Failed to send mail to: "shital.gmail.com"
org.springframework.mail.MailSendException: Failed messages: javax.mail.SendFailedException: Invalid Addresses;
  nested exception is:
	com.sun.mail.smtp.SMTPAddressFailedException: 553-5.1.3 The recipient address <shital.gmail.com> is not a valid RFC-5321
553-5.1.3 address. Learn more at
553 5.1.3  https://support.google.com/mail/answer/6596 jj21-20020a170903049500b0019f1222b9f6sm2961915plb.154 - gsmtp

	at org.springframework.mail.javamail.JavaMailSenderImpl.doSend(JavaMailSenderImpl.java:491)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:323)
	at org.springframework.mail.javamail.JavaMailSenderImpl.send(JavaMailSenderImpl.java:312)
	at com.example.spring.jwt.mongodb.service.ThreadService.sendMail(ThreadService.java:45)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:60)
	at com.example.spring.jwt.mongodb.service.ThreadService$1.call(ThreadService.java:1)
	at com.example.spring.jwt.mongodb.controllers.ThreadController.lambda$0(ThreadController.java:63)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.exec(CompletableFuture.java:1760)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
2023-04-07 19:06:32,968 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-5] Retrieving successful mail ids
2023-04-07 19:06:33,195 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-5] Retrieved 6 successful mail ids
2023-04-07 19:06:42,499 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-6] Retrieving failed mail ids
2023-04-07 19:06:42,508 INFO com.example.spring.jwt.mongodb.controllers.ThreadController [http-nio-8080-exec-6] Retrieved 4 failed mail ids
2023-04-13 13:25:36,152 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 18512 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-13 13:25:36,157 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-13 13:25:38,919 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-13 13:25:38,920 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-13 13:25:39,064 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-13 13:25:39,298 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@31524d5f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-13 13:25:39,333 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6437b57b724d536e220fd521', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:25}] to localhost:27017
2023-04-13 13:25:39,334 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6437b57b724d536e220fd521', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=33935287}
2023-04-13 13:25:39,337 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6437b57b724d536e220fd521', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:26}] to localhost:27017
2023-04-13 13:25:40,082 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-13 13:25:40,161 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-13 13:25:40,377 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-13 13:25:40,526 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-13 13:25:41,038 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-13 13:25:41,062 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-13 13:25:41,941 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-13 13:25:42,553 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-13 13:25:42,554 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-13 13:25:42,630 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-13 13:25:42,986 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-13 13:25:43,141 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-13 13:25:43,219 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-13 13:25:43,221 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-13 13:25:43,222 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-13 13:25:43,223 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-13 13:25:43,225 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-13 13:25:43,643 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 34203.
2023-04-13 13:25:43,684 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-13 13:25:43,711 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-13 13:25:43,720 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-13 13:25:43,721 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-13 13:25:43,734 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-22eca01a-8b1c-4f0e-81ed-0f0b23bc1778
2023-04-13 13:25:43,772 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-13 13:25:43,800 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-13 13:25:43,907 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @10150ms
2023-04-13 13:25:43,978 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-13 13:25:44,009 INFO org.spark_project.jetty.server.Server [restartedMain] Started @10252ms
2023-04-13 13:25:44,035 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@550a37f7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-13 13:25:44,036 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-13 13:25:44,062 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58e14402{/jobs,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,064 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69d6cb8f{/jobs/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,067 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@eb397fb{/jobs/job,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,069 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6b67d064{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,072 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79798ebc{/stages,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,074 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@24bedd0c{/stages/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,076 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7d10ada{/stages/stage,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,083 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6892e69b{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,085 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44d6b505{/stages/pool,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,087 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1dd97aee{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,089 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@9ce781c{/storage,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,091 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7697f180{/storage/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,092 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7981cca{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,094 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@514018dd{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,096 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2bb49471{/environment,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,097 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@62667b76{/environment/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,099 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@25df55bc{/executors,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,102 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7488272a{/executors/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,103 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b1032d6{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,105 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2a7c4b09{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,115 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@75d1994f{/static,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,116 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@50af5bca{/,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,119 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@fa36a29{/api,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,120 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@755d2c95{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,122 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@77f6c112{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-13 13:25:44,126 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-13 13:25:44,267 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-13 13:25:44,316 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35923.
2023-04-13 13:25:44,318 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:35923
2023-04-13 13:25:44,321 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-13 13:25:44,365 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 35923, None)
2023-04-13 13:25:44,370 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:35923 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 35923, None)
2023-04-13 13:25:44,376 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 35923, None)
2023-04-13 13:25:44,377 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 35923, None)
2023-04-13 13:25:44,401 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7fe6d99e{/metrics/json,null,AVAILABLE,@Spark}
2023-04-13 13:25:46,979 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 11.515 seconds (JVM running for 13.222)
2023-04-13 13:25:46,983 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-13 13:25:46,984 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-13 13:25:52,345 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-13 13:25:53,626 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 592 ms
