2023-04-26 11:42:12,303 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:42:12,312 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:42:18,449 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:42:18,450 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:42:18,700 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:42:19,040 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:42:19,926 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c0c2adee62176f29075a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:43}] to localhost:27017
2023-04-26 11:42:19,926 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c0c2adee62176f29075a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:42}] to localhost:27017
2023-04-26 11:42:19,928 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c0c2adee62176f29075a', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=843594220}
2023-04-26 11:42:20,770 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:42:20,949 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-26 11:42:21,412 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-26 11:42:21,671 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-26 11:42:21,952 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-26 11:42:22,020 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:42:23,375 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:42:25,539 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-26 11:42:25,541 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-26 11:42:25,882 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:42:26,614 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-26 11:42:27,413 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:42:28,014 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:42:28,016 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:42:28,018 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:42:28,020 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:42:28,021 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:42:29,269 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 45037.
2023-04-26 11:42:29,467 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:42:29,625 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:42:29,672 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:42:29,673 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:42:29,726 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-96035a0c-5baa-485f-9981-d59e9c549a93
2023-04-26 11:42:29,817 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:42:29,900 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:42:30,132 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @22364ms
2023-04-26 11:42:30,496 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:42:30,521 INFO org.spark_project.jetty.server.Server [restartedMain] Started @22754ms
2023-04-26 11:42:30,578 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@2dfbf2f2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:42:30,579 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:42:30,620 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1cc31945{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,622 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3601df28{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,624 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@61ead456{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,628 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@38bfc05{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,631 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34f4d046{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,632 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6b4ee677{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,633 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@c840281{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,636 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3f126d73{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,639 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@443d9e41{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,641 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2abdfb56{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,643 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@c43cc35{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,644 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2096513b{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,646 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@8f10cfe{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,648 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d5331fd{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,650 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5fe37e06{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,651 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d6ef348{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,653 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4df890e7{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,654 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@19f09c7c{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d27d20a{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,658 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@67e99e55{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,670 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6e1f45e7{/static,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,672 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4f2a7f1c{/,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,674 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@75f05f16{/api,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,677 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44a04dbc{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,679 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b6cfe80{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:42:30,696 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:42:31,014 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:42:31,065 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45759.
2023-04-26 11:42:31,074 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:45759
2023-04-26 11:42:31,077 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:42:31,142 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 45759, None)
2023-04-26 11:42:31,147 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:45759 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 45759, None)
2023-04-26 11:42:31,187 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 45759, None)
2023-04-26 11:42:31,188 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 45759, None)
2023-04-26 11:42:31,417 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3dd278bc{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:42:35,946 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:42:36,140 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:42:36,140 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:42:36,141 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489556136
2023-04-26 11:42:36,147 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-1, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:42:36,291 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 25.283 seconds (JVM running for 28.523)
2023-04-26 11:42:36,296 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:42:36,296 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:42:37,432 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:42:37,436 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:42:37,438 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:42:37,441 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] (Re-)joining group
2023-04-26 11:42:37,486 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:42:37,487 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] (Re-)joining group
2023-04-26 11:42:37,492 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Successfully joined group with generation Generation{generationId=131, memberId='consumer-book-group-1-5d588ee0-de10-4b93-ae76-ab2d11043439', protocol='range'}
2023-04-26 11:42:37,498 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Finished assignment for group at generation 131: {consumer-book-group-1-5d588ee0-de10-4b93-ae76-ab2d11043439=Assignment(partitions=[my-topic-0])}
2023-04-26 11:42:37,511 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Successfully synced group in generation Generation{generationId=131, memberId='consumer-book-group-1-5d588ee0-de10-4b93-ae76-ab2d11043439', protocol='range'}
2023-04-26 11:42:37,513 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:42:37,519 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:42:37,541 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=414, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:42:50,223 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-26 11:42:54,147 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-8] Init duration for springdoc-openapi is: 1239 ms
2023-04-26 11:43:27,534 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-7] Unauthorized error: Full authentication is required to access this resource
2023-04-26 11:44:04,926 INFO org.mongodb.driver.connection [http-nio-8080-exec-8] Opened connection [connectionId{localValue:3, serverValue:44}] to localhost:27017
2023-04-26 11:44:33,024 INFO org.apache.kafka.clients.producer.ProducerConfig [http-nio-8080-exec-10] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2023-04-26 11:44:33,065 INFO org.apache.kafka.clients.producer.KafkaProducer [http-nio-8080-exec-10] [Producer clientId=producer-1] Instantiated an idempotent producer.
2023-04-26 11:44:33,095 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-10] Kafka version: 3.1.1
2023-04-26 11:44:33,096 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-10] Kafka commitId: 97671528ba54a138
2023-04-26 11:44:33,097 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-10] Kafka startTimeMs: 1682489673095
2023-04-26 11:44:33,111 INFO org.apache.kafka.clients.Metadata [kafka-producer-network-thread | producer-1] [Producer clientId=producer-1] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:44:33,112 INFO org.apache.kafka.clients.Metadata [kafka-producer-network-thread | producer-1] [Producer clientId=producer-1] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:44:33,391 INFO org.apache.kafka.clients.producer.internals.TransactionManager [kafka-producer-network-thread | producer-1] [Producer clientId=producer-1] ProducerId set to 3000 with epoch 0
2023-04-26 11:47:29,194 INFO org.apache.catalina.core.StandardService [Thread-4] Stopping service [Tomcat]
2023-04-26 11:47:29,197 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [Thread-4] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-26 11:47:29,209 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-4] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:29,210 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-4] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c0c2adee62176f29075a', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:29,211 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-4] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c0c2adee62176f29075a', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:29,212 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-4] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:29,214 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-4] The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/sun.nio.ch.EPoll.wait(Native Method)
 java.base@17.0.6/sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:118)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:129)
 java.base@17.0.6/sun.nio.ch.SelectorImpl.select(SelectorImpl.java:141)
 app//org.apache.kafka.common.network.Selector.select(Selector.java:873)
 app//org.apache.kafka.common.network.Selector.poll(Selector.java:465)
 app//org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:560)
 app//org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:328)
 app//org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:243)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:29,225 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:47:29,227 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Member consumer-book-group-1-5d588ee0-de10-4b93-ae76-ab2d11043439 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:47:29,232 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:47:29,232 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:47:29,233 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:47:29,234 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:47:29,234 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-1, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:47:29,248 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:47:29,253 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:47:29,253 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:47:29,280 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-1 unregistered
2023-04-26 11:47:29,292 INFO org.apache.kafka.clients.producer.KafkaProducer [Thread-4] [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2023-04-26 11:47:29,316 INFO org.apache.kafka.common.metrics.Metrics [Thread-4] Metrics scheduler closed
2023-04-26 11:47:29,317 INFO org.apache.kafka.common.metrics.Metrics [Thread-4] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:47:29,317 INFO org.apache.kafka.common.metrics.Metrics [Thread-4] Metrics reporters closed
2023-04-26 11:47:29,317 INFO org.apache.kafka.common.utils.AppInfoParser [Thread-4] App info kafka.producer for producer-1 unregistered
2023-04-26 11:47:29,360 INFO org.spark_project.jetty.server.AbstractConnector [Thread-4] Stopped Spark@2dfbf2f2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:47:29,364 INFO org.apache.spark.ui.SparkUI [Thread-4] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:47:29,438 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-0] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:47:29,552 INFO org.apache.spark.storage.memory.MemoryStore [Thread-4] MemoryStore cleared
2023-04-26 11:47:29,553 INFO org.apache.spark.storage.BlockManager [Thread-4] BlockManager stopped
2023-04-26 11:47:29,628 INFO org.apache.spark.storage.BlockManagerMaster [Thread-4] BlockManagerMaster stopped
2023-04-26 11:47:29,710 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-26 11:47:29,811 INFO org.apache.spark.SparkContext [Thread-4] Successfully stopped SparkContext
2023-04-26 11:47:29,812 INFO org.apache.spark.SparkContext [Thread-4] SparkContext already stopped.
2023-04-26 11:47:29,828 INFO com.zaxxer.hikari.HikariDataSource [Thread-4] HikariPool-1 - Shutdown initiated...
2023-04-26 11:47:29,846 INFO com.zaxxer.hikari.HikariDataSource [Thread-4] HikariPool-1 - Shutdown completed.
2023-04-26 11:47:30,427 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:47:30,427 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:47:31,346 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:47:31,346 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:47:31,389 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:47:31,471 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:47:31,474 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c1fbadee62176f29075b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:5, serverValue:46}] to localhost:27017
2023-04-26 11:47:31,481 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c1fbadee62176f29075b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:4, serverValue:45}] to localhost:27017
2023-04-26 11:47:31,482 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c1fbadee62176f29075b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2490111}
2023-04-26 11:47:31,737 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:47:31,753 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-2 - Starting...
2023-04-26 11:47:31,764 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-2 - Start completed.
2023-04-26 11:47:31,765 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:47:31,884 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:47:32,168 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:47:32,169 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:47:32,172 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:47:32,173 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:47:32,173 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:47:32,174 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:47:32,174 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:47:32,237 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 42199.
2023-04-26 11:47:32,242 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:47:32,243 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:47:32,244 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:47:32,244 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:47:32,246 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-2e5ee95c-c4a5-40df-9dee-e768482a9209
2023-04-26 11:47:32,247 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:47:32,250 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:47:32,261 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:47:32,265 INFO org.spark_project.jetty.server.Server [restartedMain] Started @324498ms
2023-04-26 11:47:32,267 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@35df1986{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:47:32,268 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:47:32,269 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4dd69c3a{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,271 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7933bc7{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,272 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@52dd2f2e{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,273 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1f830fda{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,274 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@66cd675c{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,275 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@781e3541{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,276 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4381c133{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,278 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44fbeb46{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,279 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49818302{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,280 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@40bc034e{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,281 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@d79ca33{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,282 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@16c3a101{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,283 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@531fb948{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,284 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@73997616{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,284 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@30f21204{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,285 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3bb266b2{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,286 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@15494d75{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,287 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d58a00c{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,288 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@d1af591{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,289 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@25358576{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,291 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a485640{/static,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,293 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@12f8d1c5{/,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,294 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@48941876{/api,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,295 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79c19e01{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,297 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d631e05{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:47:32,297 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:47:32,335 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:47:32,342 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44061.
2023-04-26 11:47:32,343 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:44061
2023-04-26 11:47:32,343 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:47:32,344 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 44061, None)
2023-04-26 11:47:32,345 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:44061 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 44061, None)
2023-04-26 11:47:32,346 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 44061, None)
2023-04-26 11:47:32,347 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 44061, None)
2023-04-26 11:47:32,349 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@494dbc07{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:47:34,017 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:47:34,024 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:47:34,025 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:47:34,025 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489854024
2023-04-26 11:47:34,026 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-2, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:47:34,037 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:47:34,038 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:47:34,038 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:47:34,041 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] (Re-)joining group
2023-04-26 11:47:34,049 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:47:34,054 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] (Re-)joining group
2023-04-26 11:47:34,058 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Successfully joined group with generation Generation{generationId=133, memberId='consumer-book-group-2-b9aeb80a-6c33-4bbc-9f15-626d497f76c3', protocol='range'}
2023-04-26 11:47:34,058 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Finished assignment for group at generation 133: {consumer-book-group-2-b9aeb80a-6c33-4bbc-9f15-626d497f76c3=Assignment(partitions=[my-topic-0])}
2023-04-26 11:47:34,069 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Successfully synced group in generation Generation{generationId=133, memberId='consumer-book-group-2-b9aeb80a-6c33-4bbc-9f15-626d497f76c3', protocol='range'}
2023-04-26 11:47:34,070 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:47:34,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:47:34,076 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:47:34,103 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.829 seconds (JVM running for 326.336)
2023-04-26 11:47:34,108 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:47:34,108 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:47:59,504 INFO org.apache.catalina.core.StandardService [Thread-21] Stopping service [Tomcat]
2023-04-26 11:47:59,508 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-21] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c1fbadee62176f29075b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:59,509 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-21] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c1fbadee62176f29075b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:59,510 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-21] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-3-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:47:59,513 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:47:59,513 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Member consumer-book-group-2-b9aeb80a-6c33-4bbc-9f15-626d497f76c3 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:47:59,516 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:47:59,517 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:47:59,517 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:47:59,518 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:47:59,518 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-2, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:47:59,519 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:47:59,519 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:47:59,520 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:47:59,523 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-2 unregistered
2023-04-26 11:47:59,528 INFO org.spark_project.jetty.server.AbstractConnector [Thread-21] Stopped Spark@35df1986{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:47:59,529 INFO org.apache.spark.ui.SparkUI [Thread-21] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:47:59,531 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:47:59,542 INFO org.apache.spark.storage.memory.MemoryStore [Thread-21] MemoryStore cleared
2023-04-26 11:47:59,542 INFO org.apache.spark.storage.BlockManager [Thread-21] BlockManager stopped
2023-04-26 11:47:59,543 INFO org.apache.spark.storage.BlockManagerMaster [Thread-21] BlockManagerMaster stopped
2023-04-26 11:47:59,544 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:47:59,554 INFO org.apache.spark.SparkContext [Thread-21] Successfully stopped SparkContext
2023-04-26 11:47:59,555 INFO org.apache.spark.SparkContext [Thread-21] SparkContext already stopped.
2023-04-26 11:47:59,562 INFO com.zaxxer.hikari.HikariDataSource [Thread-21] HikariPool-2 - Shutdown initiated...
2023-04-26 11:47:59,566 INFO com.zaxxer.hikari.HikariDataSource [Thread-21] HikariPool-2 - Shutdown completed.
2023-04-26 11:47:59,811 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:47:59,811 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:48:00,548 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:48:00,549 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:48:00,576 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:48:00,621 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:48:00,656 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c218adee62176f29075c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:6, serverValue:48}] to localhost:27017
2023-04-26 11:48:00,657 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c218adee62176f29075c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32268287}
2023-04-26 11:48:00,657 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c218adee62176f29075c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:7, serverValue:47}] to localhost:27017
2023-04-26 11:48:00,852 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:48:00,865 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-3 - Starting...
2023-04-26 11:48:00,871 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-3 - Start completed.
2023-04-26 11:48:00,872 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:48:00,980 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:48:01,275 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:48:01,276 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:48:01,279 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:48:01,279 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:48:01,280 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:48:01,280 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:48:01,281 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:48:01,349 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 39283.
2023-04-26 11:48:01,355 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:48:01,357 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:48:01,358 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:48:01,358 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:48:01,359 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-39b9aad9-7785-41ba-8cea-73edfbd6c313
2023-04-26 11:48:01,360 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:48:01,364 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:48:01,374 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:48:01,376 INFO org.spark_project.jetty.server.Server [restartedMain] Started @353609ms
2023-04-26 11:48:01,378 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@2317ddb8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:48:01,379 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:48:01,380 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2982d4e0{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,381 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5cfaba45{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,382 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@530b45da{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,383 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4e6ca81e{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,384 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@71f640e7{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,385 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@78d7f40e{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,387 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@71fb4b5b{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,388 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5a7c3122{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,390 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@194ea3f2{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,391 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5efe5351{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,391 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@75f47a46{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,392 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4e3aa0fb{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,393 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2207cbfd{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,396 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@e4f7037{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,398 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58bf1df2{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,400 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@43194366{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,401 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5f5d30db{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,402 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ae63dcf{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,403 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@a96e5ec{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,404 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@31d95ab{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,406 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3570b6fb{/static,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,407 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2e63fddf{/,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,408 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1367c47a{/api,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,410 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4ccf1d72{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,411 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7d739c31{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:48:01,411 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:48:01,456 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:48:01,465 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33337.
2023-04-26 11:48:01,468 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:33337
2023-04-26 11:48:01,468 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:48:01,469 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 33337, None)
2023-04-26 11:48:01,470 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-3] Registering block manager 192.168.1.125:33337 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 33337, None)
2023-04-26 11:48:01,471 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 33337, None)
2023-04-26 11:48:01,471 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 33337, None)
2023-04-26 11:48:01,472 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6d7eb6eb{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:02,923 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:48:02,930 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:48:02,930 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:48:02,930 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489882930
2023-04-26 11:48:02,931 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-3, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:48:02,936 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:48:02,937 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:48:02,939 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:48:02,940 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] (Re-)joining group
2023-04-26 11:48:02,945 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:48:02,946 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] (Re-)joining group
2023-04-26 11:48:02,948 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.193 seconds (JVM running for 355.18)
2023-04-26 11:48:02,948 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Successfully joined group with generation Generation{generationId=135, memberId='consumer-book-group-3-9509cc31-3830-43fe-a842-ce10f80e473c', protocol='range'}
2023-04-26 11:48:02,949 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Finished assignment for group at generation 135: {consumer-book-group-3-9509cc31-3830-43fe-a842-ce10f80e473c=Assignment(partitions=[my-topic-0])}
2023-04-26 11:48:02,953 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Successfully synced group in generation Generation{generationId=135, memberId='consumer-book-group-3-9509cc31-3830-43fe-a842-ce10f80e473c', protocol='range'}
2023-04-26 11:48:02,954 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:48:02,954 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:48:02,956 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:48:02,956 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:48:02,963 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:48:28,411 INFO org.apache.catalina.core.StandardService [Thread-37] Stopping service [Tomcat]
2023-04-26 11:48:28,418 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-37] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c218adee62176f29075c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:48:28,423 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-37] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c218adee62176f29075c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:48:28,424 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-37] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-4-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:48:28,428 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:48:28,429 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Member consumer-book-group-3-9509cc31-3830-43fe-a842-ce10f80e473c sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:48:28,435 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:48:28,436 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:48:28,436 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:48:28,436 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:48:28,437 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-3, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:48:28,438 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:48:28,438 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:48:28,439 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:48:28,445 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-3 unregistered
2023-04-26 11:48:28,455 INFO org.spark_project.jetty.server.AbstractConnector [Thread-37] Stopped Spark@2317ddb8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:48:28,458 INFO org.apache.spark.ui.SparkUI [Thread-37] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:48:28,462 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:48:28,500 INFO org.apache.spark.storage.memory.MemoryStore [Thread-37] MemoryStore cleared
2023-04-26 11:48:28,501 INFO org.apache.spark.storage.BlockManager [Thread-37] BlockManager stopped
2023-04-26 11:48:28,501 INFO org.apache.spark.storage.BlockManagerMaster [Thread-37] BlockManagerMaster stopped
2023-04-26 11:48:28,502 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-2] OutputCommitCoordinator stopped!
2023-04-26 11:48:28,516 INFO org.apache.spark.SparkContext [Thread-37] Successfully stopped SparkContext
2023-04-26 11:48:28,516 INFO org.apache.spark.SparkContext [Thread-37] SparkContext already stopped.
2023-04-26 11:48:28,518 INFO com.zaxxer.hikari.HikariDataSource [Thread-37] HikariPool-3 - Shutdown initiated...
2023-04-26 11:48:28,523 INFO com.zaxxer.hikari.HikariDataSource [Thread-37] HikariPool-3 - Shutdown completed.
2023-04-26 11:48:28,788 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:48:28,788 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:48:29,534 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:48:29,534 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:48:29,560 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:48:29,638 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:48:29,640 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c235adee62176f29075d', description='null'}-localhost:27017] Opened connection [connectionId{localValue:9, serverValue:49}] to localhost:27017
2023-04-26 11:48:29,647 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c235adee62176f29075d', description='null'}-localhost:27017] Opened connection [connectionId{localValue:8, serverValue:50}] to localhost:27017
2023-04-26 11:48:29,648 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c235adee62176f29075d', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=8222265}
2023-04-26 11:48:29,937 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:48:29,962 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-4 - Starting...
2023-04-26 11:48:29,968 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-4 - Start completed.
2023-04-26 11:48:29,969 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:48:30,160 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:48:30,536 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:48:30,538 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:48:30,542 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:48:30,543 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:48:30,544 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:48:30,544 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:48:30,544 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:48:30,604 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 46635.
2023-04-26 11:48:30,610 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:48:30,612 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:48:30,613 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:48:30,613 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:48:30,614 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-c49aacd1-a35f-49cf-bc99-ef4570b4857e
2023-04-26 11:48:30,615 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:48:30,618 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:48:30,626 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:48:30,636 INFO org.spark_project.jetty.server.Server [restartedMain] Started @382869ms
2023-04-26 11:48:30,637 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@5d94c86c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:48:30,638 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:48:30,639 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58ebaa44{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,640 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@e459b4d{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,641 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@68e95542{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,642 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13c5379b{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,644 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@16f9062d{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,647 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3444784c{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,648 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@16a568c3{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,650 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ce6fc63{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,651 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@72705fbc{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,652 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6561cfa6{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,653 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58bf40b9{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@43a1ba29{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@33dc905e{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,657 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@582b757c{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,658 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7ab35c48{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,659 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@340dc1c5{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,660 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6384f97a{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,661 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6087f0e3{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,661 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@b6b1a7{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,662 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5aef5b9d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,663 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1e643693{/static,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,664 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@413bcd54{/,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,665 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@74b5675d{/api,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,667 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6bc99d4c{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,668 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7487bc0c{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:48:30,668 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:48:30,705 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:48:30,713 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46789.
2023-04-26 11:48:30,714 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:46789
2023-04-26 11:48:30,714 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:48:30,714 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 46789, None)
2023-04-26 11:48:30,715 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-3] Registering block manager 192.168.1.125:46789 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 46789, None)
2023-04-26 11:48:30,717 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 46789, None)
2023-04-26 11:48:30,717 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 46789, None)
2023-04-26 11:48:30,719 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d13bb48{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:48:32,492 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-4
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:48:32,496 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:48:32,497 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:48:32,497 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489912496
2023-04-26 11:48:32,498 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-4, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:48:32,504 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:48:32,505 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:48:32,506 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:48:32,507 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] (Re-)joining group
2023-04-26 11:48:32,513 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.791 seconds (JVM running for 384.746)
2023-04-26 11:48:32,514 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:48:32,514 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] (Re-)joining group
2023-04-26 11:48:32,518 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:48:32,518 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:48:32,520 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Successfully joined group with generation Generation{generationId=137, memberId='consumer-book-group-4-700fef6a-07f9-4334-adb5-4d46a53e5324', protocol='range'}
2023-04-26 11:48:32,521 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Finished assignment for group at generation 137: {consumer-book-group-4-700fef6a-07f9-4334-adb5-4d46a53e5324=Assignment(partitions=[my-topic-0])}
2023-04-26 11:48:32,531 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Successfully synced group in generation Generation{generationId=137, memberId='consumer-book-group-4-700fef6a-07f9-4334-adb5-4d46a53e5324', protocol='range'}
2023-04-26 11:48:32,532 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:48:32,532 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:48:32,535 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:49:21,075 INFO org.apache.catalina.core.StandardService [Thread-53] Stopping service [Tomcat]
2023-04-26 11:49:21,084 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-53] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c235adee62176f29075d', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:21,085 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-53] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c235adee62176f29075d', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:21,086 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-53] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-5-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:21,097 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:49:21,098 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Member consumer-book-group-4-700fef6a-07f9-4334-adb5-4d46a53e5324 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:49:21,101 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:49:21,102 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:49:21,102 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:49:21,103 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:49:21,103 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-4, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:49:21,104 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:49:21,104 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:49:21,104 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:49:21,107 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-4 unregistered
2023-04-26 11:49:21,121 INFO org.spark_project.jetty.server.AbstractConnector [Thread-53] Stopped Spark@5d94c86c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:49:21,123 INFO org.apache.spark.ui.SparkUI [Thread-53] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:49:21,126 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:49:21,143 INFO org.apache.spark.storage.memory.MemoryStore [Thread-53] MemoryStore cleared
2023-04-26 11:49:21,144 INFO org.apache.spark.storage.BlockManager [Thread-53] BlockManager stopped
2023-04-26 11:49:21,144 INFO org.apache.spark.storage.BlockManagerMaster [Thread-53] BlockManagerMaster stopped
2023-04-26 11:49:21,145 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-2] OutputCommitCoordinator stopped!
2023-04-26 11:49:21,153 INFO org.apache.spark.SparkContext [Thread-53] Successfully stopped SparkContext
2023-04-26 11:49:21,153 INFO org.apache.spark.SparkContext [Thread-53] SparkContext already stopped.
2023-04-26 11:49:21,156 INFO com.zaxxer.hikari.HikariDataSource [Thread-53] HikariPool-4 - Shutdown initiated...
2023-04-26 11:49:21,159 INFO com.zaxxer.hikari.HikariDataSource [Thread-53] HikariPool-4 - Shutdown completed.
2023-04-26 11:49:21,510 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:49:21,511 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:49:22,349 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:49:22,349 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:49:22,379 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:49:22,434 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:49:22,436 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c26aadee62176f29075e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:10, serverValue:51}] to localhost:27017
2023-04-26 11:49:22,436 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c26aadee62176f29075e', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1562409}
2023-04-26 11:49:22,437 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c26aadee62176f29075e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:11, serverValue:52}] to localhost:27017
2023-04-26 11:49:22,656 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:49:22,674 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-5 - Starting...
2023-04-26 11:49:22,699 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-5 - Start completed.
2023-04-26 11:49:22,700 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:49:22,880 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:49:23,245 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:49:23,248 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:49:23,250 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:49:23,251 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:49:23,251 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:49:23,252 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:49:23,252 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:49:23,336 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 45505.
2023-04-26 11:49:23,343 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:49:23,344 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:49:23,345 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:49:23,346 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:49:23,347 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-1098ad2c-6946-4ec6-80e8-e29c678b59e8
2023-04-26 11:49:23,348 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:49:23,352 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:49:23,362 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:49:23,365 INFO org.spark_project.jetty.server.Server [restartedMain] Started @435598ms
2023-04-26 11:49:23,366 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@7f090bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:49:23,367 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:49:23,368 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5adadacd{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,369 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2fddecb2{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,370 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c2749b6{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,376 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5bc79869{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,378 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@57473d6e{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,379 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@173ff348{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,380 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@410372e0{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,381 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@26e0be79{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,382 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@48225b86{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,383 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20ef4479{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,388 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7aa1a6f6{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,391 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5991dcad{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,393 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3355272{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,394 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59a302e1{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,403 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ec29935{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,407 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79e15cf4{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,408 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@506e3778{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,409 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@111b839e{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,411 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2b2aabb9{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,412 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@585f44d4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,414 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79ab7d50{/static,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,415 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34e11688{/,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,416 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4a6814ce{/api,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,417 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4ad03118{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,418 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@76392b9c{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:49:23,419 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:49:23,457 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:49:23,465 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39617.
2023-04-26 11:49:23,466 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:39617
2023-04-26 11:49:23,466 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:49:23,467 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 39617, None)
2023-04-26 11:49:23,468 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:39617 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 39617, None)
2023-04-26 11:49:23,468 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 39617, None)
2023-04-26 11:49:23,469 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 39617, None)
2023-04-26 11:49:23,471 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@47d8da6a{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:25,150 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-5
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:49:25,157 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:49:25,157 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:49:25,157 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489965157
2023-04-26 11:49:25,159 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-5, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:49:25,168 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:49:25,169 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:49:25,169 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:49:25,178 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] (Re-)joining group
2023-04-26 11:49:25,183 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:49:25,183 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] (Re-)joining group
2023-04-26 11:49:25,188 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.771 seconds (JVM running for 437.421)
2023-04-26 11:49:25,194 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Successfully joined group with generation Generation{generationId=139, memberId='consumer-book-group-5-96428b7d-20c8-4cf3-88cf-7534bdff645e', protocol='range'}
2023-04-26 11:49:25,194 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Finished assignment for group at generation 139: {consumer-book-group-5-96428b7d-20c8-4cf3-88cf-7534bdff645e=Assignment(partitions=[my-topic-0])}
2023-04-26 11:49:25,197 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Successfully synced group in generation Generation{generationId=139, memberId='consumer-book-group-5-96428b7d-20c8-4cf3-88cf-7534bdff645e', protocol='range'}
2023-04-26 11:49:25,198 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:49:25,198 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:49:25,198 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:49:25,198 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:49:25,206 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:49:34,576 INFO org.apache.catalina.core.StandardService [Thread-69] Stopping service [Tomcat]
2023-04-26 11:49:34,589 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-69] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c26aadee62176f29075e', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:34,592 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-69] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c26aadee62176f29075e', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:34,593 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-69] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-6-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:49:34,599 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:49:34,600 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Member consumer-book-group-5-96428b7d-20c8-4cf3-88cf-7534bdff645e sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:49:34,609 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:49:34,609 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:49:34,610 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:49:34,610 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:49:34,610 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-5, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:49:34,611 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:49:34,611 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:49:34,612 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:49:34,624 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-5 unregistered
2023-04-26 11:49:34,645 INFO org.spark_project.jetty.server.AbstractConnector [Thread-69] Stopped Spark@7f090bd0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:49:34,649 INFO org.apache.spark.ui.SparkUI [Thread-69] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:49:34,655 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-1] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:49:34,706 INFO org.apache.spark.storage.memory.MemoryStore [Thread-69] MemoryStore cleared
2023-04-26 11:49:34,707 INFO org.apache.spark.storage.BlockManager [Thread-69] BlockManager stopped
2023-04-26 11:49:34,707 INFO org.apache.spark.storage.BlockManagerMaster [Thread-69] BlockManagerMaster stopped
2023-04-26 11:49:34,710 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:49:34,747 INFO org.apache.spark.SparkContext [Thread-69] Successfully stopped SparkContext
2023-04-26 11:49:34,748 INFO org.apache.spark.SparkContext [Thread-69] SparkContext already stopped.
2023-04-26 11:49:34,750 INFO com.zaxxer.hikari.HikariDataSource [Thread-69] HikariPool-5 - Shutdown initiated...
2023-04-26 11:49:34,764 INFO com.zaxxer.hikari.HikariDataSource [Thread-69] HikariPool-5 - Shutdown completed.
2023-04-26 11:49:35,119 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:49:35,119 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:49:35,815 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:49:35,816 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:49:35,842 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:49:35,889 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:49:35,891 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c277adee62176f29075f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:13, serverValue:54}] to localhost:27017
2023-04-26 11:49:35,893 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c277adee62176f29075f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:12, serverValue:53}] to localhost:27017
2023-04-26 11:49:35,893 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c277adee62176f29075f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2484954}
2023-04-26 11:49:36,113 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:49:36,133 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-6 - Starting...
2023-04-26 11:49:36,137 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-6 - Start completed.
2023-04-26 11:49:36,138 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:49:36,264 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:49:36,557 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:49:36,558 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:49:36,560 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:49:36,560 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:49:36,561 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:49:36,561 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:49:36,561 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:49:36,643 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 40271.
2023-04-26 11:49:36,646 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:49:36,648 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:49:36,648 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:49:36,649 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:49:36,649 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-1770c861-6bc7-4491-b3db-26d428f32f71
2023-04-26 11:49:36,650 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:49:36,652 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:49:36,658 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:49:36,660 INFO org.spark_project.jetty.server.Server [restartedMain] Started @448893ms
2023-04-26 11:49:36,662 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@7b630c84{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:49:36,662 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:49:36,663 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6108d83c{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,664 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5793be82{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,665 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@67992066{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,666 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4fd173d{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,667 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2393f6a6{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,668 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@693e3bf8{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,668 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@478aaca9{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,669 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ba20f9a{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,670 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1738fa8e{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,671 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@fc1e26a{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,672 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1dbce8df{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,673 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@26d9fa2d{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,674 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@76e598f2{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,675 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7637e6f6{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,676 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@cb712ff{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,677 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@655699d6{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,677 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3faebf86{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,678 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@76e7fed3{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,679 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@42f32a1a{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,679 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13ba83bb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,680 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59225cc5{/static,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,681 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10fa3054{/,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,682 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b026bab{/api,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,683 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@476d3f16{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,684 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6d4df3f{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:49:36,685 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:49:36,724 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:49:36,730 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42991.
2023-04-26 11:49:36,730 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:42991
2023-04-26 11:49:36,731 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:49:36,732 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 42991, None)
2023-04-26 11:49:36,734 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:42991 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 42991, None)
2023-04-26 11:49:36,735 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 42991, None)
2023-04-26 11:49:36,736 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 42991, None)
2023-04-26 11:49:36,737 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@37749b75{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:49:38,568 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-6
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:49:38,575 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:49:38,575 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:49:38,576 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682489978575
2023-04-26 11:49:38,577 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-6, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:49:38,597 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:49:38,598 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:49:38,598 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:49:38,605 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] (Re-)joining group
2023-04-26 11:49:38,613 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:49:38,613 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] (Re-)joining group
2023-04-26 11:49:38,615 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.59 seconds (JVM running for 450.848)
2023-04-26 11:49:38,617 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Successfully joined group with generation Generation{generationId=141, memberId='consumer-book-group-6-75a33a13-459f-4108-9c03-9aa2388fbbd2', protocol='range'}
2023-04-26 11:49:38,618 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Finished assignment for group at generation 141: {consumer-book-group-6-75a33a13-459f-4108-9c03-9aa2388fbbd2=Assignment(partitions=[my-topic-0])}
2023-04-26 11:49:38,621 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:49:38,621 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:49:38,623 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Successfully synced group in generation Generation{generationId=141, memberId='consumer-book-group-6-75a33a13-459f-4108-9c03-9aa2388fbbd2', protocol='range'}
2023-04-26 11:49:38,624 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:49:38,624 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:49:38,635 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:50:09,067 INFO org.apache.catalina.core.StandardService [Thread-86] Stopping service [Tomcat]
2023-04-26 11:50:09,071 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-86] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c277adee62176f29075f', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:09,071 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-86] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c277adee62176f29075f', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:09,074 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-86] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-7-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:09,080 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:50:09,080 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Member consumer-book-group-6-75a33a13-459f-4108-9c03-9aa2388fbbd2 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:50:09,081 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:09,081 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:09,082 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:50:09,082 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:09,082 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-6, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:09,086 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:50:09,086 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:50:09,087 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:50:09,096 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-6 unregistered
2023-04-26 11:50:09,104 INFO org.spark_project.jetty.server.AbstractConnector [Thread-86] Stopped Spark@7b630c84{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:09,106 INFO org.apache.spark.ui.SparkUI [Thread-86] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:50:09,114 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:50:09,138 INFO org.apache.spark.storage.memory.MemoryStore [Thread-86] MemoryStore cleared
2023-04-26 11:50:09,138 INFO org.apache.spark.storage.BlockManager [Thread-86] BlockManager stopped
2023-04-26 11:50:09,139 INFO org.apache.spark.storage.BlockManagerMaster [Thread-86] BlockManagerMaster stopped
2023-04-26 11:50:09,140 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:50:09,161 INFO org.apache.spark.SparkContext [Thread-86] Successfully stopped SparkContext
2023-04-26 11:50:09,161 INFO org.apache.spark.SparkContext [Thread-86] SparkContext already stopped.
2023-04-26 11:50:09,163 INFO com.zaxxer.hikari.HikariDataSource [Thread-86] HikariPool-6 - Shutdown initiated...
2023-04-26 11:50:09,171 INFO com.zaxxer.hikari.HikariDataSource [Thread-86] HikariPool-6 - Shutdown completed.
2023-04-26 11:50:09,464 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:50:09,464 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:50:10,210 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:50:10,210 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:50:10,244 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:50:10,292 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:50:10,312 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c29aadee62176f290760', description='null'}-localhost:27017] Opened connection [connectionId{localValue:14, serverValue:55}] to localhost:27017
2023-04-26 11:50:10,312 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c29aadee62176f290760', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=18638645}
2023-04-26 11:50:10,317 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c29aadee62176f290760', description='null'}-localhost:27017] Opened connection [connectionId{localValue:15, serverValue:56}] to localhost:27017
2023-04-26 11:50:10,637 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:50:10,658 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-7 - Starting...
2023-04-26 11:50:10,664 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-7 - Start completed.
2023-04-26 11:50:10,665 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:50:10,771 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:50:11,067 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:50:11,067 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:50:11,069 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:50:11,070 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:50:11,070 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:50:11,071 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:50:11,071 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:50:11,120 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 46345.
2023-04-26 11:50:11,124 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:50:11,126 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:50:11,126 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:50:11,127 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:50:11,127 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-539ae8b7-e783-4283-b26b-f80d29f83549
2023-04-26 11:50:11,128 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:50:11,130 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:50:11,137 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:50:11,142 INFO org.spark_project.jetty.server.Server [restartedMain] Started @483375ms
2023-04-26 11:50:11,143 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@378e2c2a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:11,143 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:50:11,145 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@428210df{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,146 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@bbf0a8f{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,147 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6f16a736{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,147 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@29bf2982{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,148 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7be9d082{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,148 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@8f15602{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,149 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@52846f3d{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,150 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@227afd6{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,151 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@37ff02d0{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,151 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@353c136b{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,152 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44b06f76{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,153 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7bd62129{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,154 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34704501{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,154 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6102afaf{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,155 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@260ea726{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,156 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c1b15a7{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,157 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5af51d68{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,157 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2e7ebe4e{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,158 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7d1a0b30{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,159 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49988f19{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,160 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3b74d51f{/static,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,161 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@60a390f1{/,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,162 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4dcd545e{/api,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,163 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d61038f{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,164 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@213924ca{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:11,164 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:50:11,195 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:50:11,198 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39693.
2023-04-26 11:50:11,199 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:39693
2023-04-26 11:50:11,199 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:50:11,199 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 39693, None)
2023-04-26 11:50:11,200 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-3] Registering block manager 192.168.1.125:39693 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 39693, None)
2023-04-26 11:50:11,200 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 39693, None)
2023-04-26 11:50:11,200 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 39693, None)
2023-04-26 11:50:11,201 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4591e792{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:12,828 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-7
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:50:12,834 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:50:12,835 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:50:12,835 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490012834
2023-04-26 11:50:12,836 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-7, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:50:12,842 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:50:12,843 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:50:12,844 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:50:12,857 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] (Re-)joining group
2023-04-26 11:50:12,862 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:50:12,863 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] (Re-)joining group
2023-04-26 11:50:12,866 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Successfully joined group with generation Generation{generationId=143, memberId='consumer-book-group-7-1e9d9a44-6ca1-463e-9315-184ad5b59ada', protocol='range'}
2023-04-26 11:50:12,867 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Finished assignment for group at generation 143: {consumer-book-group-7-1e9d9a44-6ca1-463e-9315-184ad5b59ada=Assignment(partitions=[my-topic-0])}
2023-04-26 11:50:12,870 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.481 seconds (JVM running for 485.103)
2023-04-26 11:50:12,873 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Successfully synced group in generation Generation{generationId=143, memberId='consumer-book-group-7-1e9d9a44-6ca1-463e-9315-184ad5b59ada', protocol='range'}
2023-04-26 11:50:12,874 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:50:12,875 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:50:12,875 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:50:12,875 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:50:12,882 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:50:25,254 INFO org.apache.catalina.core.StandardService [Thread-102] Stopping service [Tomcat]
2023-04-26 11:50:25,257 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-102] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c29aadee62176f290760', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:25,258 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-102] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c29aadee62176f290760', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:25,259 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-102] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-8-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:25,261 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:50:25,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Member consumer-book-group-7-1e9d9a44-6ca1-463e-9315-184ad5b59ada sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:50:25,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:25,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:25,263 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:50:25,264 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:25,265 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-7, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:25,265 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:50:25,266 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:50:25,266 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:50:25,270 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-7 unregistered
2023-04-26 11:50:25,277 INFO org.spark_project.jetty.server.AbstractConnector [Thread-102] Stopped Spark@378e2c2a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:25,279 INFO org.apache.spark.ui.SparkUI [Thread-102] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:50:25,283 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:50:25,291 INFO org.apache.spark.storage.memory.MemoryStore [Thread-102] MemoryStore cleared
2023-04-26 11:50:25,291 INFO org.apache.spark.storage.BlockManager [Thread-102] BlockManager stopped
2023-04-26 11:50:25,292 INFO org.apache.spark.storage.BlockManagerMaster [Thread-102] BlockManagerMaster stopped
2023-04-26 11:50:25,292 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:50:25,299 INFO org.apache.spark.SparkContext [Thread-102] Successfully stopped SparkContext
2023-04-26 11:50:25,300 INFO org.apache.spark.SparkContext [Thread-102] SparkContext already stopped.
2023-04-26 11:50:25,302 INFO com.zaxxer.hikari.HikariDataSource [Thread-102] HikariPool-7 - Shutdown initiated...
2023-04-26 11:50:25,305 INFO com.zaxxer.hikari.HikariDataSource [Thread-102] HikariPool-7 - Shutdown completed.
2023-04-26 11:50:25,549 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:50:25,549 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:50:26,366 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:50:26,367 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:50:26,396 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:50:26,469 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:50:26,478 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c2aaadee62176f290761', description='null'}-localhost:27017] Opened connection [connectionId{localValue:16, serverValue:57}] to localhost:27017
2023-04-26 11:50:26,479 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c2aaadee62176f290761', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1811667}
2023-04-26 11:50:26,500 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c2aaadee62176f290761', description='null'}-localhost:27017] Opened connection [connectionId{localValue:17, serverValue:58}] to localhost:27017
2023-04-26 11:50:26,781 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:50:26,794 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-8 - Starting...
2023-04-26 11:50:26,798 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-8 - Start completed.
2023-04-26 11:50:26,799 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:50:26,885 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:50:27,142 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:50:27,143 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:50:27,145 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:50:27,145 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:50:27,146 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:50:27,146 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:50:27,146 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:50:27,203 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 37817.
2023-04-26 11:50:27,205 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:50:27,207 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:50:27,207 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:50:27,207 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:50:27,208 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-a1225896-f77d-4017-b72d-ad7b293c7465
2023-04-26 11:50:27,209 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:50:27,211 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:50:27,216 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:50:27,218 INFO org.spark_project.jetty.server.Server [restartedMain] Started @499451ms
2023-04-26 11:50:27,219 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@43540428{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:27,220 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:50:27,220 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@29034431{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,221 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3dc0e9{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,221 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6a06b780{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,222 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@9908bac{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,222 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3a817463{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,222 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@54d5d152{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,223 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@b30c6ff{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,223 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6f0f1de{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,223 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3763af0f{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,224 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d46b7f0{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,225 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@404c8799{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,226 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4133f04f{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,226 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6b0234b1{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,227 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1383f716{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,227 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@37d7cab0{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,228 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69b8f58d{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,229 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1365f3b7{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,230 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1f529d8a{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,230 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1659469a{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,231 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3863cd41{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,232 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@42779b1{/static,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,233 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@f921a72{/,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,234 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5323f08c{/api,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,234 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4a59238d{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,235 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5507f13e{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:27,235 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:50:27,264 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:50:27,270 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38199.
2023-04-26 11:50:27,270 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:38199
2023-04-26 11:50:27,270 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:50:27,270 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 38199, None)
2023-04-26 11:50:27,271 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:38199 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 38199, None)
2023-04-26 11:50:27,272 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 38199, None)
2023-04-26 11:50:27,272 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 38199, None)
2023-04-26 11:50:27,274 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@56556847{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:28,863 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-8
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:50:28,870 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:50:28,870 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:50:28,870 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490028870
2023-04-26 11:50:28,871 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-8, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:50:28,877 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:50:28,878 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:50:28,878 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:50:28,881 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] (Re-)joining group
2023-04-26 11:50:28,889 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:50:28,890 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] (Re-)joining group
2023-04-26 11:50:28,893 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Successfully joined group with generation Generation{generationId=145, memberId='consumer-book-group-8-b5690281-9793-4dee-b0cf-bed76afe4b48', protocol='range'}
2023-04-26 11:50:28,893 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Finished assignment for group at generation 145: {consumer-book-group-8-b5690281-9793-4dee-b0cf-bed76afe4b48=Assignment(partitions=[my-topic-0])}
2023-04-26 11:50:28,897 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Successfully synced group in generation Generation{generationId=145, memberId='consumer-book-group-8-b5690281-9793-4dee-b0cf-bed76afe4b48', protocol='range'}
2023-04-26 11:50:28,898 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:50:28,898 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:50:28,901 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:50:28,905 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.425 seconds (JVM running for 501.138)
2023-04-26 11:50:28,911 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:50:28,912 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:50:33,250 INFO org.apache.catalina.core.StandardService [Thread-119] Stopping service [Tomcat]
2023-04-26 11:50:33,253 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-119] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c2aaadee62176f290761', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:33,254 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-119] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c2aaadee62176f290761', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:33,255 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-119] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-9-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:50:33,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:50:33,262 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Member consumer-book-group-8-b5690281-9793-4dee-b0cf-bed76afe4b48 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:50:33,263 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:33,263 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:33,263 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:50:33,263 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:50:33,264 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-8, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:50:33,267 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:50:33,267 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:50:33,267 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:50:33,272 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-8 unregistered
2023-04-26 11:50:33,277 INFO org.spark_project.jetty.server.AbstractConnector [Thread-119] Stopped Spark@43540428{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:33,279 INFO org.apache.spark.ui.SparkUI [Thread-119] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:50:33,286 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-1] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:50:33,300 INFO org.apache.spark.storage.memory.MemoryStore [Thread-119] MemoryStore cleared
2023-04-26 11:50:33,300 INFO org.apache.spark.storage.BlockManager [Thread-119] BlockManager stopped
2023-04-26 11:50:33,301 INFO org.apache.spark.storage.BlockManagerMaster [Thread-119] BlockManagerMaster stopped
2023-04-26 11:50:33,302 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:50:33,313 INFO org.apache.spark.SparkContext [Thread-119] Successfully stopped SparkContext
2023-04-26 11:50:33,314 INFO org.apache.spark.SparkContext [Thread-119] SparkContext already stopped.
2023-04-26 11:50:33,317 INFO com.zaxxer.hikari.HikariDataSource [Thread-119] HikariPool-8 - Shutdown initiated...
2023-04-26 11:50:33,323 INFO com.zaxxer.hikari.HikariDataSource [Thread-119] HikariPool-8 - Shutdown completed.
2023-04-26 11:50:33,596 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:50:33,597 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:50:34,364 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:50:34,365 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:50:34,396 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:50:34,443 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:50:34,448 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c2b2adee62176f290762', description='null'}-localhost:27017] Opened connection [connectionId{localValue:19, serverValue:60}] to localhost:27017
2023-04-26 11:50:34,446 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c2b2adee62176f290762', description='null'}-localhost:27017] Opened connection [connectionId{localValue:18, serverValue:59}] to localhost:27017
2023-04-26 11:50:34,461 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c2b2adee62176f290762', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1804053}
2023-04-26 11:50:34,771 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:50:34,785 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-9 - Starting...
2023-04-26 11:50:34,791 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-9 - Start completed.
2023-04-26 11:50:34,792 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:50:34,915 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:50:35,168 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:50:35,169 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:50:35,171 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:50:35,172 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:50:35,172 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:50:35,173 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:50:35,174 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:50:35,226 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 37027.
2023-04-26 11:50:35,230 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:50:35,232 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:50:35,232 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:50:35,232 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:50:35,233 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-b30ab857-d40d-49a4-b42d-02fbdfe37ade
2023-04-26 11:50:35,234 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:50:35,236 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:50:35,241 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:50:35,244 INFO org.spark_project.jetty.server.Server [restartedMain] Started @507477ms
2023-04-26 11:50:35,245 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@25bd761e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:50:35,245 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:50:35,246 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6ea6a987{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,246 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@9febd01{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,247 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13cbe818{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,247 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d0861f9{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,248 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@639014e{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,248 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7ad3a23d{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,249 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@36141e57{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,249 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@288da6c5{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,250 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6670e1eb{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,250 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1d57552{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,251 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@17252599{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,253 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@52db0236{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,253 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@33c5de3f{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,254 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@199052f0{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,255 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2727a5b6{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2de7d9d6{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@304ece73{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,258 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2b520d58{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,259 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@31420791{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,260 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@22785106{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,261 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@64832e6c{/static,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,262 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5f80d769{/,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,263 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7e5f2d87{/api,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,264 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@63420ed0{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,265 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3a20b64e{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:50:35,266 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:50:35,309 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:50:35,316 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38845.
2023-04-26 11:50:35,317 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:38845
2023-04-26 11:50:35,318 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:50:35,318 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 38845, None)
2023-04-26 11:50:35,319 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:38845 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 38845, None)
2023-04-26 11:50:35,320 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 38845, None)
2023-04-26 11:50:35,320 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 38845, None)
2023-04-26 11:50:35,322 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b9247fe{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:50:37,010 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-9
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:50:37,016 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:50:37,017 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:50:37,017 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490037016
2023-04-26 11:50:37,017 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-9, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:50:37,038 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:50:37,038 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:50:37,039 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:50:37,045 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.509 seconds (JVM running for 509.278)
2023-04-26 11:50:37,050 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:50:37,050 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:50:37,050 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] (Re-)joining group
2023-04-26 11:50:37,061 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:50:37,062 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] (Re-)joining group
2023-04-26 11:50:37,065 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Successfully joined group with generation Generation{generationId=147, memberId='consumer-book-group-9-5aabca3c-ddb9-4ab0-8683-e54a1641411d', protocol='range'}
2023-04-26 11:50:37,066 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Finished assignment for group at generation 147: {consumer-book-group-9-5aabca3c-ddb9-4ab0-8683-e54a1641411d=Assignment(partitions=[my-topic-0])}
2023-04-26 11:50:37,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Successfully synced group in generation Generation{generationId=147, memberId='consumer-book-group-9-5aabca3c-ddb9-4ab0-8683-e54a1641411d', protocol='range'}
2023-04-26 11:50:37,071 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:50:37,072 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:50:37,078 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:54:04,243 INFO org.apache.catalina.core.StandardService [Thread-135] Stopping service [Tomcat]
2023-04-26 11:54:04,249 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-135] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c2b2adee62176f290762', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:04,251 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-135] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c2b2adee62176f290762', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:04,255 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-135] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-10-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:04,263 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:54:04,263 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Member consumer-book-group-9-5aabca3c-ddb9-4ab0-8683-e54a1641411d sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:54:04,268 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:04,268 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:04,268 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:54:04,269 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:04,269 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-9, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:04,270 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:54:04,271 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:54:04,271 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:54:04,281 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-9 unregistered
2023-04-26 11:54:04,295 INFO org.spark_project.jetty.server.AbstractConnector [Thread-135] Stopped Spark@25bd761e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:04,297 INFO org.apache.spark.ui.SparkUI [Thread-135] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:54:04,300 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:54:04,320 INFO org.apache.spark.storage.memory.MemoryStore [Thread-135] MemoryStore cleared
2023-04-26 11:54:04,320 INFO org.apache.spark.storage.BlockManager [Thread-135] BlockManager stopped
2023-04-26 11:54:04,321 INFO org.apache.spark.storage.BlockManagerMaster [Thread-135] BlockManagerMaster stopped
2023-04-26 11:54:04,321 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2023-04-26 11:54:04,393 INFO org.apache.spark.SparkContext [Thread-135] Successfully stopped SparkContext
2023-04-26 11:54:04,393 INFO org.apache.spark.SparkContext [Thread-135] SparkContext already stopped.
2023-04-26 11:54:04,396 INFO com.zaxxer.hikari.HikariDataSource [Thread-135] HikariPool-9 - Shutdown initiated...
2023-04-26 11:54:04,410 INFO com.zaxxer.hikari.HikariDataSource [Thread-135] HikariPool-9 - Shutdown completed.
2023-04-26 11:54:04,791 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:54:04,791 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:54:05,587 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:54:05,587 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:54:05,618 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:54:05,701 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:54:05,702 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c385adee62176f290763', description='null'}-localhost:27017] Opened connection [connectionId{localValue:20, serverValue:61}] to localhost:27017
2023-04-26 11:54:05,702 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c385adee62176f290763', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=4805149}
2023-04-26 11:54:05,709 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c385adee62176f290763', description='null'}-localhost:27017] Opened connection [connectionId{localValue:21, serverValue:62}] to localhost:27017
2023-04-26 11:54:06,098 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:54:06,114 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-10 - Starting...
2023-04-26 11:54:06,118 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-10 - Start completed.
2023-04-26 11:54:06,119 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:54:06,202 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:54:06,542 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:54:06,543 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:54:06,545 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:54:06,546 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:54:06,546 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:54:06,546 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:54:06,547 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:54:06,621 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 40427.
2023-04-26 11:54:06,630 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:54:06,633 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:54:06,635 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:54:06,635 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:54:06,636 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-1c49081a-942e-4af3-9c27-682298c875ee
2023-04-26 11:54:06,636 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:54:06,638 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:54:06,642 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:54:06,644 INFO org.spark_project.jetty.server.Server [restartedMain] Started @718877ms
2023-04-26 11:54:06,645 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@6f77cdca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:06,645 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:54:06,646 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@25e47649{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,646 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b0f5659{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,647 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2fe54606{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,647 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7eadc7ad{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,648 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@787da00f{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,648 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79c19cc7{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,649 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7c11208f{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,650 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c91000f{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,650 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79f9b84a{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,651 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@c2b2416{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,651 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@794b6844{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,652 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1dbe8e1a{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,653 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@29b15e0f{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,653 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cefc4bb{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,654 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5ec48a2a{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@37e311b6{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@14016063{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@16c9b444{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,657 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c26f96d{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,657 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@43e73bfe{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,658 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5cfa5999{/static,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,658 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cabdd6{/,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,659 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5c7cd1d3{/api,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,660 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@28869ab6{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,660 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a70b67d{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:06,660 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:54:06,687 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:54:06,693 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46375.
2023-04-26 11:54:06,693 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:46375
2023-04-26 11:54:06,694 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:54:06,694 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 46375, None)
2023-04-26 11:54:06,695 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:46375 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 46375, None)
2023-04-26 11:54:06,695 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 46375, None)
2023-04-26 11:54:06,695 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 46375, None)
2023-04-26 11:54:06,697 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@785c5d40{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:08,271 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-10
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:54:08,277 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:54:08,277 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:54:08,278 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490248277
2023-04-26 11:54:08,278 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-10, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:54:08,285 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:54:08,285 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:54:08,286 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:54:08,288 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] (Re-)joining group
2023-04-26 11:54:08,298 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:54:08,299 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] (Re-)joining group
2023-04-26 11:54:08,302 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Successfully joined group with generation Generation{generationId=149, memberId='consumer-book-group-10-53cfbb99-8981-47e6-98e9-92f789f11a71', protocol='range'}
2023-04-26 11:54:08,302 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Finished assignment for group at generation 149: {consumer-book-group-10-53cfbb99-8981-47e6-98e9-92f789f11a71=Assignment(partitions=[my-topic-0])}
2023-04-26 11:54:08,306 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.597 seconds (JVM running for 720.539)
2023-04-26 11:54:08,306 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Successfully synced group in generation Generation{generationId=149, memberId='consumer-book-group-10-53cfbb99-8981-47e6-98e9-92f789f11a71', protocol='range'}
2023-04-26 11:54:08,307 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:54:08,307 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:54:08,312 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:54:08,312 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:54:08,316 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:54:27,741 INFO org.apache.catalina.core.StandardService [Thread-152] Stopping service [Tomcat]
2023-04-26 11:54:27,744 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-152] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c385adee62176f290763', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:27,745 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-152] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c385adee62176f290763', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:27,746 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-152] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-11-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:27,750 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:54:27,751 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Member consumer-book-group-10-53cfbb99-8981-47e6-98e9-92f789f11a71 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:54:27,751 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:27,751 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:27,752 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:54:27,752 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:27,752 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-10, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:27,754 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:54:27,755 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:54:27,755 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:54:27,760 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-10 unregistered
2023-04-26 11:54:27,772 INFO org.spark_project.jetty.server.AbstractConnector [Thread-152] Stopped Spark@6f77cdca{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:27,774 INFO org.apache.spark.ui.SparkUI [Thread-152] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:54:27,777 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:54:27,791 INFO org.apache.spark.storage.memory.MemoryStore [Thread-152] MemoryStore cleared
2023-04-26 11:54:27,791 INFO org.apache.spark.storage.BlockManager [Thread-152] BlockManager stopped
2023-04-26 11:54:27,792 INFO org.apache.spark.storage.BlockManagerMaster [Thread-152] BlockManagerMaster stopped
2023-04-26 11:54:27,792 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-26 11:54:27,803 INFO org.apache.spark.SparkContext [Thread-152] Successfully stopped SparkContext
2023-04-26 11:54:27,804 INFO org.apache.spark.SparkContext [Thread-152] SparkContext already stopped.
2023-04-26 11:54:27,806 INFO com.zaxxer.hikari.HikariDataSource [Thread-152] HikariPool-10 - Shutdown initiated...
2023-04-26 11:54:27,809 INFO com.zaxxer.hikari.HikariDataSource [Thread-152] HikariPool-10 - Shutdown completed.
2023-04-26 11:54:28,151 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:54:28,151 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:54:28,757 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:54:28,758 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:54:28,785 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:54:28,832 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:54:28,877 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c39cadee62176f290764', description='null'}-localhost:27017] Opened connection [connectionId{localValue:22, serverValue:63}] to localhost:27017
2023-04-26 11:54:28,926 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c39cadee62176f290764', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=43880235}
2023-04-26 11:54:28,927 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c39cadee62176f290764', description='null'}-localhost:27017] Opened connection [connectionId{localValue:23, serverValue:64}] to localhost:27017
2023-04-26 11:54:29,091 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:54:29,107 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-11 - Starting...
2023-04-26 11:54:29,112 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-11 - Start completed.
2023-04-26 11:54:29,113 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:54:29,218 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:54:29,516 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:54:29,517 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:54:29,519 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:54:29,519 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:54:29,520 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:54:29,520 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:54:29,520 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:54:29,568 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 34301.
2023-04-26 11:54:29,570 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:54:29,572 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:54:29,573 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:54:29,573 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:54:29,574 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-0f4261e8-1650-4dd8-b515-28093fad8a44
2023-04-26 11:54:29,576 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:54:29,578 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:54:29,592 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:54:29,602 INFO org.spark_project.jetty.server.Server [restartedMain] Started @741835ms
2023-04-26 11:54:29,604 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@10dbc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:29,604 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:54:29,605 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@269df452{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,606 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3a4750d{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,606 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b6f71d{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,607 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49b2976c{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,608 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@c4d56c{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,613 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20e8d464{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,614 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1056d17b{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,615 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d022dea{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,616 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6bcbfe93{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,618 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@d665c7a{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,618 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2b1d89a4{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,619 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@772c8c50{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,620 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@43a7cb40{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,620 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7c1dcac2{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,621 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3b0a3c4c{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,622 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@28d77971{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,623 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@55575ae0{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,623 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@478ed152{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,624 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d0c6db3{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,625 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e038592{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,626 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51ec58e8{/static,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,627 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@60d917c6{/,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,627 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ef68f9b{/api,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,628 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3fe382ad{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,628 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@172cc5b0{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:29,629 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:54:29,657 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:54:29,669 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35061.
2023-04-26 11:54:29,670 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:35061
2023-04-26 11:54:29,670 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:54:29,671 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 35061, None)
2023-04-26 11:54:29,672 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:35061 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 35061, None)
2023-04-26 11:54:29,673 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 35061, None)
2023-04-26 11:54:29,673 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 35061, None)
2023-04-26 11:54:29,675 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3551c501{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:31,447 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-11
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:54:31,453 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:54:31,453 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:54:31,453 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490271453
2023-04-26 11:54:31,454 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-11, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:54:31,463 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:54:31,464 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:54:31,465 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:54:31,467 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] (Re-)joining group
2023-04-26 11:54:31,471 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:54:31,471 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.389 seconds (JVM running for 743.704)
2023-04-26 11:54:31,471 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] (Re-)joining group
2023-04-26 11:54:31,474 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Successfully joined group with generation Generation{generationId=151, memberId='consumer-book-group-11-39fdddac-8bd9-45b0-9266-323c3034abc6', protocol='range'}
2023-04-26 11:54:31,476 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:54:31,475 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Finished assignment for group at generation 151: {consumer-book-group-11-39fdddac-8bd9-45b0-9266-323c3034abc6=Assignment(partitions=[my-topic-0])}
2023-04-26 11:54:31,476 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:54:31,479 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Successfully synced group in generation Generation{generationId=151, memberId='consumer-book-group-11-39fdddac-8bd9-45b0-9266-323c3034abc6', protocol='range'}
2023-04-26 11:54:31,480 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:54:31,480 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:54:31,484 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:54:39,872 INFO org.apache.catalina.core.StandardService [Thread-169] Stopping service [Tomcat]
2023-04-26 11:54:39,877 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-169] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c39cadee62176f290764', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:39,884 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-169] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c39cadee62176f290764', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:39,885 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-169] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-12-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:54:39,889 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:54:39,889 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Member consumer-book-group-11-39fdddac-8bd9-45b0-9266-323c3034abc6 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:54:39,896 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:39,897 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:39,897 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:54:39,898 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:54:39,898 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-11, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:54:39,899 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:54:39,899 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:54:39,899 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:54:39,903 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-11 unregistered
2023-04-26 11:54:39,911 INFO org.spark_project.jetty.server.AbstractConnector [Thread-169] Stopped Spark@10dbc22d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:39,917 INFO org.apache.spark.ui.SparkUI [Thread-169] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:54:39,921 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:54:39,930 INFO org.apache.spark.storage.memory.MemoryStore [Thread-169] MemoryStore cleared
2023-04-26 11:54:39,930 INFO org.apache.spark.storage.BlockManager [Thread-169] BlockManager stopped
2023-04-26 11:54:39,930 INFO org.apache.spark.storage.BlockManagerMaster [Thread-169] BlockManagerMaster stopped
2023-04-26 11:54:39,931 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:54:39,943 INFO org.apache.spark.SparkContext [Thread-169] Successfully stopped SparkContext
2023-04-26 11:54:39,943 INFO org.apache.spark.SparkContext [Thread-169] SparkContext already stopped.
2023-04-26 11:54:39,945 INFO com.zaxxer.hikari.HikariDataSource [Thread-169] HikariPool-11 - Shutdown initiated...
2023-04-26 11:54:39,949 INFO com.zaxxer.hikari.HikariDataSource [Thread-169] HikariPool-11 - Shutdown completed.
2023-04-26 11:54:40,372 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:54:40,373 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:54:41,209 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:54:41,210 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:54:41,238 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:54:41,290 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:54:41,292 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c3a9adee62176f290765', description='null'}-localhost:27017] Opened connection [connectionId{localValue:24, serverValue:65}] to localhost:27017
2023-04-26 11:54:41,292 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c3a9adee62176f290765', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1271229}
2023-04-26 11:54:41,402 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c3a9adee62176f290765', description='null'}-localhost:27017] Opened connection [connectionId{localValue:25, serverValue:66}] to localhost:27017
2023-04-26 11:54:41,560 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:54:41,579 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-12 - Starting...
2023-04-26 11:54:41,585 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-12 - Start completed.
2023-04-26 11:54:41,586 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:54:41,666 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:54:42,037 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:54:42,038 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:54:42,039 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:54:42,040 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:54:42,040 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:54:42,040 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:54:42,041 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:54:42,105 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 46041.
2023-04-26 11:54:42,111 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:54:42,113 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:54:42,114 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:54:42,114 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:54:42,115 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-54d8e340-60c5-4d11-85dd-747a1993cc0e
2023-04-26 11:54:42,116 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:54:42,118 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:54:42,121 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:54:42,124 INFO org.spark_project.jetty.server.Server [restartedMain] Started @754357ms
2023-04-26 11:54:42,125 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@778870e3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:54:42,126 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:54:42,126 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@70cec427{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,127 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3c4655c4{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,127 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2fc0d324{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,128 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1bfbb157{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,128 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1d92a1f3{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,129 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13742ff0{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,130 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3a049749{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,130 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cb3f857{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,131 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7426530b{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,132 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@461ff9d0{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,132 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@583f9085{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,133 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3badba95{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,133 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7d5508e0{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,134 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@443dafe3{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,135 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@60a2b459{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,135 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@368dc3ca{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,136 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@634acff3{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,136 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4a2136ce{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,137 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3fd443af{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,138 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@679f540c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,139 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@529f3a5b{/static,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,139 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@114be180{/,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,140 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@c9f113d{/api,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,140 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3adba608{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,141 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@74d20732{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:54:42,141 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:54:42,171 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:54:42,178 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36763.
2023-04-26 11:54:42,179 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:36763
2023-04-26 11:54:42,179 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:54:42,179 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 36763, None)
2023-04-26 11:54:42,180 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:36763 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 36763, None)
2023-04-26 11:54:42,181 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 36763, None)
2023-04-26 11:54:42,181 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 36763, None)
2023-04-26 11:54:42,183 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@61b0d56c{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:54:43,764 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-12
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:54:43,770 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:54:43,770 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:54:43,771 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490283770
2023-04-26 11:54:43,771 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-12, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:54:43,779 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:54:43,779 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:54:43,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:54:43,786 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] (Re-)joining group
2023-04-26 11:54:43,791 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:54:43,791 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] (Re-)joining group
2023-04-26 11:54:43,794 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Successfully joined group with generation Generation{generationId=153, memberId='consumer-book-group-12-d9db6d2a-572a-4930-91a7-6474f199bd1c', protocol='range'}
2023-04-26 11:54:43,794 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Finished assignment for group at generation 153: {consumer-book-group-12-d9db6d2a-572a-4930-91a7-6474f199bd1c=Assignment(partitions=[my-topic-0])}
2023-04-26 11:54:43,799 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Successfully synced group in generation Generation{generationId=153, memberId='consumer-book-group-12-d9db6d2a-572a-4930-91a7-6474f199bd1c', protocol='range'}
2023-04-26 11:54:43,800 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:54:43,800 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:54:43,808 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:54:43,830 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.565 seconds (JVM running for 756.063)
2023-04-26 11:54:43,835 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:54:43,835 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:57:07,791 INFO org.apache.catalina.core.StandardService [Thread-185] Stopping service [Tomcat]
2023-04-26 11:57:07,793 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-185] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c3a9adee62176f290765', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:07,794 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-185] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c3a9adee62176f290765', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:07,794 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-185] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-13-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:07,796 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:57:07,797 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Member consumer-book-group-12-d9db6d2a-572a-4930-91a7-6474f199bd1c sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:57:07,797 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:57:07,798 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:57:07,798 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:57:07,799 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:57:07,799 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-12, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:57:07,800 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:57:07,801 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:57:07,801 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:57:07,804 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-12 unregistered
2023-04-26 11:57:07,814 INFO org.spark_project.jetty.server.AbstractConnector [Thread-185] Stopped Spark@778870e3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:57:07,817 INFO org.apache.spark.ui.SparkUI [Thread-185] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:57:07,819 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-0] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:57:07,830 INFO org.apache.spark.storage.memory.MemoryStore [Thread-185] MemoryStore cleared
2023-04-26 11:57:07,830 INFO org.apache.spark.storage.BlockManager [Thread-185] BlockManager stopped
2023-04-26 11:57:07,831 INFO org.apache.spark.storage.BlockManagerMaster [Thread-185] BlockManagerMaster stopped
2023-04-26 11:57:07,832 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2023-04-26 11:57:07,838 INFO org.apache.spark.SparkContext [Thread-185] Successfully stopped SparkContext
2023-04-26 11:57:07,838 INFO org.apache.spark.SparkContext [Thread-185] SparkContext already stopped.
2023-04-26 11:57:07,839 INFO com.zaxxer.hikari.HikariDataSource [Thread-185] HikariPool-12 - Shutdown initiated...
2023-04-26 11:57:07,842 INFO com.zaxxer.hikari.HikariDataSource [Thread-185] HikariPool-12 - Shutdown completed.
2023-04-26 11:57:08,049 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:57:08,050 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:57:08,756 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:57:08,756 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:57:08,796 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:57:08,863 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c43cadee62176f290766', description='null'}-localhost:27017] Opened connection [connectionId{localValue:26, serverValue:67}] to localhost:27017
2023-04-26 11:57:08,863 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c43cadee62176f290766', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=847272}
2023-04-26 11:57:08,864 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:57:08,870 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c43cadee62176f290766', description='null'}-localhost:27017] Opened connection [connectionId{localValue:27, serverValue:68}] to localhost:27017
2023-04-26 11:57:09,166 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:57:09,186 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-13 - Starting...
2023-04-26 11:57:09,193 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-13 - Start completed.
2023-04-26 11:57:09,194 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:57:09,293 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:57:09,621 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:57:09,622 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:57:09,624 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:57:09,625 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:57:09,625 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:57:09,625 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:57:09,625 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:57:09,686 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 39307.
2023-04-26 11:57:09,688 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:57:09,690 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:57:09,691 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:57:09,692 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:57:09,693 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-9d533f98-8d1b-4108-b15a-8d9859326575
2023-04-26 11:57:09,693 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:57:09,695 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:57:09,702 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:57:09,704 INFO org.spark_project.jetty.server.Server [restartedMain] Started @901936ms
2023-04-26 11:57:09,705 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@70bec08b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:57:09,706 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:57:09,706 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@76c0d702{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,707 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@27f59b1{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,708 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a6593a9{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,710 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59755507{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,711 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@29fdf1ec{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,712 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51b797b3{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,713 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@719aef7{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,714 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@74b70e7e{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,715 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3203f395{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,716 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5f64f069{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,717 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@15408364{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,718 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59c8bb4c{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,718 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@747a74bb{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,719 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@ce525e5{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,719 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1dafdcbe{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,720 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1a1169c{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,720 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@26d965bf{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,720 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@336b68c{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,721 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@601fc078{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,721 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69033f11{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,722 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49a4b13{/static,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,723 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@322e0fda{/,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,723 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2c2c05e7{/api,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,724 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@ab34680{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,725 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4821c8d3{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:57:09,725 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:57:09,760 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:57:09,772 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41569.
2023-04-26 11:57:09,772 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:41569
2023-04-26 11:57:09,773 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:57:09,773 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 41569, None)
2023-04-26 11:57:09,774 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:41569 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 41569, None)
2023-04-26 11:57:09,776 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 41569, None)
2023-04-26 11:57:09,776 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 41569, None)
2023-04-26 11:57:09,778 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@57cd2f16{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:11,157 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-13
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:57:11,161 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:57:11,161 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:57:11,162 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490431161
2023-04-26 11:57:11,162 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-13, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:57:11,196 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:57:11,197 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:57:11,198 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:57:11,208 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] (Re-)joining group
2023-04-26 11:57:11,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:57:11,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] (Re-)joining group
2023-04-26 11:57:11,217 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Successfully joined group with generation Generation{generationId=155, memberId='consumer-book-group-13-f22ed525-94e1-40c7-8656-5ded2c8fefe5', protocol='range'}
2023-04-26 11:57:11,217 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Finished assignment for group at generation 155: {consumer-book-group-13-f22ed525-94e1-40c7-8656-5ded2c8fefe5=Assignment(partitions=[my-topic-0])}
2023-04-26 11:57:11,221 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Successfully synced group in generation Generation{generationId=155, memberId='consumer-book-group-13-f22ed525-94e1-40c7-8656-5ded2c8fefe5', protocol='range'}
2023-04-26 11:57:11,221 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:57:11,222 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:57:11,230 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:57:11,280 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.276 seconds (JVM running for 903.513)
2023-04-26 11:57:11,285 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:57:11,286 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 11:57:20,585 INFO org.apache.catalina.core.StandardService [Thread-202] Stopping service [Tomcat]
2023-04-26 11:57:20,601 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-202] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c43cadee62176f290766', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:20,606 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-202] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c43cadee62176f290766', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:20,607 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-202] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-14-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 11:57:20,611 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 11:57:20,611 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Member consumer-book-group-13-f22ed525-94e1-40c7-8656-5ded2c8fefe5 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 11:57:20,616 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:57:20,616 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:57:20,617 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 11:57:20,617 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 11:57:20,617 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-13, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 11:57:20,618 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 11:57:20,618 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 11:57:20,618 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 11:57:20,622 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-13 unregistered
2023-04-26 11:57:20,629 INFO org.spark_project.jetty.server.AbstractConnector [Thread-202] Stopped Spark@70bec08b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:57:20,631 INFO org.apache.spark.ui.SparkUI [Thread-202] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 11:57:20,636 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 11:57:20,728 INFO org.apache.spark.storage.memory.MemoryStore [Thread-202] MemoryStore cleared
2023-04-26 11:57:20,728 INFO org.apache.spark.storage.BlockManager [Thread-202] BlockManager stopped
2023-04-26 11:57:20,729 INFO org.apache.spark.storage.BlockManagerMaster [Thread-202] BlockManagerMaster stopped
2023-04-26 11:57:20,730 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 11:57:20,769 INFO org.apache.spark.SparkContext [Thread-202] Successfully stopped SparkContext
2023-04-26 11:57:20,769 INFO org.apache.spark.SparkContext [Thread-202] SparkContext already stopped.
2023-04-26 11:57:20,771 INFO com.zaxxer.hikari.HikariDataSource [Thread-202] HikariPool-13 - Shutdown initiated...
2023-04-26 11:57:20,819 INFO com.zaxxer.hikari.HikariDataSource [Thread-202] HikariPool-13 - Shutdown completed.
2023-04-26 11:57:21,329 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 11:57:21,330 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 11:57:22,239 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 11:57:22,239 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 11:57:22,268 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 11:57:22,311 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 11:57:22,313 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c44aadee62176f290767', description='null'}-localhost:27017] Opened connection [connectionId{localValue:28, serverValue:69}] to localhost:27017
2023-04-26 11:57:22,313 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c44aadee62176f290767', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=900058}
2023-04-26 11:57:22,314 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c44aadee62176f290767', description='null'}-localhost:27017] Opened connection [connectionId{localValue:29, serverValue:70}] to localhost:27017
2023-04-26 11:57:22,603 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 11:57:22,634 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-14 - Starting...
2023-04-26 11:57:22,639 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-14 - Start completed.
2023-04-26 11:57:22,639 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 11:57:22,717 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 11:57:23,013 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 11:57:23,013 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 11:57:23,014 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 11:57:23,015 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 11:57:23,015 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 11:57:23,015 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 11:57:23,015 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 11:57:23,072 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 44699.
2023-04-26 11:57:23,081 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 11:57:23,083 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 11:57:23,083 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 11:57:23,084 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 11:57:23,085 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-dd353b8b-c7ef-4495-b1aa-248b684cb271
2023-04-26 11:57:23,086 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 11:57:23,088 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 11:57:23,094 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 11:57:23,097 INFO org.spark_project.jetty.server.Server [restartedMain] Started @915330ms
2023-04-26 11:57:23,098 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@7632e0b1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 11:57:23,098 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 11:57:23,099 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@544047da{/jobs,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,100 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7628ff41{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,100 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d58cc40{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,101 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3c8e8832{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,101 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6aa666ee{/stages,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,102 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5bc54e0c{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,102 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@40e4a3f8{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,103 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@8636cce{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,104 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51abfa3a{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,105 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20ef7b2d{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,106 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@45f1e7ab{/storage,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,106 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5667e6c7{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,107 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5893bc1b{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,108 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3fe8237{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,108 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4978e15c{/environment,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,109 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2040776a{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,110 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6576741d{/executors,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,111 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@12eebdbe{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,111 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1c92dcbe{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,112 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3fca1361{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,114 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@694a5e19{/static,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,115 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@eae1dc3{/,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,116 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d35784{/api,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,116 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@506c3c96{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,117 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2ed2635d{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 11:57:23,118 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 11:57:23,147 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 11:57:23,150 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45233.
2023-04-26 11:57:23,151 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:45233
2023-04-26 11:57:23,151 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 11:57:23,152 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 45233, None)
2023-04-26 11:57:23,153 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:45233 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 45233, None)
2023-04-26 11:57:23,156 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 45233, None)
2023-04-26 11:57:23,157 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 45233, None)
2023-04-26 11:57:23,161 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@14ab7b49{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 11:57:24,634 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-14
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 11:57:24,639 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 11:57:24,639 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 11:57:24,640 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490444639
2023-04-26 11:57:24,640 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-14, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 11:57:24,646 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 11:57:24,647 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 11:57:24,647 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 11:57:24,649 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] (Re-)joining group
2023-04-26 11:57:24,653 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 11:57:24,654 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] (Re-)joining group
2023-04-26 11:57:24,661 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Successfully joined group with generation Generation{generationId=157, memberId='consumer-book-group-14-d347927b-581b-4c67-a008-425973d7e1ac', protocol='range'}
2023-04-26 11:57:24,662 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Finished assignment for group at generation 157: {consumer-book-group-14-d347927b-581b-4c67-a008-425973d7e1ac=Assignment(partitions=[my-topic-0])}
2023-04-26 11:57:24,671 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Successfully synced group in generation Generation{generationId=157, memberId='consumer-book-group-14-d347927b-581b-4c67-a008-425973d7e1ac', protocol='range'}
2023-04-26 11:57:24,672 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 11:57:24,672 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 11:57:24,674 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.472 seconds (JVM running for 916.907)
2023-04-26 11:57:24,679 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 11:57:24,679 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 11:57:24,679 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:00:40,826 INFO org.apache.catalina.core.StandardService [Thread-219] Stopping service [Tomcat]
2023-04-26 12:00:40,829 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-219] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c44aadee62176f290767', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:40,830 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-219] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c44aadee62176f290767', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:40,831 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-219] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-15-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:40,834 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:00:40,835 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Member consumer-book-group-14-d347927b-581b-4c67-a008-425973d7e1ac sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:00:40,835 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:00:40,835 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:00:40,835 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:00:40,836 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:00:40,836 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-14, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:00:40,839 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:00:40,839 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:00:40,839 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:00:40,841 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-14 unregistered
2023-04-26 12:00:40,847 INFO org.spark_project.jetty.server.AbstractConnector [Thread-219] Stopped Spark@7632e0b1{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:00:40,889 INFO org.apache.spark.ui.SparkUI [Thread-219] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:00:40,891 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:00:40,900 INFO org.apache.spark.storage.memory.MemoryStore [Thread-219] MemoryStore cleared
2023-04-26 12:00:40,900 INFO org.apache.spark.storage.BlockManager [Thread-219] BlockManager stopped
2023-04-26 12:00:40,901 INFO org.apache.spark.storage.BlockManagerMaster [Thread-219] BlockManagerMaster stopped
2023-04-26 12:00:40,901 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2023-04-26 12:00:40,907 INFO org.apache.spark.SparkContext [Thread-219] Successfully stopped SparkContext
2023-04-26 12:00:40,908 INFO org.apache.spark.SparkContext [Thread-219] SparkContext already stopped.
2023-04-26 12:00:40,909 INFO com.zaxxer.hikari.HikariDataSource [Thread-219] HikariPool-14 - Shutdown initiated...
2023-04-26 12:00:40,914 INFO com.zaxxer.hikari.HikariDataSource [Thread-219] HikariPool-14 - Shutdown completed.
2023-04-26 12:00:41,196 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:00:41,196 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:00:41,988 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:00:41,988 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:00:42,025 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:00:42,082 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:00:42,100 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c512adee62176f290768', description='null'}-localhost:27017] Opened connection [connectionId{localValue:30, serverValue:71}] to localhost:27017
2023-04-26 12:00:42,100 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c512adee62176f290768', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=17083662}
2023-04-26 12:00:42,100 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c512adee62176f290768', description='null'}-localhost:27017] Opened connection [connectionId{localValue:31, serverValue:72}] to localhost:27017
2023-04-26 12:00:42,359 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:00:42,371 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-15 - Starting...
2023-04-26 12:00:42,376 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-15 - Start completed.
2023-04-26 12:00:42,376 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:00:42,464 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:00:42,784 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:00:42,785 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:00:42,786 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:00:42,786 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:00:42,786 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:00:42,787 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:00:42,787 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:00:42,847 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 45719.
2023-04-26 12:00:42,850 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:00:42,851 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:00:42,851 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:00:42,851 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:00:42,852 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-cc2e19ca-9259-40b3-8dca-56205f07dd9a
2023-04-26 12:00:42,853 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:00:42,856 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:00:42,862 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:00:42,873 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1115106ms
2023-04-26 12:00:42,875 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@1451541a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:00:42,875 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:00:42,876 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6d715010{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,876 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@108af5b1{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,876 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59979eec{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,877 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@47f8e040{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,877 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20eed97f{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,878 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@670e87ae{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,880 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@28b055d{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,881 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2711fac{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,883 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@54021bbc{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,884 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@47a2d565{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,885 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1d598121{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,886 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@175f6159{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,888 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@53c447f5{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,889 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@21cb915{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,891 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@531d70fe{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,892 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3fa4966d{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,893 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4e2e8583{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,894 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@299d4942{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,895 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@113f560f{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,896 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@a33bdbb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,898 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@300b23e3{/static,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,899 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@731fabf9{/,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,900 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@187b14bb{/api,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,901 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@664f9254{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,905 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6801ad07{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:00:42,905 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:00:42,933 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:00:42,937 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38551.
2023-04-26 12:00:42,938 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:38551
2023-04-26 12:00:42,939 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:00:42,939 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 38551, None)
2023-04-26 12:00:42,939 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:38551 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 38551, None)
2023-04-26 12:00:42,940 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 38551, None)
2023-04-26 12:00:42,940 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 38551, None)
2023-04-26 12:00:42,941 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1805cef3{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:44,314 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-15
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:00:44,319 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:00:44,319 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:00:44,319 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490644319
2023-04-26 12:00:44,320 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-15, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:00:44,326 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:00:44,327 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:00:44,328 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:00:44,333 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] (Re-)joining group
2023-04-26 12:00:44,338 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:00:44,338 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] (Re-)joining group
2023-04-26 12:00:44,341 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Successfully joined group with generation Generation{generationId=159, memberId='consumer-book-group-15-4b29ca69-e657-4bcb-9d69-7679eb69f86f', protocol='range'}
2023-04-26 12:00:44,341 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Finished assignment for group at generation 159: {consumer-book-group-15-4b29ca69-e657-4bcb-9d69-7679eb69f86f=Assignment(partitions=[my-topic-0])}
2023-04-26 12:00:44,346 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Successfully synced group in generation Generation{generationId=159, memberId='consumer-book-group-15-4b29ca69-e657-4bcb-9d69-7679eb69f86f', protocol='range'}
2023-04-26 12:00:44,347 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:00:44,347 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:00:44,353 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:00:44,361 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.219 seconds (JVM running for 1116.594)
2023-04-26 12:00:44,365 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:00:44,366 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:00:48,708 INFO org.apache.catalina.core.StandardService [Thread-235] Stopping service [Tomcat]
2023-04-26 12:00:48,711 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-235] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c512adee62176f290768', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:48,712 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-235] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c512adee62176f290768', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:48,713 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-235] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-16-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:00:48,717 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:00:48,717 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Member consumer-book-group-15-4b29ca69-e657-4bcb-9d69-7679eb69f86f sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:00:48,717 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:00:48,718 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:00:48,718 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:00:48,719 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:00:48,719 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-15, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:00:48,729 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:00:48,730 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:00:48,731 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:00:48,735 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-15 unregistered
2023-04-26 12:00:48,741 INFO org.spark_project.jetty.server.AbstractConnector [Thread-235] Stopped Spark@1451541a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:00:48,748 INFO org.apache.spark.ui.SparkUI [Thread-235] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:00:48,751 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:00:48,762 INFO org.apache.spark.storage.memory.MemoryStore [Thread-235] MemoryStore cleared
2023-04-26 12:00:48,762 INFO org.apache.spark.storage.BlockManager [Thread-235] BlockManager stopped
2023-04-26 12:00:48,763 INFO org.apache.spark.storage.BlockManagerMaster [Thread-235] BlockManagerMaster stopped
2023-04-26 12:00:48,763 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 12:00:48,770 INFO org.apache.spark.SparkContext [Thread-235] Successfully stopped SparkContext
2023-04-26 12:00:48,770 INFO org.apache.spark.SparkContext [Thread-235] SparkContext already stopped.
2023-04-26 12:00:48,771 INFO com.zaxxer.hikari.HikariDataSource [Thread-235] HikariPool-15 - Shutdown initiated...
2023-04-26 12:00:48,773 INFO com.zaxxer.hikari.HikariDataSource [Thread-235] HikariPool-15 - Shutdown completed.
2023-04-26 12:00:49,128 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:00:49,129 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:00:49,913 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:00:49,914 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:00:49,945 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:00:49,996 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:00:49,998 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c519adee62176f290769', description='null'}-localhost:27017] Opened connection [connectionId{localValue:33, serverValue:74}] to localhost:27017
2023-04-26 12:00:49,999 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c519adee62176f290769', description='null'}-localhost:27017] Opened connection [connectionId{localValue:32, serverValue:73}] to localhost:27017
2023-04-26 12:00:49,999 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c519adee62176f290769', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=835152}
2023-04-26 12:00:50,221 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:00:50,235 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-16 - Starting...
2023-04-26 12:00:50,239 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-16 - Start completed.
2023-04-26 12:00:50,240 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:00:50,325 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:00:50,590 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:00:50,590 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:00:50,592 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:00:50,592 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:00:50,592 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:00:50,593 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:00:50,593 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:00:50,639 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 43295.
2023-04-26 12:00:50,642 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:00:50,643 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:00:50,644 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:00:50,644 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:00:50,645 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-e879e262-8026-4097-9de3-7e585ce4ee96
2023-04-26 12:00:50,645 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:00:50,647 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:00:50,651 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:00:50,652 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1122885ms
2023-04-26 12:00:50,653 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@bcd9e2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:00:50,654 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:00:50,654 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49c8fea{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,654 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58ea8b28{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3d5573d{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@65c0ed6c{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,655 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5c3dde1{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@97cb5ba{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20b97717{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,656 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@427055e1{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,657 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59c7a49b{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,658 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@357a0b7c{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,659 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5e90d30b{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,659 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1e8f5a65{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,660 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a88d653{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,661 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1fcc1395{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,661 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@471c93ec{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,664 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@23a4a518{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,665 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1fa2d571{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,665 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@608d3dab{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,666 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@432d41a5{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,666 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@45a7a0bd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,667 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4ca7fc25{/static,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,668 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@45cef07f{/,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,668 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6cc7b10a{/api,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,669 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6728c615{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,670 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@55578f87{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:00:50,670 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:00:50,700 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:00:50,706 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34551.
2023-04-26 12:00:50,707 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:34551
2023-04-26 12:00:50,707 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:00:50,708 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 34551, None)
2023-04-26 12:00:50,708 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:34551 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 34551, None)
2023-04-26 12:00:50,709 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 34551, None)
2023-04-26 12:00:50,709 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 34551, None)
2023-04-26 12:00:50,711 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2a97e098{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:00:52,039 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-16
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:00:52,046 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:00:52,046 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:00:52,046 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490652046
2023-04-26 12:00:52,047 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-16, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:00:52,053 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:00:52,054 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:00:52,054 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:00:52,061 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] (Re-)joining group
2023-04-26 12:00:52,065 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:00:52,065 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] (Re-)joining group
2023-04-26 12:00:52,069 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.011 seconds (JVM running for 1124.302)
2023-04-26 12:00:52,072 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:00:52,072 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:00:52,080 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Successfully joined group with generation Generation{generationId=161, memberId='consumer-book-group-16-f8966966-71ba-436c-bc63-6f85cc0ded45', protocol='range'}
2023-04-26 12:00:52,083 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Finished assignment for group at generation 161: {consumer-book-group-16-f8966966-71ba-436c-bc63-6f85cc0ded45=Assignment(partitions=[my-topic-0])}
2023-04-26 12:00:52,088 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Successfully synced group in generation Generation{generationId=161, memberId='consumer-book-group-16-f8966966-71ba-436c-bc63-6f85cc0ded45', protocol='range'}
2023-04-26 12:00:52,088 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:00:52,088 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:00:52,091 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:04:38,350 INFO org.apache.catalina.core.StandardService [Thread-252] Stopping service [Tomcat]
2023-04-26 12:04:38,354 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-252] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c519adee62176f290769', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:38,354 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-252] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c519adee62176f290769', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:38,356 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-252] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-17-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:38,362 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:04:38,363 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Member consumer-book-group-16-f8966966-71ba-436c-bc63-6f85cc0ded45 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:04:38,363 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:04:38,363 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:04:38,363 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:04:38,364 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:04:38,364 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-16, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:04:38,367 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:04:38,368 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:04:38,368 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:04:38,371 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-16 unregistered
2023-04-26 12:04:38,379 INFO org.spark_project.jetty.server.AbstractConnector [Thread-252] Stopped Spark@bcd9e2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:04:38,380 INFO org.apache.spark.ui.SparkUI [Thread-252] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:04:38,387 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-1] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:04:38,439 INFO org.apache.spark.storage.memory.MemoryStore [Thread-252] MemoryStore cleared
2023-04-26 12:04:38,440 INFO org.apache.spark.storage.BlockManager [Thread-252] BlockManager stopped
2023-04-26 12:04:38,440 INFO org.apache.spark.storage.BlockManagerMaster [Thread-252] BlockManagerMaster stopped
2023-04-26 12:04:38,440 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-26 12:04:38,447 INFO org.apache.spark.SparkContext [Thread-252] Successfully stopped SparkContext
2023-04-26 12:04:38,447 INFO org.apache.spark.SparkContext [Thread-252] SparkContext already stopped.
2023-04-26 12:04:38,449 INFO com.zaxxer.hikari.HikariDataSource [Thread-252] HikariPool-16 - Shutdown initiated...
2023-04-26 12:04:38,451 INFO com.zaxxer.hikari.HikariDataSource [Thread-252] HikariPool-16 - Shutdown completed.
2023-04-26 12:04:38,684 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:04:38,684 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:04:39,369 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:04:39,369 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:04:39,404 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:04:39,449 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:04:39,451 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c5ffadee62176f29076a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:35, serverValue:76}] to localhost:27017
2023-04-26 12:04:39,451 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c5ffadee62176f29076a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:34, serverValue:75}] to localhost:27017
2023-04-26 12:04:39,451 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c5ffadee62176f29076a', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=991048}
2023-04-26 12:04:39,724 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:04:39,736 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-17 - Starting...
2023-04-26 12:04:39,741 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-17 - Start completed.
2023-04-26 12:04:39,741 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:04:39,812 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:04:40,125 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:04:40,126 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:04:40,127 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:04:40,127 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:04:40,127 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:04:40,128 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:04:40,128 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:04:40,186 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 36809.
2023-04-26 12:04:40,190 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:04:40,192 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:04:40,192 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:04:40,192 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:04:40,193 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-7ac22925-4678-4b6a-af2f-54ab64b088ca
2023-04-26 12:04:40,194 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:04:40,196 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:04:40,201 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:04:40,203 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1352435ms
2023-04-26 12:04:40,204 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@577ab19b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:04:40,204 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:04:40,204 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@71e393ae{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,205 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d83e1df{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,206 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@223bcfe3{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,206 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20cf5456{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,207 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d5ccd02{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,208 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1f83406f{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,208 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@633bc0ab{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,209 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@390c457e{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,209 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1213ab80{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,209 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@17161195{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,210 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2a95a544{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,210 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@71e932dd{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,210 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7e29d8cb{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,211 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5994e422{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,211 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5eacc5d1{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,212 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@66eb6b03{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,212 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@56b40895{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,213 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@287f5395{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,213 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10c58906{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,214 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d4b5b6e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,214 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5bcd1ef2{/static,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,215 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@97c1de5{/,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,215 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@354d3875{/api,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,216 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@71a329a0{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,217 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@18598144{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:04:40,217 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:04:40,268 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:04:40,277 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37843.
2023-04-26 12:04:40,278 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:37843
2023-04-26 12:04:40,278 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:04:40,278 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 37843, None)
2023-04-26 12:04:40,279 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:37843 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 37843, None)
2023-04-26 12:04:40,280 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 37843, None)
2023-04-26 12:04:40,280 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 37843, None)
2023-04-26 12:04:40,282 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@774aa47f{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:41,921 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-17
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:04:41,925 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:04:41,926 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:04:41,926 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490881925
2023-04-26 12:04:41,926 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-17, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:04:41,932 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:04:41,932 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:04:41,933 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:04:41,936 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] (Re-)joining group
2023-04-26 12:04:41,942 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:04:41,943 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] (Re-)joining group
2023-04-26 12:04:41,946 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Successfully joined group with generation Generation{generationId=163, memberId='consumer-book-group-17-cfa6489e-3e8f-43b1-98fc-b622d1842d6c', protocol='range'}
2023-04-26 12:04:41,946 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Finished assignment for group at generation 163: {consumer-book-group-17-cfa6489e-3e8f-43b1-98fc-b622d1842d6c=Assignment(partitions=[my-topic-0])}
2023-04-26 12:04:41,949 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Successfully synced group in generation Generation{generationId=163, memberId='consumer-book-group-17-cfa6489e-3e8f-43b1-98fc-b622d1842d6c', protocol='range'}
2023-04-26 12:04:41,950 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:04:41,950 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:04:41,956 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:04:41,964 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.333 seconds (JVM running for 1354.197)
2023-04-26 12:04:41,968 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:04:41,968 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:04:46,319 INFO org.apache.catalina.core.StandardService [Thread-269] Stopping service [Tomcat]
2023-04-26 12:04:46,327 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-269] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c5ffadee62176f29076a', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:46,328 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-269] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c5ffadee62176f29076a', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:46,329 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-269] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-18-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:04:46,332 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:04:46,332 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Member consumer-book-group-17-cfa6489e-3e8f-43b1-98fc-b622d1842d6c sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:04:46,333 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:04:46,334 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:04:46,334 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:04:46,336 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:04:46,336 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-17, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:04:46,337 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:04:46,337 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:04:46,337 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:04:46,341 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-17 unregistered
2023-04-26 12:04:46,350 INFO org.spark_project.jetty.server.AbstractConnector [Thread-269] Stopped Spark@577ab19b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:04:46,354 INFO org.apache.spark.ui.SparkUI [Thread-269] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:04:46,356 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:04:46,372 INFO org.apache.spark.storage.memory.MemoryStore [Thread-269] MemoryStore cleared
2023-04-26 12:04:46,372 INFO org.apache.spark.storage.BlockManager [Thread-269] BlockManager stopped
2023-04-26 12:04:46,373 INFO org.apache.spark.storage.BlockManagerMaster [Thread-269] BlockManagerMaster stopped
2023-04-26 12:04:46,373 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 12:04:46,388 INFO org.apache.spark.SparkContext [Thread-269] Successfully stopped SparkContext
2023-04-26 12:04:46,389 INFO org.apache.spark.SparkContext [Thread-269] SparkContext already stopped.
2023-04-26 12:04:46,390 INFO com.zaxxer.hikari.HikariDataSource [Thread-269] HikariPool-17 - Shutdown initiated...
2023-04-26 12:04:46,394 INFO com.zaxxer.hikari.HikariDataSource [Thread-269] HikariPool-17 - Shutdown completed.
2023-04-26 12:04:46,679 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:04:46,680 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:04:47,313 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:04:47,313 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:04:47,341 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:04:47,387 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:04:47,388 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c607adee62176f29076b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:36, serverValue:78}] to localhost:27017
2023-04-26 12:04:47,389 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c607adee62176f29076b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:37, serverValue:77}] to localhost:27017
2023-04-26 12:04:47,389 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c607adee62176f29076b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=976497}
2023-04-26 12:04:47,676 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:04:47,696 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-18 - Starting...
2023-04-26 12:04:47,702 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-18 - Start completed.
2023-04-26 12:04:47,703 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:04:47,860 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:04:48,279 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:04:48,280 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:04:48,282 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:04:48,282 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:04:48,282 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:04:48,283 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:04:48,283 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:04:48,357 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 34561.
2023-04-26 12:04:48,371 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:04:48,372 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:04:48,373 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:04:48,373 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:04:48,374 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-7e3ec5d3-04a6-49d2-9d90-e0e239042cad
2023-04-26 12:04:48,374 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:04:48,377 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:04:48,381 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:04:48,389 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1360622ms
2023-04-26 12:04:48,390 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@2a457a79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:04:48,391 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:04:48,391 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@17b65a75{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,392 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13259eb9{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,392 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7ee4a289{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,392 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7f73999e{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,393 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5ab311f7{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,393 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@655c9c4e{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,394 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e778a86{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,394 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5dab4bbf{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,394 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1f55c554{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,396 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1e6a941c{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,396 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1c4b1eed{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,397 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1b3a4868{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,397 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2af4513e{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,397 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@60f4fa08{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,398 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@248c3c8d{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,399 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6d3c597c{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,399 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@65498844{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,400 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@22aa1a5f{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,400 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@670732d3{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,401 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@687f70f6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,401 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@415dce15{/static,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,402 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@33d74c83{/,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,402 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6d187180{/api,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,403 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51f100b8{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,403 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58cbed51{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:04:48,403 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:04:48,441 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:04:48,445 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37625.
2023-04-26 12:04:48,445 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:37625
2023-04-26 12:04:48,445 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:04:48,446 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 37625, None)
2023-04-26 12:04:48,446 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:37625 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 37625, None)
2023-04-26 12:04:48,446 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 37625, None)
2023-04-26 12:04:48,447 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 37625, None)
2023-04-26 12:04:48,448 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@75666d2a{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:04:49,935 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-18
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:04:49,939 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:04:49,939 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:04:49,940 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682490889939
2023-04-26 12:04:49,940 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-18, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:04:49,945 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:04:49,946 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:04:49,948 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:04:49,948 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] (Re-)joining group
2023-04-26 12:04:49,953 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:04:49,954 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] (Re-)joining group
2023-04-26 12:04:49,957 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Successfully joined group with generation Generation{generationId=165, memberId='consumer-book-group-18-77343b22-cf7a-4d9b-9add-85049a650d98', protocol='range'}
2023-04-26 12:04:49,957 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Finished assignment for group at generation 165: {consumer-book-group-18-77343b22-cf7a-4d9b-9add-85049a650d98=Assignment(partitions=[my-topic-0])}
2023-04-26 12:04:49,960 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.343 seconds (JVM running for 1362.193)
2023-04-26 12:04:49,965 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Successfully synced group in generation Generation{generationId=165, memberId='consumer-book-group-18-77343b22-cf7a-4d9b-9add-85049a650d98', protocol='range'}
2023-04-26 12:04:49,965 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:04:49,966 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:04:49,968 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:04:49,969 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:04:49,973 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:04:56,719 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-26 12:04:57,750 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 327 ms
2023-04-26 12:05:50,358 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:38, serverValue:79}] to localhost:27017
2023-04-26 12:09:01,474 INFO org.apache.catalina.core.StandardService [Thread-286] Stopping service [Tomcat]
2023-04-26 12:09:01,475 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [Thread-286] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-26 12:09:01,491 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-286] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c607adee62176f29076b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:09:01,496 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-286] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c607adee62176f29076b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:09:01,497 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-286] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-19-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:09:01,503 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:09:01,504 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Member consumer-book-group-18-77343b22-cf7a-4d9b-9add-85049a650d98 sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:09:01,507 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:09:01,507 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:09:01,507 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:09:01,508 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:09:01,509 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-18, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:09:01,509 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:09:01,509 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:09:01,510 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:09:01,526 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-18 unregistered
2023-04-26 12:09:01,531 INFO org.spark_project.jetty.server.AbstractConnector [Thread-286] Stopped Spark@2a457a79{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:09:01,533 INFO org.apache.spark.ui.SparkUI [Thread-286] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:09:01,543 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-0] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:09:01,580 INFO org.apache.spark.storage.memory.MemoryStore [Thread-286] MemoryStore cleared
2023-04-26 12:09:01,580 INFO org.apache.spark.storage.BlockManager [Thread-286] BlockManager stopped
2023-04-26 12:09:01,581 INFO org.apache.spark.storage.BlockManagerMaster [Thread-286] BlockManagerMaster stopped
2023-04-26 12:09:01,581 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-1] OutputCommitCoordinator stopped!
2023-04-26 12:09:01,605 INFO org.apache.spark.SparkContext [Thread-286] Successfully stopped SparkContext
2023-04-26 12:09:01,605 INFO org.apache.spark.SparkContext [Thread-286] SparkContext already stopped.
2023-04-26 12:09:01,606 INFO com.zaxxer.hikari.HikariDataSource [Thread-286] HikariPool-18 - Shutdown initiated...
2023-04-26 12:09:01,611 INFO com.zaxxer.hikari.HikariDataSource [Thread-286] HikariPool-18 - Shutdown completed.
2023-04-26 12:09:02,098 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:09:02,099 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:09:02,796 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:09:02,797 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:09:02,833 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:09:02,878 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:09:02,881 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c706adee62176f29076c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:39, serverValue:80}] to localhost:27017
2023-04-26 12:09:02,881 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c706adee62176f29076c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1213934}
2023-04-26 12:09:02,899 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c706adee62176f29076c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:40, serverValue:81}] to localhost:27017
2023-04-26 12:09:03,231 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:09:03,255 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-19 - Starting...
2023-04-26 12:09:03,260 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-19 - Start completed.
2023-04-26 12:09:03,261 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:09:03,359 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:09:03,646 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:09:03,647 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:09:03,656 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:09:03,657 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:09:03,657 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:09:03,657 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:09:03,658 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:09:03,727 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 37175.
2023-04-26 12:09:03,733 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:09:03,735 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:09:03,735 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:09:03,736 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:09:03,737 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-dc214804-5b2a-4768-811d-6a5fe36ed0ab
2023-04-26 12:09:03,737 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:09:03,741 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:09:03,747 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:09:03,749 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1615982ms
2023-04-26 12:09:03,750 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@6a89a85d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:09:03,750 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:09:03,751 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5cfac573{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,752 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3dfc713{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,752 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b4a6537{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,753 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c26f743{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,753 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@667d76e9{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,753 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1be7d26a{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,754 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@31c7ffc{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,754 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58db0c33{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,754 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@551cf3ff{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,755 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@70cd0fb4{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,755 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10ce6dce{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,756 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10f44170{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,756 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@22c5db9a{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,757 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3aedc0d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,757 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@592e6a57{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,757 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6be34fc3{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,758 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@67f6402e{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,758 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@33c9bf01{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,758 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@191f17fd{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,759 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6873ce4a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,759 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3dd1045a{/static,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,760 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@439e8556{/,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,760 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@225fd227{/api,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,760 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@61ee74a3{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,761 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@56edf9fd{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:09:03,761 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:09:03,793 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:09:03,801 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35431.
2023-04-26 12:09:03,802 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:35431
2023-04-26 12:09:03,802 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:09:03,802 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 35431, None)
2023-04-26 12:09:03,803 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-1] Registering block manager 192.168.1.125:35431 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 35431, None)
2023-04-26 12:09:03,803 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 35431, None)
2023-04-26 12:09:03,804 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 35431, None)
2023-04-26 12:09:03,805 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@52dd6d1b{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:09:05,474 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-19
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:09:05,478 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:09:05,479 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:09:05,479 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682491145478
2023-04-26 12:09:05,479 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-19, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:09:05,487 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:09:05,488 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:09:05,493 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:09:05,495 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] (Re-)joining group
2023-04-26 12:09:05,500 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:09:05,500 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] (Re-)joining group
2023-04-26 12:09:05,502 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 3.531 seconds (JVM running for 1617.735)
2023-04-26 12:09:05,503 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Successfully joined group with generation Generation{generationId=167, memberId='consumer-book-group-19-642fe059-35d8-4f66-8971-699a7c13200a', protocol='range'}
2023-04-26 12:09:05,503 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Finished assignment for group at generation 167: {consumer-book-group-19-642fe059-35d8-4f66-8971-699a7c13200a=Assignment(partitions=[my-topic-0])}
2023-04-26 12:09:05,506 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Successfully synced group in generation Generation{generationId=167, memberId='consumer-book-group-19-642fe059-35d8-4f66-8971-699a7c13200a', protocol='range'}
2023-04-26 12:09:05,507 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:09:05,507 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:09:05,507 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:09:05,509 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:09:05,517 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:09:24,319 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-26 12:09:25,203 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 327 ms
2023-04-26 12:09:53,175 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:41, serverValue:82}] to localhost:27017
2023-04-26 12:10:59,325 INFO org.apache.catalina.core.StandardService [Thread-302] Stopping service [Tomcat]
2023-04-26 12:10:59,326 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [Thread-302] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-26 12:10:59,330 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-302] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='6448c706adee62176f29076c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:10:59,337 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-302] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='6448c706adee62176f29076c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:10:59,339 WARN org.apache.catalina.loader.WebappClassLoaderBase [Thread-302] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-20-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-26 12:10:59,342 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Revoke previously assigned partitions my-topic-0
2023-04-26 12:10:59,343 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Member consumer-book-group-19-642fe059-35d8-4f66-8971-699a7c13200a sending LeaveGroup request to coordinator wks-012:9092 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2023-04-26 12:10:59,343 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:10:59,343 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:10:59,343 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Unsubscribed all topics or patterns and assigned partitions
2023-04-26 12:10:59,346 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Resetting generation due to: consumer pro-actively leaving the group
2023-04-26 12:10:59,346 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-19, groupId=book-group] Request joining group due to: consumer pro-actively leaving the group
2023-04-26 12:10:59,347 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics scheduler closed
2023-04-26 12:10:59,347 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Closing reporter org.apache.kafka.common.metrics.JmxReporter
2023-04-26 12:10:59,347 INFO org.apache.kafka.common.metrics.Metrics [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] Metrics reporters closed
2023-04-26 12:10:59,352 INFO org.apache.kafka.common.utils.AppInfoParser [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] App info kafka.consumer for consumer-book-group-19 unregistered
2023-04-26 12:10:59,360 INFO org.spark_project.jetty.server.AbstractConnector [Thread-302] Stopped Spark@6a89a85d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:10:59,362 INFO org.apache.spark.ui.SparkUI [Thread-302] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-26 12:10:59,365 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-26 12:10:59,388 INFO org.apache.spark.storage.memory.MemoryStore [Thread-302] MemoryStore cleared
2023-04-26 12:10:59,389 INFO org.apache.spark.storage.BlockManager [Thread-302] BlockManager stopped
2023-04-26 12:10:59,389 INFO org.apache.spark.storage.BlockManagerMaster [Thread-302] BlockManagerMaster stopped
2023-04-26 12:10:59,390 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-26 12:10:59,399 INFO org.apache.spark.SparkContext [Thread-302] Successfully stopped SparkContext
2023-04-26 12:10:59,399 INFO org.apache.spark.SparkContext [Thread-302] SparkContext already stopped.
2023-04-26 12:10:59,401 INFO com.zaxxer.hikari.HikariDataSource [Thread-302] HikariPool-19 - Shutdown initiated...
2023-04-26 12:10:59,406 INFO com.zaxxer.hikari.HikariDataSource [Thread-302] HikariPool-19 - Shutdown completed.
2023-04-26 12:10:59,838 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 102147 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-26 12:10:59,838 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-26 12:11:00,570 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-26 12:11:00,571 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-26 12:11:00,598 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-26 12:11:00,640 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@269fb271]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-26 12:11:00,641 INFO org.mongodb.driver.connection [cluster-ClusterId{value='6448c77cadee62176f29076d', description='null'}-localhost:27017] Opened connection [connectionId{localValue:42, serverValue:83}] to localhost:27017
2023-04-26 12:11:00,641 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='6448c77cadee62176f29076d', description='null'}-localhost:27017] Opened connection [connectionId{localValue:43, serverValue:84}] to localhost:27017
2023-04-26 12:11:00,641 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='6448c77cadee62176f29076d', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=668151}
2023-04-26 12:11:00,847 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-26 12:11:00,859 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-20 - Starting...
2023-04-26 12:11:00,864 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-20 - Start completed.
2023-04-26 12:11:00,865 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-26 12:11:00,936 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-26 12:11:01,186 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-26 12:11:01,187 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-26 12:11:01,188 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-26 12:11:01,189 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-26 12:11:01,189 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-26 12:11:01,189 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-26 12:11:01,190 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-26 12:11:01,236 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 36545.
2023-04-26 12:11:01,238 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-26 12:11:01,239 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-26 12:11:01,240 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-26 12:11:01,240 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-26 12:11:01,240 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-f6faa9a3-4295-460d-8a6e-7757bbbfe144
2023-04-26 12:11:01,241 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-26 12:11:01,242 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-26 12:11:01,246 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-26 12:11:01,252 INFO org.spark_project.jetty.server.Server [restartedMain] Started @1733485ms
2023-04-26 12:11:01,254 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@59b69054{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-26 12:11:01,254 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-26 12:11:01,255 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@615c9289{/jobs,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,255 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@39625941{/jobs/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6cadd5b7{/jobs/job,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@174dc46{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b9de3b{/stages,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,256 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2f3a37bc{/stages/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,257 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d384f81{/stages/stage,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,257 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@a89208c{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,257 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@408b7fe0{/stages/pool,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,258 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e72379a{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,258 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51592392{/storage,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,259 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1217f475{/storage/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,259 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@9f8fda8{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,259 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2619c5ea{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,260 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e442708{/environment,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,260 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@135dd8e9{/environment/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,261 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d067297{/executors,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,261 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3558da48{/executors/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,262 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2abbc78c{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,262 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@57dcd8a2{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,263 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@39208a04{/static,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,263 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4a599df2{/,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,264 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3eaaa492{/api,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,264 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@324fb963{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,265 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34ff04d5{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-26 12:11:01,265 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-26 12:11:01,289 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-26 12:11:01,292 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37199.
2023-04-26 12:11:01,293 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:37199
2023-04-26 12:11:01,293 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-26 12:11:01,293 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 37199, None)
2023-04-26 12:11:01,294 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:37199 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 37199, None)
2023-04-26 12:11:01,294 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 37199, None)
2023-04-26 12:11:01,294 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 37199, None)
2023-04-26 12:11:01,295 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@42b473e0{/metrics/json,null,AVAILABLE,@Spark}
2023-04-26 12:11:02,589 INFO org.apache.kafka.clients.consumer.ConsumerConfig [restartedMain] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-book-group-20
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = book-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer

2023-04-26 12:11:02,593 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka version: 3.1.1
2023-04-26 12:11:02,593 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka commitId: 97671528ba54a138
2023-04-26 12:11:02,594 INFO org.apache.kafka.common.utils.AppInfoParser [restartedMain] Kafka startTimeMs: 1682491262593
2023-04-26 12:11:02,594 INFO org.apache.kafka.clients.consumer.KafkaConsumer [restartedMain] [Consumer clientId=consumer-book-group-20, groupId=book-group] Subscribed to topic(s): my-topic
2023-04-26 12:11:02,600 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:11:02,601 INFO org.apache.kafka.clients.Metadata [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:11:02,601 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Discovered group coordinator wks-012:9092 (id: 2147483647 rack: null)
2023-04-26 12:11:02,603 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] (Re-)joining group
2023-04-26 12:11:02,606 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Request joining group due to: need to re-join with the given member-id
2023-04-26 12:11:02,606 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] (Re-)joining group
2023-04-26 12:11:02,609 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Successfully joined group with generation Generation{generationId=169, memberId='consumer-book-group-20-c713a369-b434-4aa0-ac32-c7c41dc311c5', protocol='range'}
2023-04-26 12:11:02,610 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Finished assignment for group at generation 169: {consumer-book-group-20-c713a369-b434-4aa0-ac32-c7c41dc311c5=Assignment(partitions=[my-topic-0])}
2023-04-26 12:11:02,614 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Successfully synced group in generation Generation{generationId=169, memberId='consumer-book-group-20-c713a369-b434-4aa0-ac32-c7c41dc311c5', protocol='range'}
2023-04-26 12:11:02,614 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Notifying assignor about the new Assignment(partitions=[my-topic-0])
2023-04-26 12:11:02,614 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Adding newly assigned partitions: my-topic-0
2023-04-26 12:11:02,617 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-book-group-20, groupId=book-group] Setting offset for partition my-topic-0 to the committed offset FetchPosition{offset=415, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[wks-012:9092 (id: 0 rack: null)], epoch=0}}
2023-04-26 12:11:02,617 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 2.878 seconds (JVM running for 1734.85)
2023-04-26 12:11:02,623 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-26 12:11:02,624 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-26 12:11:20,504 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-26 12:11:20,546 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:44, serverValue:85}] to localhost:27017
2023-04-26 12:11:28,950 INFO org.apache.kafka.clients.producer.ProducerConfig [http-nio-8080-exec-2] ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.springframework.kafka.support.serializer.JsonSerializer

2023-04-26 12:11:28,952 INFO org.apache.kafka.clients.producer.KafkaProducer [http-nio-8080-exec-2] [Producer clientId=producer-2] Instantiated an idempotent producer.
2023-04-26 12:11:28,956 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-2] Kafka version: 3.1.1
2023-04-26 12:11:28,956 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-2] Kafka commitId: 97671528ba54a138
2023-04-26 12:11:28,957 INFO org.apache.kafka.common.utils.AppInfoParser [http-nio-8080-exec-2] Kafka startTimeMs: 1682491288956
2023-04-26 12:11:28,964 INFO org.apache.kafka.clients.Metadata [kafka-producer-network-thread | producer-2] [Producer clientId=producer-2] Resetting the last seen epoch of partition my-topic-0 to 0 since the associated topicId changed from null to QqwJ2XdJQbi2BDXQbzT51g
2023-04-26 12:11:28,966 INFO org.apache.kafka.clients.Metadata [kafka-producer-network-thread | producer-2] [Producer clientId=producer-2] Cluster ID: 6CnV1ouTQjGsP-r9Rd2WRA
2023-04-26 12:11:28,967 INFO org.apache.kafka.clients.producer.internals.TransactionManager [kafka-producer-network-thread | producer-2] [Producer clientId=producer-2] ProducerId set to 3001 with epoch 0
2023-04-26 12:11:49,062 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-4] Get All Employee
