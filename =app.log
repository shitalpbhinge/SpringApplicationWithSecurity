2023-04-19 15:01:40,230 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29141 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:01:40,276 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:01:43,321 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:01:43,322 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:01:43,478 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:01:43,781 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4a98c6c8]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:01:44,700 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:01:44,772 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:01:44,907 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb4ff54ae7d174aaeb32a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:1}] to localhost:27017
2023-04-19 15:01:44,909 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb4ff54ae7d174aaeb32a', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1091761259}
2023-04-19 15:01:44,909 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb4ff54ae7d174aaeb32a', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:2}] to localhost:27017
2023-04-19 15:01:45,009 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:01:45,162 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:01:45,727 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:01:45,758 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:01:46,828 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:01:47,236 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:01:47,273 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:01:47,281 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:01:47,287 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:01:47,349 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:03:54,662 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29245 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:03:54,666 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:03:57,492 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:03:57,492 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:03:57,632 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:03:57,876 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7919f528]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:03:57,907 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb585d272062c963db508', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
2023-04-19 15:03:57,907 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb585d272062c963db508', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:3}] to localhost:27017
2023-04-19 15:03:57,909 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb585d272062c963db508', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=33740167}
2023-04-19 15:03:58,807 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:03:58,903 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:03:59,169 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:03:59,317 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:03:59,852 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:03:59,878 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:04:00,906 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:04:01,411 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:04:01,460 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:04:01,469 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:04:01,476 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:04:01,530 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:05:35,783 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29367 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:05:35,787 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:05:38,564 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:05:38,565 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:05:38,702 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:05:38,931 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@d893916]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:05:38,959 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb5ea798cc56df27a9522', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:5}] to localhost:27017
2023-04-19 15:05:38,959 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb5ea798cc56df27a9522', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:6}] to localhost:27017
2023-04-19 15:05:38,960 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb5ea798cc56df27a9522', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32006110}
2023-04-19 15:05:39,774 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:05:39,863 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:05:40,143 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:05:40,331 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:05:40,882 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:05:40,915 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:05:41,877 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:05:42,103 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:05:42,139 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:05:42,150 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:05:42,159 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:05:42,237 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Field employeeRepository in com.example.spring.jwt.mongodb.service.EmployeeService required a bean of type 'com.example.spring.jwt.mongodb.repository.EmployeeRepository' that could not be found.

The injection point has the following annotations:
	- @org.springframework.beans.factory.annotation.Autowired(required=true)


Action:

Consider defining a bean of type 'com.example.spring.jwt.mongodb.repository.EmployeeRepository' in your configuration.

2023-04-19 15:08:06,933 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29481 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:08:06,936 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:08:09,634 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:08:09,635 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:08:09,788 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:08:10,082 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@1e4da9e]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:08:10,109 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb681e2e19b46541d83ca', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:7}] to localhost:27017
2023-04-19 15:08:10,121 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb681e2e19b46541d83ca', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:8}] to localhost:27017
2023-04-19 15:08:10,122 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb681e2e19b46541d83ca', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=39149945}
2023-04-19 15:08:11,056 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:08:11,135 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:08:11,352 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:08:11,505 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:08:11,999 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:08:12,026 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:08:12,967 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:08:13,391 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:08:13,433 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:08:13,442 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:08:13,447 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:08:13,507 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:09:13,348 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29607 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:09:13,352 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:09:16,281 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:09:16,282 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:09:16,425 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:09:16,663 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@c6ee5dd]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:09:16,713 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb6c4508f0e5c90dceb29', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:9}] to localhost:27017
2023-04-19 15:09:16,714 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb6c4508f0e5c90dceb29', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=56727147}
2023-04-19 15:09:16,725 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb6c4508f0e5c90dceb29', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:10}] to localhost:27017
2023-04-19 15:09:17,487 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:09:17,564 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:09:17,776 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:09:17,921 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:09:18,405 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:09:18,428 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:09:19,365 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:09:19,779 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:09:19,846 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:09:19,855 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:09:19,861 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:09:19,922 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:10:40,042 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 29716 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:10:40,046 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:10:42,995 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:10:42,996 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:10:43,155 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:10:43,442 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@20e3619f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:10:43,468 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb71b9de4d228e9aaa51b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:12}] to localhost:27017
2023-04-19 15:10:43,469 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb71b9de4d228e9aaa51b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=32792604}
2023-04-19 15:10:43,473 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb71b9de4d228e9aaa51b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:11}] to localhost:27017
2023-04-19 15:10:44,224 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:10:44,296 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:10:44,546 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:10:44,714 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:10:45,262 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:10:45,288 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:10:46,359 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:10:46,820 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:10:46,832 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:10:46,842 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:10:46,848 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:10:46,904 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:15:22,848 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30045 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:15:22,851 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:15:25,610 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:15:25,611 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:15:25,746 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:15:26,015 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5251449a]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:15:26,060 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb835221da44ba69bf111', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:13}] to localhost:27017
2023-04-19 15:15:26,061 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb835221da44ba69bf111', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=58562020}
2023-04-19 15:15:26,062 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb835221da44ba69bf111', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:14}] to localhost:27017
2023-04-19 15:15:27,030 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:15:27,117 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:15:27,376 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:15:27,548 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:15:28,032 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:15:28,058 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:15:29,022 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:15:29,531 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:15:29,570 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:15:29,581 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:15:29,587 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:15:29,654 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:16:44,488 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30150 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:16:44,492 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:16:47,425 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:16:47,426 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:16:47,562 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:16:47,819 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3a52595d]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:16:47,848 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb8870f951311fe531a8b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:15}] to localhost:27017
2023-04-19 15:16:47,848 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb8870f951311fe531a8b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:16}] to localhost:27017
2023-04-19 15:16:47,848 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb8870f951311fe531a8b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=36393699}
2023-04-19 15:16:48,649 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:16:48,727 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:16:48,986 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:16:49,171 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:16:49,760 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:16:49,787 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:16:50,717 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:16:51,183 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:16:51,208 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:16:51,217 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:16:51,223 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:16:51,288 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:20:45,663 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30373 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:20:45,667 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:20:48,476 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:20:48,477 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:20:48,630 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:20:48,868 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7d697c2f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:20:48,920 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fb97823b68d117ee35629', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:17}] to localhost:27017
2023-04-19 15:20:48,920 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fb97823b68d117ee35629', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:18}] to localhost:27017
2023-04-19 15:20:48,921 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fb97823b68d117ee35629', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=57410462}
2023-04-19 15:20:49,679 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:20:49,764 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:20:50,002 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:20:50,153 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:20:50,646 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:20:50,674 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:20:51,617 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:20:52,006 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:20:52,054 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:20:52,062 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:20:52,069 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:20:52,128 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:25:42,729 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30531 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:25:42,732 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:25:45,621 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:25:45,621 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:25:45,781 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:25:46,040 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@5a4f7675]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:25:46,072 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbaa174c5817c747f5d25', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:19}] to localhost:27017
2023-04-19 15:25:46,077 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbaa174c5817c747f5d25', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=36959814}
2023-04-19 15:25:46,078 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbaa174c5817c747f5d25', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:20}] to localhost:27017
2023-04-19 15:25:46,872 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:25:46,947 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:25:47,170 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:25:47,319 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:25:47,893 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:25:47,924 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:25:48,982 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:25:49,414 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:25:49,429 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:25:49,438 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:25:49,443 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:25:49,499 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:26:39,665 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30638 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:26:39,671 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:26:42,683 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:26:42,684 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:26:42,883 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:26:43,158 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@70224d48]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:26:43,185 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbadb601e107b70a6f5ab', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:21}] to localhost:27017
2023-04-19 15:26:43,191 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbadb601e107b70a6f5ab', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:22}] to localhost:27017
2023-04-19 15:26:43,192 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbadb601e107b70a6f5ab', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=31313347}
2023-04-19 15:26:44,185 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:26:44,257 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:26:44,473 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:26:44,643 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:26:45,150 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:26:45,183 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:26:46,300 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:26:46,743 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:26:46,787 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:26:46,797 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:26:46,803 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:26:46,865 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:35:22,587 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 30995 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:35:22,591 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:35:26,249 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:35:26,250 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:35:26,426 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:35:26,748 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@7d71d4f]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:35:26,798 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbce6579c5b62b2b39deb', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:23}] to localhost:27017
2023-04-19 15:35:26,806 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbce6579c5b62b2b39deb', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=54645303}
2023-04-19 15:35:26,799 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbce6579c5b62b2b39deb', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:24}] to localhost:27017
2023-04-19 15:35:27,770 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:35:27,864 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:35:28,185 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:35:28,399 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:35:29,161 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:35:29,197 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:35:30,387 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:35:30,953 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:35:31,007 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:35:31,035 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:35:31,049 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:35:31,133 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:36:44,479 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 31084 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:36:44,484 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:36:48,155 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:36:48,156 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:36:48,358 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:36:48,679 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2af00cf5]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:36:48,714 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbd387368492d362b2a1f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:26}] to localhost:27017
2023-04-19 15:36:48,716 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbd387368492d362b2a1f', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:25}] to localhost:27017
2023-04-19 15:36:48,717 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbd387368492d362b2a1f', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=38191727}
2023-04-19 15:36:49,723 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:36:49,820 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:36:50,086 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:36:50,274 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:36:50,989 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:36:51,027 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:36:52,325 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:36:52,893 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:36:52,944 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:36:52,957 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:36:52,965 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:36:53,046 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:38:46,379 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 31191 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:38:46,385 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:38:50,302 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:38:50,303 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:38:50,523 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:38:50,861 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@43503b14]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:38:50,910 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbdb2bc5d232e492e2198', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:27}] to localhost:27017
2023-04-19 15:38:50,911 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbdb2bc5d232e492e2198', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=54257895}
2023-04-19 15:38:50,920 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbdb2bc5d232e492e2198', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:28}] to localhost:27017
2023-04-19 15:38:51,918 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:38:52,020 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:38:52,322 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:38:52,524 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:38:53,220 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:38:53,277 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:38:54,661 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:38:55,354 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:38:55,405 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:38:55,417 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:38:55,426 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:38:55,530 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:41:54,103 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 31323 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:41:54,107 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:41:57,589 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:41:57,590 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:41:57,800 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:41:58,165 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@38de3d6d]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:41:58,219 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbe6e371bc9281e9ebf52', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:30}] to localhost:27017
2023-04-19 15:41:58,220 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbe6e371bc9281e9ebf52', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=46983206}
2023-04-19 15:41:58,223 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbe6e371bc9281e9ebf52', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:29}] to localhost:27017
2023-04-19 15:41:59,251 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:41:59,343 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:41:59,624 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:41:59,817 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:42:00,511 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:42:00,548 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:42:01,784 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:42:02,263 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 15:42:02,280 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 15:42:02,292 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 15:42:02,300 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:42:02,376 ERROR org.springframework.boot.SpringApplication [restartedMain] Application run failed
org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeController': Unsatisfied dependency expressed through field 'empService'; nested exception is org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)
	at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)
	at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)
	at org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)
	at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)
	at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:308)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)
	at com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication.main(SpringBootSecurityJwtMongodbApplication.java:16)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.boot.devtools.restart.RestartLauncher.run(RestartLauncher.java:49)
Caused by: org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'employeeService': Unsatisfied dependency expressed through field 'employeeRepository'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:659)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:639)
	at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessProperties(AutowiredAnnotationBeanPostProcessor.java:399)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 25 common frames omitted
Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'employeeRepository' defined in com.example.spring.jwt.mongodb.repository.EmployeeRepository defined in @EnableJpaRepositories declared on JpaRepositoriesRegistrar.EnableJpaRepositoriesConfiguration: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1804)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:620)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)
	at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)
	at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)
	at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)
	at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)
	at org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)
	at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)
	at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.resolveFieldValue(AutowiredAnnotationBeanPostProcessor.java:656)
	... 39 common frames omitted
Caused by: java.lang.IllegalArgumentException: Not a managed type: class com.example.spring.jwt.mongodb.models.Employee
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:582)
	at org.hibernate.metamodel.internal.MetamodelImpl.managedType(MetamodelImpl.java:85)
	at org.springframework.data.jpa.repository.support.JpaMetamodelEntityInformation.<init>(JpaMetamodelEntityInformation.java:75)
	at org.springframework.data.jpa.repository.support.JpaEntityInformationSupport.getEntityInformation(JpaEntityInformationSupport.java:66)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getEntityInformation(JpaRepositoryFactory.java:233)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:182)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:165)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactory.getTargetRepository(JpaRepositoryFactory.java:76)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport.getRepository(RepositoryFactorySupport.java:325)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.lambda$afterPropertiesSet$5(RepositoryFactoryBeanSupport.java:323)
	at org.springframework.data.util.Lazy.getNullable(Lazy.java:231)
	at org.springframework.data.util.Lazy.get(Lazy.java:115)
	at org.springframework.data.repository.core.support.RepositoryFactoryBeanSupport.afterPropertiesSet(RepositoryFactoryBeanSupport.java:329)
	at org.springframework.data.jpa.repository.support.JpaRepositoryFactoryBean.afterPropertiesSet(JpaRepositoryFactoryBean.java:144)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1863)
	at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1800)
	... 49 common frames omitted
2023-04-19 15:48:09,695 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 32024 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 15:48:09,724 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 15:48:13,210 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 15:48:13,211 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 15:48:13,405 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 15:48:13,706 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@52a888de]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 15:48:13,754 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fbfe5a131347ea8b94477', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:32}] to localhost:27017
2023-04-19 15:48:13,755 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fbfe5a131347ea8b94477', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=55988556}
2023-04-19 15:48:13,767 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fbfe5a131347ea8b94477', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:31}] to localhost:27017
2023-04-19 15:48:14,739 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 15:48:14,827 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 15:48:15,133 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 15:48:15,311 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 15:48:15,926 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 15:48:15,963 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 15:48:17,316 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 15:48:18,431 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 15:48:18,432 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 15:48:18,518 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 15:48:19,024 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 15:48:19,314 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 15:48:19,443 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 15:48:19,447 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 15:48:19,450 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 15:48:19,452 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 15:48:19,453 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 15:48:20,029 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 43315.
2023-04-19 15:48:20,082 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 15:48:20,117 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 15:48:20,124 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 15:48:20,126 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 15:48:20,148 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-57683b4a-79a1-4fb2-9466-cd58217b4390
2023-04-19 15:48:20,195 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 15:48:20,225 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 15:48:20,378 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @13427ms
2023-04-19 15:48:20,476 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 15:48:20,503 INFO org.spark_project.jetty.server.Server [restartedMain] Started @13551ms
2023-04-19 15:48:20,537 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@101f768a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 15:48:20,538 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-19 15:48:20,570 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b5e38f{/jobs,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,572 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44e41eca{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,574 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7ec3c1bb{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,576 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@33efbe5c{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,577 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@53417f83{/stages,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,579 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@445a8bae{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,580 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5c9afb2e{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,582 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@ef8c82a{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,584 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2725d60c{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,585 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@21e80774{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,586 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6a3fc2e4{/storage,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,587 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@224efe11{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,589 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2bd2d9e2{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,590 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4ae0a84b{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,591 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5edc7b11{/environment,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,593 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@b37a8ad{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,594 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@36976de0{/executors,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,596 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@79fa3989{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,598 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44c3d154{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,600 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@72877ba1{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,615 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7ff2f07c{/static,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,617 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2fb9c9de{/,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,620 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5d8e0f8c{/api,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,623 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a76d070{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,624 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@270ba5bd{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 15:48:20,628 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-19 15:48:20,809 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 15:48:20,845 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45353.
2023-04-19 15:48:20,846 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:45353
2023-04-19 15:48:20,850 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 15:48:20,913 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 45353, None)
2023-04-19 15:48:20,922 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:45353 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 45353, None)
2023-04-19 15:48:20,930 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 45353, None)
2023-04-19 15:48:20,932 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 45353, None)
2023-04-19 15:48:20,958 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6b9c4c25{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 15:48:24,220 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 15.403 seconds (JVM running for 17.268)
2023-04-19 15:48:24,229 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-19 15:48:24,229 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-19 15:48:33,305 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-19 15:48:35,750 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 647 ms
2023-04-19 15:49:14,036 INFO org.mongodb.driver.connection [http-nio-8080-exec-10] Opened connection [connectionId{localValue:3, serverValue:33}] to localhost:27017
2023-04-19 15:49:42,676 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-2] Get All Employee
2023-04-19 15:50:26,538 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-3] Adding Employee
2023-04-19 15:50:37,685 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-5] Get All Employee
2023-04-19 15:51:00,790 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-4] Adding Employee
2023-04-19 15:51:13,085 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-7] Get All Employee
2023-04-19 15:57:09,784 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(12)-127.0.0.1] Stopping service [Tomcat]
2023-04-19 15:57:09,787 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(12)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-19 15:57:09,793 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(12)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:57:09,794 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(12)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='643fbfe5a131347ea8b94477', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:57:09,795 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(12)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='643fbfe5a131347ea8b94477', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:57:09,796 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(12)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 15:57:09,808 INFO org.apache.spark.SparkContext [Thread-7] Invoking stop() from shutdown hook
2023-04-19 15:57:09,813 INFO org.apache.spark.SparkContext [RMI TCP Connection(12)-127.0.0.1] SparkContext already stopped.
2023-04-19 15:57:09,814 INFO org.apache.spark.SparkContext [RMI TCP Connection(12)-127.0.0.1] SparkContext already stopped.
2023-04-19 15:57:09,822 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(12)-127.0.0.1] HikariPool-1 - Shutdown initiated...
2023-04-19 15:57:09,824 INFO org.spark_project.jetty.server.AbstractConnector [Thread-7] Stopped Spark@101f768a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 15:57:09,838 INFO org.apache.spark.ui.SparkUI [Thread-7] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-19 15:57:09,877 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 15:57:09,935 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(12)-127.0.0.1] HikariPool-1 - Shutdown completed.
2023-04-19 15:57:09,961 INFO org.apache.spark.storage.memory.MemoryStore [Thread-7] MemoryStore cleared
2023-04-19 15:57:09,962 INFO org.apache.spark.storage.BlockManager [Thread-7] BlockManager stopped
2023-04-19 15:57:09,963 INFO org.apache.spark.storage.BlockManagerMaster [Thread-7] BlockManagerMaster stopped
2023-04-19 15:57:09,970 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-19 15:57:09,977 INFO org.apache.spark.SparkContext [Thread-7] Successfully stopped SparkContext
2023-04-19 15:57:09,979 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Shutdown hook called
2023-04-19 15:57:09,981 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Deleting directory /tmp/spark-1f89f2df-af67-4cd6-af5b-50491c9d14a9
2023-04-19 16:44:58,005 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 5852 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 16:44:58,054 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 16:45:04,441 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 16:45:04,442 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 16:45:04,657 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 16:45:05,023 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@233a5726]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 16:45:05,711 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fcd38324a251760fdb73c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:2}] to localhost:27017
2023-04-19 16:45:05,712 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fcd38324a251760fdb73c', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=683255841}
2023-04-19 16:45:05,727 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fcd38324a251760fdb73c', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:1}] to localhost:27017
2023-04-19 16:45:06,673 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 16:45:06,847 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 16:45:07,462 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 16:45:07,698 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 16:45:08,903 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 16:45:08,981 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 16:45:12,471 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 16:45:14,168 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 16:45:14,169 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 16:45:14,556 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 16:45:15,488 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 16:45:15,952 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 16:45:16,401 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 16:45:16,403 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 16:45:16,415 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 16:45:16,418 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 16:45:16,420 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 16:45:17,944 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 45785.
2023-04-19 16:45:18,153 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 16:45:18,297 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 16:45:18,314 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 16:45:18,315 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 16:45:18,368 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-88ca5f8c-65ae-4f0a-84e0-ffda4371b68b
2023-04-19 16:45:18,465 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 16:45:18,552 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 16:45:18,816 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @30673ms
2023-04-19 16:45:19,024 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 16:45:19,046 INFO org.spark_project.jetty.server.Server [restartedMain] Started @30903ms
2023-04-19 16:45:19,086 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@571ec32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 16:45:19,087 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-19 16:45:19,118 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@629f0a7e{/jobs,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,120 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@714dc52{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,121 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@73fc8ec{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,123 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@f2f5ab4{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,124 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@762e9b15{/stages,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,125 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7fe8dc5b{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,126 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@16d2dd8e{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,128 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@550cad0c{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,130 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cbe12d4{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,131 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@748dda02{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,132 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@8b564fa{/storage,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,133 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3861dc2d{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,138 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34454147{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,141 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2e02d007{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,145 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@db3f389{/environment,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,150 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3b05c6a6{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,152 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2554f7f8{/executors,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,154 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1dee99bd{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,156 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@f530e32{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,158 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1a76d988{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,173 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@181f1609{/static,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,174 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2fbcabbf{/,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,177 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@11e74433{/api,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,179 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@506f0ea{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,181 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@73f7064c{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 16:45:19,194 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-19 16:45:19,477 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 16:45:19,528 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43863.
2023-04-19 16:45:19,538 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:43863
2023-04-19 16:45:19,541 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 16:45:19,606 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 43863, None)
2023-04-19 16:45:19,613 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:43863 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 43863, None)
2023-04-19 16:45:19,641 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 43863, None)
2023-04-19 16:45:19,642 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 43863, None)
2023-04-19 16:45:19,717 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2f9ec46e{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 16:45:23,260 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 26.483 seconds (JVM running for 35.117)
2023-04-19 16:45:23,266 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-19 16:45:23,266 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-19 16:45:27,701 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-19 16:45:29,266 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 634 ms
2023-04-19 16:47:09,277 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-4] Unauthorized error: Full authentication is required to access this resource
2023-04-19 16:47:41,913 INFO org.mongodb.driver.connection [http-nio-8080-exec-5] Opened connection [connectionId{localValue:3, serverValue:3}] to localhost:27017
2023-04-19 16:48:07,367 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-8] Deleting Employee
2023-04-19 16:48:14,230 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-7] Deleting Employee
2023-04-19 16:48:45,749 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-9] Adding Employee
2023-04-19 16:49:06,989 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-10] Adding Employee
2023-04-19 16:50:04,106 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-1] Adding Employee
2023-04-19 16:50:04,141 WARN org.hibernate.engine.jdbc.spi.SqlExceptionHelper [http-nio-8080-exec-1] SQL Error: 1146, SQLState: 42S02
2023-04-19 16:50:04,142 ERROR org.hibernate.engine.jdbc.spi.SqlExceptionHelper [http-nio-8080-exec-1] Table 'BookLibrary.employee' doesn't exist
2023-04-19 16:50:04,180 INFO org.hibernate.event.internal.DefaultLoadEventListener [http-nio-8080-exec-1] HHH000327: Error performing load command
org.hibernate.exception.SQLGrammarException: could not extract ResultSet
	at org.hibernate.exception.internal.SQLExceptionTypeDelegate.convert(SQLExceptionTypeDelegate.java:63)
	at org.hibernate.exception.internal.StandardSQLExceptionConverter.convert(StandardSQLExceptionConverter.java:37)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:113)
	at org.hibernate.engine.jdbc.spi.SqlExceptionHelper.convert(SqlExceptionHelper.java:99)
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.extract(ResultSetReturnImpl.java:67)
	at org.hibernate.loader.Loader.getResultSet(Loader.java:2322)
	at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2075)
	at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2037)
	at org.hibernate.loader.Loader.doQuery(Loader.java:956)
	at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:357)
	at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:327)
	at org.hibernate.loader.Loader.loadEntity(Loader.java:2440)
	at org.hibernate.loader.entity.AbstractEntityLoader.load(AbstractEntityLoader.java:77)
	at org.hibernate.loader.entity.AbstractEntityLoader.load(AbstractEntityLoader.java:61)
	at org.hibernate.persister.entity.AbstractEntityPersister.doLoad(AbstractEntityPersister.java:4521)
	at org.hibernate.persister.entity.AbstractEntityPersister.load(AbstractEntityPersister.java:4511)
	at org.hibernate.event.internal.DefaultLoadEventListener.loadFromDatasource(DefaultLoadEventListener.java:571)
	at org.hibernate.event.internal.DefaultLoadEventListener.doLoad(DefaultLoadEventListener.java:539)
	at org.hibernate.event.internal.DefaultLoadEventListener.load(DefaultLoadEventListener.java:208)
	at org.hibernate.event.internal.DefaultLoadEventListener.proxyOrLoad(DefaultLoadEventListener.java:327)
	at org.hibernate.event.internal.DefaultLoadEventListener.doOnLoad(DefaultLoadEventListener.java:108)
	at org.hibernate.event.internal.DefaultLoadEventListener.onLoad(DefaultLoadEventListener.java:74)
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:118)
	at org.hibernate.internal.SessionImpl.fireLoadNoChecks(SessionImpl.java:1231)
	at org.hibernate.internal.SessionImpl.fireLoad(SessionImpl.java:1220)
	at org.hibernate.internal.SessionImpl.access$2100(SessionImpl.java:202)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.doLoad(SessionImpl.java:2835)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.lambda$load$1(SessionImpl.java:2812)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.perform(SessionImpl.java:2768)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.load(SessionImpl.java:2812)
	at org.hibernate.internal.SessionImpl.get(SessionImpl.java:1024)
	at org.hibernate.event.internal.DefaultMergeEventListener.entityIsDetached(DefaultMergeEventListener.java:306)
	at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:172)
	at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:70)
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107)
	at org.hibernate.internal.SessionImpl.fireMerge(SessionImpl.java:829)
	at org.hibernate.internal.SessionImpl.merge(SessionImpl.java:816)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.orm.jpa.ExtendedEntityManagerCreator$ExtendedEntityManagerInvocationHandler.invoke(ExtendedEntityManagerCreator.java:362)
	at jdk.proxy3/jdk.proxy3.$Proxy138.merge(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:311)
	at jdk.proxy3/jdk.proxy3.$Proxy138.merge(Unknown Source)
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:669)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:81)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at jdk.proxy3/jdk.proxy3.$Proxy141.save(Unknown Source)
	at com.example.spring.jwt.mongodb.service.EmployeeService.addEmployee(EmployeeService.java:21)
	at com.example.spring.jwt.mongodb.controllers.EmployeeController.addEmployee(EmployeeController.java:35)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.sql.SQLSyntaxErrorException: Table 'BookLibrary.employee' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1003)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.extract(ResultSetReturnImpl.java:57)
	... 164 common frames omitted
2023-04-19 16:50:04,227 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.springframework.dao.InvalidDataAccessResourceUsageException: could not extract ResultSet; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not extract ResultSet] with root cause
java.sql.SQLSyntaxErrorException: Table 'BookLibrary.employee' doesn't exist
	at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:120)
	at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeInternal(ClientPreparedStatement.java:953)
	at com.mysql.cj.jdbc.ClientPreparedStatement.executeQuery(ClientPreparedStatement.java:1003)
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52)
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java)
	at org.hibernate.engine.jdbc.internal.ResultSetReturnImpl.extract(ResultSetReturnImpl.java:57)
	at org.hibernate.loader.Loader.getResultSet(Loader.java:2322)
	at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2075)
	at org.hibernate.loader.Loader.executeQueryStatement(Loader.java:2037)
	at org.hibernate.loader.Loader.doQuery(Loader.java:956)
	at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:357)
	at org.hibernate.loader.Loader.doQueryAndInitializeNonLazyCollections(Loader.java:327)
	at org.hibernate.loader.Loader.loadEntity(Loader.java:2440)
	at org.hibernate.loader.entity.AbstractEntityLoader.load(AbstractEntityLoader.java:77)
	at org.hibernate.loader.entity.AbstractEntityLoader.load(AbstractEntityLoader.java:61)
	at org.hibernate.persister.entity.AbstractEntityPersister.doLoad(AbstractEntityPersister.java:4521)
	at org.hibernate.persister.entity.AbstractEntityPersister.load(AbstractEntityPersister.java:4511)
	at org.hibernate.event.internal.DefaultLoadEventListener.loadFromDatasource(DefaultLoadEventListener.java:571)
	at org.hibernate.event.internal.DefaultLoadEventListener.doLoad(DefaultLoadEventListener.java:539)
	at org.hibernate.event.internal.DefaultLoadEventListener.load(DefaultLoadEventListener.java:208)
	at org.hibernate.event.internal.DefaultLoadEventListener.proxyOrLoad(DefaultLoadEventListener.java:327)
	at org.hibernate.event.internal.DefaultLoadEventListener.doOnLoad(DefaultLoadEventListener.java:108)
	at org.hibernate.event.internal.DefaultLoadEventListener.onLoad(DefaultLoadEventListener.java:74)
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:118)
	at org.hibernate.internal.SessionImpl.fireLoadNoChecks(SessionImpl.java:1231)
	at org.hibernate.internal.SessionImpl.fireLoad(SessionImpl.java:1220)
	at org.hibernate.internal.SessionImpl.access$2100(SessionImpl.java:202)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.doLoad(SessionImpl.java:2835)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.lambda$load$1(SessionImpl.java:2812)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.perform(SessionImpl.java:2768)
	at org.hibernate.internal.SessionImpl$IdentifierLoadAccessImpl.load(SessionImpl.java:2812)
	at org.hibernate.internal.SessionImpl.get(SessionImpl.java:1024)
	at org.hibernate.event.internal.DefaultMergeEventListener.entityIsDetached(DefaultMergeEventListener.java:306)
	at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:172)
	at org.hibernate.event.internal.DefaultMergeEventListener.onMerge(DefaultMergeEventListener.java:70)
	at org.hibernate.event.service.internal.EventListenerGroupImpl.fireEventOnEachListener(EventListenerGroupImpl.java:107)
	at org.hibernate.internal.SessionImpl.fireMerge(SessionImpl.java:829)
	at org.hibernate.internal.SessionImpl.merge(SessionImpl.java:816)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.orm.jpa.ExtendedEntityManagerCreator$ExtendedEntityManagerInvocationHandler.invoke(ExtendedEntityManagerCreator.java:362)
	at jdk.proxy3/jdk.proxy3.$Proxy138.merge(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.orm.jpa.SharedEntityManagerCreator$SharedEntityManagerInvocationHandler.invoke(SharedEntityManagerCreator.java:311)
	at jdk.proxy3/jdk.proxy3.$Proxy138.merge(Unknown Source)
	at org.springframework.data.jpa.repository.support.SimpleJpaRepository.save(SimpleJpaRepository.java:669)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:530)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:286)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:640)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:164)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:139)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:81)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:123)
	at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:388)
	at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:119)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.jpa.repository.support.CrudMethodMetadataPostProcessor$CrudMethodMetadataPopulatingMethodInterceptor.invoke(CrudMethodMetadataPostProcessor.java:174)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at jdk.proxy3/jdk.proxy3.$Proxy141.save(Unknown Source)
	at com.example.spring.jwt.mongodb.service.EmployeeService.addEmployee(EmployeeService.java:21)
	at com.example.spring.jwt.mongodb.controllers.EmployeeController.addEmployee(EmployeeController.java:35)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:681)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:50:38,296 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(9)-127.0.0.1] Stopping service [Tomcat]
2023-04-19 16:50:38,298 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(9)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-19 16:50:38,302 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(9)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:50:38,303 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(9)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='643fcd38324a251760fdb73c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:50:38,304 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(9)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='643fcd38324a251760fdb73c', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:50:38,308 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(9)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:50:38,317 INFO org.apache.spark.SparkContext [Thread-7] Invoking stop() from shutdown hook
2023-04-19 16:50:38,319 INFO org.apache.spark.SparkContext [RMI TCP Connection(9)-127.0.0.1] SparkContext already stopped.
2023-04-19 16:50:38,320 INFO org.apache.spark.SparkContext [RMI TCP Connection(9)-127.0.0.1] SparkContext already stopped.
2023-04-19 16:50:38,327 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(9)-127.0.0.1] HikariPool-1 - Shutdown initiated...
2023-04-19 16:50:38,338 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(9)-127.0.0.1] HikariPool-1 - Shutdown completed.
2023-04-19 16:50:38,351 INFO org.spark_project.jetty.server.AbstractConnector [Thread-7] Stopped Spark@571ec32d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 16:50:38,353 INFO org.apache.spark.ui.SparkUI [Thread-7] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-19 16:50:38,432 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-1] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 16:50:38,452 INFO org.apache.spark.storage.memory.MemoryStore [Thread-7] MemoryStore cleared
2023-04-19 16:50:38,453 INFO org.apache.spark.storage.BlockManager [Thread-7] BlockManager stopped
2023-04-19 16:50:48,061 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 6398 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 16:50:48,065 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 16:50:50,740 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 16:50:50,741 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 16:50:50,889 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 16:50:51,138 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@296eafc2]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 16:50:51,168 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fce9314fbf430adc3c94b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:5}] to localhost:27017
2023-04-19 16:50:51,169 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fce9314fbf430adc3c94b', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=33127071}
2023-04-19 16:50:51,175 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fce9314fbf430adc3c94b', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:4}] to localhost:27017
2023-04-19 16:50:51,973 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 16:50:52,044 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 16:50:52,294 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 16:50:52,435 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 16:50:52,885 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 16:50:52,915 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 16:50:54,201 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 16:50:55,015 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 16:50:55,016 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 16:50:55,099 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 16:50:55,523 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 16:50:55,665 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 16:50:55,749 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 16:50:55,750 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 16:50:55,752 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 16:50:55,753 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 16:50:55,755 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 16:50:56,187 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 44019.
2023-04-19 16:50:56,221 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 16:50:56,244 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 16:50:56,250 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 16:50:56,251 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 16:50:56,268 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-9dfc1e8e-e5c0-4ec8-a0ff-c3466023e023
2023-04-19 16:50:56,296 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 16:50:56,318 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 16:50:56,437 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @10755ms
2023-04-19 16:50:56,512 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 16:50:56,536 INFO org.spark_project.jetty.server.Server [restartedMain] Started @10854ms
2023-04-19 16:50:56,562 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@650c3246{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 16:50:56,563 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-19 16:50:56,587 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2d0a9b6e{/jobs,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,589 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@ece9b77{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,591 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4481a24d{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,593 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51c90312{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,595 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@189350ac{/stages,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,597 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3da4dc16{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,598 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@27994c30{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,600 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cbaa4e0{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,602 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69323de8{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,603 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1ef8390c{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,605 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2de37e56{/storage,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,606 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4d742ae{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,608 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7c72f2a1{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,609 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@239d847a{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,611 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@15ba5f91{/environment,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,614 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2b46adba{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,615 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@40cab589{/executors,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,616 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@fbb57be{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,618 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@483ad70f{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,623 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@560f88cf{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,636 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@437c197a{/static,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,638 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@51539ea{/,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,641 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@30c369e7{/api,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,642 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b980b12{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,644 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@24de3110{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 16:50:56,648 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-19 16:50:56,756 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 16:50:56,786 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42197.
2023-04-19 16:50:56,788 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:42197
2023-04-19 16:50:56,791 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 16:50:56,827 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 42197, None)
2023-04-19 16:50:56,833 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:42197 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 42197, None)
2023-04-19 16:50:56,838 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 42197, None)
2023-04-19 16:50:56,840 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 42197, None)
2023-04-19 16:50:56,859 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7cdf4b00{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 16:50:59,383 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 12.05 seconds (JVM running for 13.701)
2023-04-19 16:50:59,391 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-19 16:50:59,391 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-19 16:51:41,418 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-19 16:51:42,801 INFO org.springdoc.api.AbstractOpenApiResource [http-nio-8080-exec-9] Init duration for springdoc-openapi is: 669 ms
2023-04-19 16:52:11,131 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:6}] to localhost:27017
2023-04-19 16:52:55,146 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-6] Adding Employee
2023-04-19 16:53:17,990 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-7] Adding Employee
2023-04-19 16:53:38,457 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-8] Adding Employee
2023-04-19 16:53:59,482 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-10] Adding Employee
2023-04-19 16:54:45,666 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-9] Adding Employee
2023-04-19 16:55:17,213 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-1] Adding Employee
2023-04-19 16:56:10,241 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-2] Adding Employee
2023-04-19 16:56:28,819 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-3] getting Employee By Id
2023-04-19 16:56:36,741 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-4] Get All Employee
2023-04-19 16:57:13,984 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-5] Updatting Employee details
2023-04-19 16:57:25,778 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-6] Get All Employee
2023-04-19 16:57:39,190 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-7] Deleting Employee
2023-04-19 16:57:45,764 INFO com.example.spring.jwt.mongodb.controllers.EmailController [http-nio-8080-exec-8] Get All Employee
2023-04-19 16:58:19,380 WARN /api [SparkUI-61] unavailable
java.lang.IllegalStateException: InjectionManagerFactory not found.
	at org.glassfish.jersey.internal.inject.Injections.lambda$lookupInjectionManagerFactory$0(Injections.java:74)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at org.glassfish.jersey.internal.inject.Injections.lookupInjectionManagerFactory(Injections.java:74)
	at org.glassfish.jersey.internal.inject.Injections.createInjectionManager(Injections.java:69)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:261)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:154)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:347)
	at javax.servlet.GenericServlet.init(GenericServlet.java:158)
	at org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:643)
	at org.spark_project.jetty.servlet.ServletHolder.getServlet(ServletHolder.java:499)
	at org.spark_project.jetty.servlet.ServletHolder.ensureInstance(ServletHolder.java:791)
	at org.spark_project.jetty.servlet.ServletHolder.prepare(ServletHolder.java:776)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:580)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:58:19,383 WARN org.spark_project.jetty.servlet.ServletHandler [SparkUI-61] 
javax.servlet.ServletException: org.glassfish.jersey.servlet.ServletContainer-158b9c3a@13ce2d34==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
	at org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:664)
	at org.spark_project.jetty.servlet.ServletHolder.getServlet(ServletHolder.java:499)
	at org.spark_project.jetty.servlet.ServletHolder.ensureInstance(ServletHolder.java:791)
	at org.spark_project.jetty.servlet.ServletHolder.prepare(ServletHolder.java:776)
	at org.spark_project.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:580)
	at org.spark_project.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.spark_project.jetty.servlet.ServletHandler.doScope(ServletHandler.java:513)
	at org.spark_project.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.spark_project.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.spark_project.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:493)
	at org.spark_project.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:213)
	at org.spark_project.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.spark_project.jetty.server.Server.handle(Server.java:539)
	at org.spark_project.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.spark_project.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.spark_project.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.spark_project.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.spark_project.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.spark_project.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.spark_project.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.spark_project.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: java.lang.IllegalStateException: InjectionManagerFactory not found.
	at org.glassfish.jersey.internal.inject.Injections.lambda$lookupInjectionManagerFactory$0(Injections.java:74)
	at java.base/java.util.Optional.orElseThrow(Optional.java:403)
	at org.glassfish.jersey.internal.inject.Injections.lookupInjectionManagerFactory(Injections.java:74)
	at org.glassfish.jersey.internal.inject.Injections.createInjectionManager(Injections.java:69)
	at org.glassfish.jersey.server.ApplicationHandler.<init>(ApplicationHandler.java:261)
	at org.glassfish.jersey.servlet.WebComponent.<init>(WebComponent.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:154)
	at org.glassfish.jersey.servlet.ServletContainer.init(ServletContainer.java:347)
	at javax.servlet.GenericServlet.init(GenericServlet.java:158)
	at org.spark_project.jetty.servlet.ServletHolder.initServlet(ServletHolder.java:643)
	... 23 common frames omitted
2023-04-19 16:59:27,260 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-9] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse').
2023-04-19 16:59:27,272 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-9] Warehouse path is 'file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse'.
2023-04-19 16:59:27,322 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-9] Started o.s.j.s.ServletContextHandler@717a9438{/SQL,null,AVAILABLE,@Spark}
2023-04-19 16:59:27,325 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-9] Started o.s.j.s.ServletContextHandler@5e9b2195{/SQL/json,null,AVAILABLE,@Spark}
2023-04-19 16:59:27,328 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-9] Started o.s.j.s.ServletContextHandler@26d19371{/SQL/execution,null,AVAILABLE,@Spark}
2023-04-19 16:59:27,329 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-9] Started o.s.j.s.ServletContextHandler@636b5053{/SQL/execution/json,null,AVAILABLE,@Spark}
2023-04-19 16:59:27,334 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-9] Started o.s.j.s.ServletContextHandler@3d791d17{/static/sql,null,AVAILABLE,@Spark}
2023-04-19 16:59:29,219 INFO org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef [http-nio-8080-exec-9] Registered StateStoreCoordinator endpoint
2023-04-19 16:59:30,074 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-9] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 16:59:41,746 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:00:48,141 ERROR com.example.spring.jwt.mongodb.security.jwt.AuthEntryPointJwt [http-nio-8080-exec-1] Unauthorized error: Full authentication is required to access this resource
2023-04-19 17:01:48,286 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-7] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:07:51,790 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 6800 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 17:07:51,793 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 17:07:54,662 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 17:07:54,663 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 17:07:54,802 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 17:07:55,097 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@40992749]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 17:07:55,138 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fd293fa96c83e34b5f38e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:7}] to localhost:27017
2023-04-19 17:07:55,144 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fd293fa96c83e34b5f38e', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:8}] to localhost:27017
2023-04-19 17:07:55,146 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fd293fa96c83e34b5f38e', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=59864805}
2023-04-19 17:07:55,973 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 17:07:56,043 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 17:07:56,265 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 17:07:56,447 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 17:07:56,938 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 17:07:56,962 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 17:07:57,870 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 17:07:58,691 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 17:07:58,692 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 17:07:58,769 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 17:07:59,102 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 17:07:59,241 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 17:07:59,317 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 17:07:59,318 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 17:07:59,319 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 17:07:59,321 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 17:07:59,322 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 17:07:59,713 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 39683.
2023-04-19 17:07:59,758 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 17:07:59,782 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 17:07:59,786 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 17:07:59,787 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 17:07:59,801 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-0df2a026-0627-4aa7-9f99-3bdec03a1c2b
2023-04-19 17:07:59,827 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 17:07:59,848 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 17:07:59,939 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @10621ms
2023-04-19 17:08:00,004 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 17:08:00,023 INFO org.spark_project.jetty.server.Server [restartedMain] Started @10706ms
2023-04-19 17:08:00,040 WARN org.apache.spark.util.Utils [restartedMain] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2023-04-19 17:08:00,048 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@8f88c3f{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-19 17:08:00,048 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4041.
2023-04-19 17:08:00,071 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6bdf21ea{/jobs,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,073 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@cfe11e0{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,074 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@fa6e775{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,076 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2bccdf78{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,077 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@13e9083b{/stages,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,079 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44ef1f37{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,080 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1edf50e6{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,083 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2847c9af{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,084 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10677543{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,085 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@418010c1{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,086 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@15ae5510{/storage,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,088 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3b2ecbb{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,089 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@28d44ce3{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,090 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69134720{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,092 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@e7299c7{/environment,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,093 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1a317b86{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,094 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10888f77{/executors,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,095 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6351f001{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,098 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7977e10d{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,099 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@688b58ee{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,107 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3cac81bf{/static,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,108 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@e5f87a8{/,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,110 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@19d985ad{/api,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,112 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4b460f09{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,115 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@76153afc{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 17:08:00,117 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4041
2023-04-19 17:08:00,221 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 17:08:00,250 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41695.
2023-04-19 17:08:00,251 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:41695
2023-04-19 17:08:00,253 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 17:08:00,284 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 41695, None)
2023-04-19 17:08:00,289 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:41695 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 41695, None)
2023-04-19 17:08:00,293 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 41695, None)
2023-04-19 17:08:00,294 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 41695, None)
2023-04-19 17:08:00,312 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@288f5afc{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 17:08:02,629 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Stopped Spark@8f88c3f{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-19 17:08:02,637 INFO org.apache.spark.ui.SparkUI [restartedMain] Stopped Spark web UI at http://192.168.1.125:4041
2023-04-19 17:08:02,651 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 17:08:02,665 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore cleared
2023-04-19 17:08:02,666 INFO org.apache.spark.storage.BlockManager [restartedMain] BlockManager stopped
2023-04-19 17:08:02,676 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] BlockManagerMaster stopped
2023-04-19 17:08:02,681 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-19 17:08:02,687 INFO org.apache.spark.SparkContext [restartedMain] Successfully stopped SparkContext
2023-04-19 17:08:02,688 INFO org.apache.spark.SparkContext [restartedMain] SparkContext already stopped.
2023-04-19 17:08:02,697 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 17:08:02,707 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 17:08:02,721 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 17:08:02,726 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:08:02,770 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Web server failed to start. Port 8080 was already in use.

Action:

Identify and stop the process that's listening on port 8080 or configure this application to listen on another port.

2023-04-19 17:08:20,297 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-8] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private transient java.lang.String java.net.URI.scheme accessible: module java.base does not "opens java.net" to unnamed module @14f232c4
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,014 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(23)-127.0.0.1] Stopping service [Tomcat]
2023-04-19 17:09:34,017 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(23)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-19 17:09:34,020 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,021 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='643fce9314fbf430adc3c94b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,022 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='643fce9314fbf430adc3c94b', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,024 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,025 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [spark-listener-group-streams] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3463)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3434)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1623)
 java.base@17.0.6/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:97)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
 app//org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
 app//org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1302)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
2023-04-19 17:09:34,026 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(23)-127.0.0.1] The web application [ROOT] appears to have started a thread named [org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Object.wait(Native Method)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
 app//org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:2989)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:09:34,039 INFO org.apache.spark.SparkContext [Thread-7] Invoking stop() from shutdown hook
2023-04-19 17:09:34,040 INFO org.apache.spark.SparkContext [Thread-7] SparkContext already stopped.
2023-04-19 17:09:34,048 INFO org.apache.spark.storage.DiskBlockManager [Thread-7] Shutdown hook called
2023-04-19 17:09:34,052 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(23)-127.0.0.1] Stopped Spark@650c3246{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 17:09:34,056 INFO org.apache.spark.ui.SparkUI [RMI TCP Connection(23)-127.0.0.1] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-19 17:09:34,056 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Shutdown hook called
2023-04-19 17:09:34,058 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Deleting directory /tmp/spark-9fbf1c03-a95c-4cc7-acb3-0ac34434eb43
2023-04-19 17:09:34,064 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Deleting directory /tmp/spark-9fbf1c03-a95c-4cc7-acb3-0ac34434eb43/userFiles-d60fa77a-3645-45ef-ab17-91eebe0f6b18
2023-04-19 17:09:34,073 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 17:09:34,081 INFO org.apache.spark.storage.memory.MemoryStore [RMI TCP Connection(23)-127.0.0.1] MemoryStore cleared
2023-04-19 17:09:34,082 INFO org.apache.spark.storage.BlockManager [RMI TCP Connection(23)-127.0.0.1] BlockManager stopped
2023-04-19 17:09:34,085 INFO org.apache.spark.storage.BlockManagerMaster [RMI TCP Connection(23)-127.0.0.1] BlockManagerMaster stopped
2023-04-19 17:09:34,094 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2023-04-19 17:09:34,102 INFO org.apache.spark.SparkContext [RMI TCP Connection(23)-127.0.0.1] Successfully stopped SparkContext
2023-04-19 17:09:34,103 INFO org.apache.spark.SparkContext [RMI TCP Connection(23)-127.0.0.1] SparkContext already stopped.
2023-04-19 17:09:34,111 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(23)-127.0.0.1] HikariPool-1 - Shutdown initiated...
2023-04-19 17:09:34,126 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(23)-127.0.0.1] HikariPool-1 - Shutdown completed.
2023-04-19 17:09:58,358 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 7026 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 17:09:58,362 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 17:10:01,038 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 17:10:01,038 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 17:10:01,179 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 17:10:01,477 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@3de2cd74]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 17:10:01,510 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fd3113db13f74cb8eef49', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:9}] to localhost:27017
2023-04-19 17:10:01,513 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fd3113db13f74cb8eef49', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:10}] to localhost:27017
2023-04-19 17:10:01,514 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fd3113db13f74cb8eef49', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=39626277}
2023-04-19 17:10:02,439 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 17:10:02,510 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 17:10:02,720 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 17:10:02,863 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 17:10:03,332 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 17:10:03,360 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 17:10:04,382 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 17:10:05,321 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 17:10:05,322 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 17:10:05,401 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 17:10:05,742 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 17:10:05,891 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 17:10:05,979 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 17:10:05,980 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 17:10:05,981 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 17:10:05,983 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 17:10:05,984 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 17:10:06,446 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 32867.
2023-04-19 17:10:06,493 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 17:10:06,530 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 17:10:06,537 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 17:10:06,539 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 17:10:06,559 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-00fdd0f0-9a24-46ad-b80c-2667879f5a57
2023-04-19 17:10:06,598 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 17:10:06,623 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 17:10:06,733 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @10787ms
2023-04-19 17:10:06,806 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 17:10:06,831 INFO org.spark_project.jetty.server.Server [restartedMain] Started @10886ms
2023-04-19 17:10:06,865 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@5beccda9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 17:10:06,866 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-19 17:10:06,897 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5f84dbcd{/jobs,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,899 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@34974f84{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,901 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2dc2018f{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,902 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1b25c1a1{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,903 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@26567533{/stages,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,904 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@62fd60f3{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,905 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@75155489{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,907 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@628feb3{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,909 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@460651ab{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,910 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@178f70a1{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,911 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6c720b83{/storage,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,912 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2deeadd8{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,913 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@59913ac7{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,914 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3577432c{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,915 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@49256812{/environment,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,916 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@117d9c83{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,917 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@41eadb69{/executors,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,918 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4e8b8e5b{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,920 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2c0c0a60{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,922 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@516812e6{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,936 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@46ceaa31{/static,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,938 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@161fb84a{/,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,940 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@69f8a521{/api,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,942 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5640e3d3{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,943 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@9fce192{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 17:10:06,964 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-19 17:10:07,100 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 17:10:07,131 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36865.
2023-04-19 17:10:07,133 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:36865
2023-04-19 17:10:07,135 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 17:10:07,169 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 36865, None)
2023-04-19 17:10:07,174 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:36865 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 36865, None)
2023-04-19 17:10:07,179 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 36865, None)
2023-04-19 17:10:07,180 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 36865, None)
2023-04-19 17:10:07,199 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@590c490{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:09,643 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 12.028 seconds (JVM running for 13.698)
2023-04-19 17:10:09,648 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-19 17:10:09,648 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-19 17:10:19,438 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-19 17:10:19,714 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:11}] to localhost:27017
2023-04-19 17:10:19,931 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse').
2023-04-19 17:10:19,932 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Warehouse path is 'file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse'.
2023-04-19 17:10:19,946 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@53e717e9{/SQL,null,AVAILABLE,@Spark}
2023-04-19 17:10:19,947 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@7aa5ec76{/SQL/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:19,949 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@947f7a4{/SQL/execution,null,AVAILABLE,@Spark}
2023-04-19 17:10:19,951 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@62cb0355{/SQL/execution/json,null,AVAILABLE,@Spark}
2023-04-19 17:10:19,954 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@3b677ca7{/static/sql,null,AVAILABLE,@Spark}
2023-04-19 17:10:20,732 INFO org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef [http-nio-8080-exec-1] Registered StateStoreCoordinator endpoint
2023-04-19 17:10:21,117 ERROR org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/].[dispatcherServlet] [http-nio-8080-exec-1] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.reflect.InaccessibleObjectException: Unable to make field private final byte[] java.lang.String.value accessible: module java.base does not "opens java.lang" to unnamed module @24c22fe] with root cause
java.lang.reflect.InaccessibleObjectException: Unable to make field private final byte[] java.lang.String.value accessible: module java.base does not "opens java.lang" to unnamed module @24c22fe
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:354)
	at java.base/java.lang.reflect.AccessibleObject.checkCanSetAccessible(AccessibleObject.java:297)
	at java.base/java.lang.reflect.Field.checkCanSetAccessible(Field.java:178)
	at java.base/java.lang.reflect.Field.setAccessible(Field.java:172)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:336)
	at org.apache.spark.util.SizeEstimator$$anonfun$getClassInfo$3.apply(SizeEstimator.scala:330)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.SizeEstimator$.getClassInfo(SizeEstimator.scala:330)
	at org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:222)
	at org.apache.spark.util.SizeEstimator$.org$apache$spark$util$SizeEstimator$$estimate(SizeEstimator.scala:201)
	at org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:69)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:109)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$1.weigh(FileStatusCache.scala:107)
	at org.spark_project.guava.cache.LocalCache$Segment.setValue(LocalCache.java:2222)
	at org.spark_project.guava.cache.LocalCache$Segment.put(LocalCache.java:2944)
	at org.spark_project.guava.cache.LocalCache.put(LocalCache.java:4212)
	at org.spark_project.guava.cache.LocalCache$LocalManualCache.put(LocalCache.java:4804)
	at org.apache.spark.sql.execution.datasources.SharedInMemoryCache$$anon$3.putLeafFiles(FileStatusCache.scala:152)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:131)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex$$anonfun$listLeafFiles$2.apply(InMemoryFileIndex.scala:129)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.listLeafFiles(InMemoryFileIndex.scala:129)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.refresh0(InMemoryFileIndex.scala:91)
	at org.apache.spark.sql.execution.datasources.InMemoryFileIndex.<init>(InMemoryFileIndex.scala:67)
	at org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$createInMemoryFileIndex(DataSource.scala:533)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:371)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:619)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:468)
	at com.example.spring.jwt.mongodb.controllers.SparkController.readFile(SparkController.java:55)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:568)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:150)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:117)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1070)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:227)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:111)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:337)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.invoke(FilterSecurityInterceptor.java:115)
	at org.springframework.security.web.access.intercept.FilterSecurityInterceptor.doFilter(FilterSecurityInterceptor.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:122)
	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:116)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:126)
	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:81)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:109)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:149)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at com.example.spring.jwt.mongodb.security.jwt.AuthTokenFilter.doFilterInternal(AuthTokenFilter.java:50)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:103)
	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:89)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:91)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.header.HeaderWriterFilter.doHeadersAfter(HeaderWriterFilter.java:90)
	at org.springframework.security.web.header.HeaderWriterFilter.doFilterInternal(HeaderWriterFilter.java:75)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:112)
	at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java:82)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java:55)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.session.DisableEncodeUrlFilter.doFilterInternal(DisableEncodeUrlFilter.java:42)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:346)
	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:221)
	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:186)
	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:354)
	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:267)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:117)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:189)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:162)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:197)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:135)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:360)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:399)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:890)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1789)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1191)
	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:659)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:14,445 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 7280 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 17:12:14,449 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 17:12:17,532 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 17:12:17,533 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 17:12:17,682 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 17:12:18,018 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@2ff30aaf]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 17:12:18,045 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fd3996c7fd83f822a4cc0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:13}] to localhost:27017
2023-04-19 17:12:18,048 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fd3996c7fd83f822a4cc0', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:12}] to localhost:27017
2023-04-19 17:12:18,049 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fd3996c7fd83f822a4cc0', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=39760677}
2023-04-19 17:12:18,955 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 17:12:19,079 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 17:12:19,452 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 17:12:19,660 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 17:12:20,190 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 17:12:20,226 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 17:12:21,259 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 17:12:22,263 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 17:12:22,265 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 17:12:22,403 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 17:12:22,776 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 17:12:22,977 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 17:12:23,101 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 17:12:23,102 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 17:12:23,104 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 17:12:23,106 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 17:12:23,107 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 17:12:23,657 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 35299.
2023-04-19 17:12:23,693 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 17:12:23,721 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 17:12:23,728 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 17:12:23,729 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 17:12:23,749 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-5a7ca6fb-db1e-4c76-a0d9-19032ddbe419
2023-04-19 17:12:23,786 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 17:12:23,820 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 17:12:23,983 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @11935ms
2023-04-19 17:12:24,061 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 17:12:24,083 INFO org.spark_project.jetty.server.Server [restartedMain] Started @12035ms
2023-04-19 17:12:24,108 WARN org.apache.spark.util.Utils [restartedMain] Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2023-04-19 17:12:24,116 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@6e49d170{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-19 17:12:24,116 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4041.
2023-04-19 17:12:24,150 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@370e23e2{/jobs,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,152 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@440b0b91{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,155 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6f1793b3{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,158 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1b4472b7{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,159 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@489de067{/stages,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,161 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@63de0106{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,162 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@199926af{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,164 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@65d7d2b7{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,166 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@28b09801{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,167 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@5911b6f2{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,169 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1ff91805{/storage,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,171 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@44602327{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,174 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@68bccb3a{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,175 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3c4e56f9{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,178 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6b204845{/environment,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,182 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2e1c371d{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,185 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@20f7dcff{/executors,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,187 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6ec0af86{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,189 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@74ba07b{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,190 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@48a0cb50{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,204 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@56aee69f{/static,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,207 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@381f0a5e{/,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,214 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@30c529f9{/api,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,216 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3b4cb74a{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,218 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@15dae192{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 17:12:24,222 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4041
2023-04-19 17:12:24,404 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 17:12:24,434 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42249.
2023-04-19 17:12:24,436 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:42249
2023-04-19 17:12:24,439 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 17:12:24,484 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 42249, None)
2023-04-19 17:12:24,489 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:42249 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 42249, None)
2023-04-19 17:12:24,495 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 42249, None)
2023-04-19 17:12:24,497 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 42249, None)
2023-04-19 17:12:24,515 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@4f52b060{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:27,218 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Stopped Spark@6e49d170{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2023-04-19 17:12:27,221 INFO org.apache.spark.ui.SparkUI [restartedMain] Stopped Spark web UI at http://192.168.1.125:4041
2023-04-19 17:12:27,236 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-2] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 17:12:27,299 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore cleared
2023-04-19 17:12:27,300 INFO org.apache.spark.storage.BlockManager [restartedMain] BlockManager stopped
2023-04-19 17:12:27,311 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] BlockManagerMaster stopped
2023-04-19 17:12:27,317 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-3] OutputCommitCoordinator stopped!
2023-04-19 17:12:27,334 INFO org.apache.spark.SparkContext [restartedMain] Successfully stopped SparkContext
2023-04-19 17:12:27,336 INFO org.apache.spark.SparkContext [restartedMain] SparkContext already stopped.
2023-04-19 17:12:27,345 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown initiated...
2023-04-19 17:12:27,362 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Shutdown completed.
2023-04-19 17:12:27,376 INFO org.apache.catalina.core.StandardService [restartedMain] Stopping service [Tomcat]
2023-04-19 17:12:27,388 WARN org.apache.catalina.loader.WebappClassLoaderBase [restartedMain] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:27,532 ERROR org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter [restartedMain] 

***************************
APPLICATION FAILED TO START
***************************

Description:

Web server failed to start. Port 8080 was already in use.

Action:

Identify and stop the process that's listening on port 8080 or configure this application to listen on another port.

2023-04-19 17:12:27,541 INFO org.apache.spark.util.ShutdownHookManager [Thread-5] Shutdown hook called
2023-04-19 17:12:27,543 INFO org.apache.spark.util.ShutdownHookManager [Thread-5] Deleting directory /tmp/spark-bbb5ec75-0d6b-4c6f-82a6-4f1afc082948
2023-04-19 17:12:30,834 INFO org.apache.catalina.core.StandardService [RMI TCP Connection(6)-127.0.0.1] Stopping service [Tomcat]
2023-04-19 17:12:30,838 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [RMI TCP Connection(6)-127.0.0.1] Destroying Spring FrameworkServlet 'dispatcherServlet'
2023-04-19 17:12:30,841 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [BufferPoolPruner-1-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:30,842 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-ClusterId{value='643fd3113db13f74cb8eef49', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForSignalOrTimeout(DefaultServerMonitor.java:300)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.waitForNext(DefaultServerMonitor.java:281)
 app//com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:179)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:30,843 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [cluster-rtt-ClusterId{value='643fd3113db13f74cb8eef49', description='null'}-localhost:27017] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Thread.sleep(Native Method)
 app//com.mongodb.internal.connection.DefaultServerMonitor.waitForNext(DefaultServerMonitor.java:443)
 app//com.mongodb.internal.connection.DefaultServerMonitor.access$1500(DefaultServerMonitor.java:64)
 app//com.mongodb.internal.connection.DefaultServerMonitor$RoundTripTimeRunnable.run(DefaultServerMonitor.java:415)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:30,844 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [MaintenanceTimer-2-thread-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:252)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1672)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1182)
 java.base@17.0.6/java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:899)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1062)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1122)
 java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:30,846 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [spark-listener-group-streams] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/jdk.internal.misc.Unsafe.park(Native Method)
 java.base@17.0.6/java.util.concurrent.locks.LockSupport.park(LockSupport.java:341)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionNode.block(AbstractQueuedSynchronizer.java:506)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.unmanagedBlock(ForkJoinPool.java:3463)
 java.base@17.0.6/java.util.concurrent.ForkJoinPool.managedBlock(ForkJoinPool.java:3434)
 java.base@17.0.6/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1623)
 java.base@17.0.6/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:435)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:97)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
 app//scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
 app//org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
 app//org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1302)
 app//org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
2023-04-19 17:12:30,848 WARN org.apache.catalina.loader.WebappClassLoaderBase [RMI TCP Connection(6)-127.0.0.1] The web application [ROOT] appears to have started a thread named [org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 java.base@17.0.6/java.lang.Object.wait(Native Method)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:155)
 java.base@17.0.6/java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:176)
 app//org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:2989)
 java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2023-04-19 17:12:30,858 INFO org.apache.spark.storage.DiskBlockManager [Thread-7] Shutdown hook called
2023-04-19 17:12:30,864 INFO org.spark_project.jetty.server.AbstractConnector [RMI TCP Connection(6)-127.0.0.1] Stopped Spark@5beccda9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 17:12:30,868 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Shutdown hook called
2023-04-19 17:12:30,868 INFO org.apache.spark.ui.SparkUI [RMI TCP Connection(6)-127.0.0.1] Stopped Spark web UI at http://192.168.1.125:4040
2023-04-19 17:12:30,870 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Deleting directory /tmp/spark-0d92c258-bd9b-45a7-8643-f4660ead16f3/userFiles-88ff2248-ed26-4e2c-af19-eb1809f0b52d
2023-04-19 17:12:30,876 INFO org.apache.spark.util.ShutdownHookManager [Thread-7] Deleting directory /tmp/spark-0d92c258-bd9b-45a7-8643-f4660ead16f3
2023-04-19 17:12:30,882 INFO org.apache.spark.MapOutputTrackerMasterEndpoint [dispatcher-event-loop-3] MapOutputTrackerMasterEndpoint stopped!
2023-04-19 17:12:30,889 INFO org.apache.spark.storage.memory.MemoryStore [RMI TCP Connection(6)-127.0.0.1] MemoryStore cleared
2023-04-19 17:12:30,890 INFO org.apache.spark.storage.BlockManager [RMI TCP Connection(6)-127.0.0.1] BlockManager stopped
2023-04-19 17:12:30,891 INFO org.apache.spark.storage.BlockManagerMaster [RMI TCP Connection(6)-127.0.0.1] BlockManagerMaster stopped
2023-04-19 17:12:30,898 INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint [dispatcher-event-loop-0] OutputCommitCoordinator stopped!
2023-04-19 17:12:30,915 INFO org.apache.spark.SparkContext [RMI TCP Connection(6)-127.0.0.1] Successfully stopped SparkContext
2023-04-19 17:12:30,916 INFO org.apache.spark.SparkContext [RMI TCP Connection(6)-127.0.0.1] SparkContext already stopped.
2023-04-19 17:12:30,926 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(6)-127.0.0.1] HikariPool-1 - Shutdown initiated...
2023-04-19 17:12:30,953 INFO com.zaxxer.hikari.HikariDataSource [RMI TCP Connection(6)-127.0.0.1] HikariPool-1 - Shutdown completed.
2023-04-19 17:12:36,425 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Starting SpringBootSecurityJwtMongodbApplication using Java 17.0.6 on wks-012 with PID 7473 (/home/inferyx/git/SpringApplicationWithSecurity/target/classes started by inferyx in /home/inferyx/git/SpringApplicationWithSecurity)
2023-04-19 17:12:36,427 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] No active profile set, falling back to 1 default profile: "default"
2023-04-19 17:12:39,208 INFO org.apache.catalina.core.StandardService [restartedMain] Starting service [Tomcat]
2023-04-19 17:12:39,209 INFO org.apache.catalina.core.StandardEngine [restartedMain] Starting Servlet engine: [Apache Tomcat/9.0.65]
2023-04-19 17:12:39,341 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [restartedMain] Initializing Spring embedded WebApplicationContext
2023-04-19 17:12:39,587 INFO org.mongodb.driver.client [restartedMain] MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|spring-boot", "version": "4.6.1"}, "os": {"type": "Linux", "name": "Linux", "architecture": "amd64", "version": "5.15.0-69-generic"}, "platform": "Java/Eclipse Adoptium/17.0.6+10"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@287d84a3]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=JAVA_LEGACY, serverApi=null, autoEncryptionSettings=null, contextProvider=null}
2023-04-19 17:12:39,617 INFO org.mongodb.driver.connection [cluster-rtt-ClusterId{value='643fd3af5a94df187277def7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:2, serverValue:15}] to localhost:27017
2023-04-19 17:12:39,622 INFO org.mongodb.driver.connection [cluster-ClusterId{value='643fd3af5a94df187277def7', description='null'}-localhost:27017] Opened connection [connectionId{localValue:1, serverValue:14}] to localhost:27017
2023-04-19 17:12:39,623 INFO org.mongodb.driver.cluster [cluster-ClusterId{value='643fd3af5a94df187277def7', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=6, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=33472526}
2023-04-19 17:12:40,362 INFO org.hibernate.jpa.internal.util.LogHelper [restartedMain] HHH000204: Processing PersistenceUnitInfo [name: default]
2023-04-19 17:12:40,437 INFO org.hibernate.Version [restartedMain] HHH000412: Hibernate ORM core version 5.6.10.Final
2023-04-19 17:12:40,644 INFO org.hibernate.annotations.common.Version [restartedMain] HCANN000001: Hibernate Commons Annotations {5.1.2.Final}
2023-04-19 17:12:40,781 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Starting...
2023-04-19 17:12:41,258 INFO com.zaxxer.hikari.HikariDataSource [restartedMain] HikariPool-1 - Start completed.
2023-04-19 17:12:41,286 INFO org.hibernate.dialect.Dialect [restartedMain] HHH000400: Using dialect: org.hibernate.dialect.MySQL5Dialect
2023-04-19 17:12:42,300 INFO org.hibernate.engine.transaction.jta.platform.internal.JtaPlatformInitiator [restartedMain] HHH000490: Using JtaPlatform implementation: [org.hibernate.engine.transaction.jta.platform.internal.NoJtaPlatform]
2023-04-19 17:12:43,132 WARN org.apache.spark.util.Utils [restartedMain] Your hostname, wks-012 resolves to a loopback address: 127.0.1.1; using 192.168.1.125 instead (on interface wlp6s0)
2023-04-19 17:12:43,133 WARN org.apache.spark.util.Utils [restartedMain] Set SPARK_LOCAL_IP if you need to bind to another address
2023-04-19 17:12:43,301 INFO org.apache.spark.SparkContext [restartedMain] Running Spark version 2.4.5
2023-04-19 17:12:43,663 WARN org.apache.hadoop.util.NativeCodeLoader [restartedMain] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-04-19 17:12:43,891 INFO org.apache.spark.SparkContext [restartedMain] Submitted application: MyAppName
2023-04-19 17:12:43,973 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls to: inferyx
2023-04-19 17:12:43,975 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls to: inferyx
2023-04-19 17:12:43,976 INFO org.apache.spark.SecurityManager [restartedMain] Changing view acls groups to: 
2023-04-19 17:12:43,978 INFO org.apache.spark.SecurityManager [restartedMain] Changing modify acls groups to: 
2023-04-19 17:12:43,980 INFO org.apache.spark.SecurityManager [restartedMain] SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inferyx); groups with view permissions: Set(); users  with modify permissions: Set(inferyx); groups with modify permissions: Set()
2023-04-19 17:12:44,420 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'sparkDriver' on port 43471.
2023-04-19 17:12:44,454 INFO org.apache.spark.SparkEnv [restartedMain] Registering MapOutputTracker
2023-04-19 17:12:44,481 INFO org.apache.spark.SparkEnv [restartedMain] Registering BlockManagerMaster
2023-04-19 17:12:44,487 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2023-04-19 17:12:44,488 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [restartedMain] BlockManagerMasterEndpoint up
2023-04-19 17:12:44,503 INFO org.apache.spark.storage.DiskBlockManager [restartedMain] Created local directory at /tmp/blockmgr-87a78507-de92-4a38-858c-e9543119d0a1
2023-04-19 17:12:44,535 INFO org.apache.spark.storage.memory.MemoryStore [restartedMain] MemoryStore started with capacity 998.4 MB
2023-04-19 17:12:44,560 INFO org.apache.spark.SparkEnv [restartedMain] Registering OutputCommitCoordinator
2023-04-19 17:12:44,688 INFO org.spark_project.jetty.util.log [restartedMain] Logging initialized @10586ms
2023-04-19 17:12:44,765 INFO org.spark_project.jetty.server.Server [restartedMain] jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2023-04-19 17:12:44,785 INFO org.spark_project.jetty.server.Server [restartedMain] Started @10683ms
2023-04-19 17:12:44,809 INFO org.spark_project.jetty.server.AbstractConnector [restartedMain] Started ServerConnector@647c3db4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2023-04-19 17:12:44,810 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'SparkUI' on port 4040.
2023-04-19 17:12:44,834 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@682017e4{/jobs,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,836 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7a96d93e{/jobs/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,837 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@72605b56{/jobs/job,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,840 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1d698100{/jobs/job/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,842 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6da3d310{/stages,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,844 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@2f199ff9{/stages/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,845 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@290c241f{/stages/stage,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,848 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e3ae772{/stages/stage/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,850 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@10d7cd30{/stages/pool,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,851 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@707741df{/stages/pool/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,852 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7f324eec{/storage,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,853 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@165a370f{/storage/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,854 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@384ac6b9{/storage/rdd,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,856 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@727911d6{/storage/rdd/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,857 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@1fd1645b{/environment,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,858 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@58f4cae1{/environment/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,860 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3665a048{/executors,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,861 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@ca8f0f3{/executors/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,862 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@18cfbe81{/executors/threadDump,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,863 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@6612ccbb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,873 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7d6e57d1{/static,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,875 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@3e0d0c47{/,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,878 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@e47ee5e{/api,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,881 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@21caf4e4{/jobs/job/kill,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,883 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@7b452343{/stages/stage/kill,null,AVAILABLE,@Spark}
2023-04-19 17:12:44,887 INFO org.apache.spark.ui.SparkUI [restartedMain] Bound SparkUI to 0.0.0.0, and started at http://192.168.1.125:4040
2023-04-19 17:12:45,021 INFO org.apache.spark.executor.Executor [restartedMain] Starting executor ID driver on host localhost
2023-04-19 17:12:45,058 INFO org.apache.spark.util.Utils [restartedMain] Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41995.
2023-04-19 17:12:45,059 INFO org.apache.spark.network.netty.NettyBlockTransferService [restartedMain] Server created on 192.168.1.125:41995
2023-04-19 17:12:45,062 INFO org.apache.spark.storage.BlockManager [restartedMain] Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2023-04-19 17:12:45,105 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registering BlockManager BlockManagerId(driver, 192.168.1.125, 41995, None)
2023-04-19 17:12:45,112 INFO org.apache.spark.storage.BlockManagerMasterEndpoint [dispatcher-event-loop-2] Registering block manager 192.168.1.125:41995 with 998.4 MB RAM, BlockManagerId(driver, 192.168.1.125, 41995, None)
2023-04-19 17:12:45,117 INFO org.apache.spark.storage.BlockManagerMaster [restartedMain] Registered BlockManager BlockManagerId(driver, 192.168.1.125, 41995, None)
2023-04-19 17:12:45,118 INFO org.apache.spark.storage.BlockManager [restartedMain] Initialized BlockManager: BlockManagerId(driver, 192.168.1.125, 41995, None)
2023-04-19 17:12:45,135 INFO org.spark_project.jetty.server.handler.ContextHandler [restartedMain] Started o.s.j.s.ServletContextHandler@727c3ed9{/metrics/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:47,554 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] Started SpringBootSecurityJwtMongodbApplication in 11.836 seconds (JVM running for 13.452)
2023-04-19 17:12:47,561 INFO com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a info message
2023-04-19 17:12:47,562 WARN com.example.spring.jwt.mongodb.SpringBootSecurityJwtMongodbApplication [restartedMain] This is a warn message
2023-04-19 17:12:52,052 INFO org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] [http-nio-8080-exec-1] Initializing Spring DispatcherServlet 'dispatcherServlet'
2023-04-19 17:12:52,291 INFO org.mongodb.driver.connection [http-nio-8080-exec-1] Opened connection [connectionId{localValue:3, serverValue:16}] to localhost:27017
2023-04-19 17:12:52,464 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse').
2023-04-19 17:12:52,465 INFO org.apache.spark.sql.internal.SharedState [http-nio-8080-exec-1] Warehouse path is 'file:/home/inferyx/git/SpringApplicationWithSecurity/spark-warehouse'.
2023-04-19 17:12:52,480 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@2a154c23{/SQL,null,AVAILABLE,@Spark}
2023-04-19 17:12:52,482 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@48f706e1{/SQL/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:52,484 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@9fc424a{/SQL/execution,null,AVAILABLE,@Spark}
2023-04-19 17:12:52,486 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@784a9b55{/SQL/execution/json,null,AVAILABLE,@Spark}
2023-04-19 17:12:52,490 INFO org.spark_project.jetty.server.handler.ContextHandler [http-nio-8080-exec-1] Started o.s.j.s.ServletContextHandler@6e3e167a{/static/sql,null,AVAILABLE,@Spark}
2023-04-19 17:12:53,298 INFO org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef [http-nio-8080-exec-1] Registered StateStoreCoordinator endpoint
2023-04-19 17:12:53,645 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 96 ms to list leaf files for 1 paths.
2023-04-19 17:12:54,080 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 3 ms to list leaf files for 1 paths.
2023-04-19 17:12:58,428 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:12:58,435 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#0, None)) > 0)
2023-04-19 17:12:58,452 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:12:58,467 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:12:59,410 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 339.492737 ms
2023-04-19 17:13:00,035 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 50.681758 ms
2023-04-19 17:13:00,380 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_0 stored as values in memory (estimated size 112.7 KB, free 998.3 MB)
2023-04-19 17:13:00,574 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.3 MB)
2023-04-19 17:13:00,579 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_0_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.4 MB)
2023-04-19 17:13:00,612 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 0 from csv at SparkController.java:55
2023-04-19 17:13:00,659 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:01,207 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:55
2023-04-19 17:13:01,299 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 0 (csv at SparkController.java:55) with 1 output partitions
2023-04-19 17:13:01,300 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 0 (csv at SparkController.java:55)
2023-04-19 17:13:01,301 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:01,306 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:01,375 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at SparkController.java:55), which has no missing parents
2023-04-19 17:13:01,688 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 998.3 MB)
2023-04-19 17:13:01,691 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 998.3 MB)
2023-04-19 17:13:01,692 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_1_piece0 in memory on 192.168.1.125:41995 (size: 4.6 KB, free: 998.4 MB)
2023-04-19 17:13:01,694 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 1 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:01,735 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at SparkController.java:55) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:01,777 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 0.0 with 1 tasks
2023-04-19 17:13:02,050 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-19 17:13:02,121 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 0] Running task 0.0 in stage 0.0 (TID 0)
2023-04-19 17:13:02,344 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 0] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-19 17:13:02,386 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 0] Code generated in 19.123566 ms
2023-04-19 17:13:02,566 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 0] Finished task 0.0 in stage 0.0 (TID 0). 1307 bytes result sent to driver
2023-04-19 17:13:02,593 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 0.0 (TID 0) in 598 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:02,612 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 0.0, whose tasks have all completed, from pool 
2023-04-19 17:13:02,640 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 0 (csv at SparkController.java:55) finished in 1.101 s
2023-04-19 17:13:02,653 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 0 finished: csv at SparkController.java:55, took 1.445101 s
2023-04-19 17:13:02,865 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:02,867 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:02,868 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:13:02,869 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:02,893 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 16.898641 ms
2023-04-19 17:13:02,947 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_2 stored as values in memory (estimated size 112.7 KB, free 998.1 MB)
2023-04-19 17:13:02,970 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.1 MB)
2023-04-19 17:13:02,974 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_2_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.4 MB)
2023-04-19 17:13:02,977 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 2 from csv at SparkController.java:55
2023-04-19 17:13:02,979 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:03,158 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:55
2023-04-19 17:13:03,161 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 1 (csv at SparkController.java:55) with 1 output partitions
2023-04-19 17:13:03,161 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 1 (csv at SparkController.java:55)
2023-04-19 17:13:03,161 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:03,162 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:03,164 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at SparkController.java:55), which has no missing parents
2023-04-19 17:13:03,170 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 998.1 MB)
2023-04-19 17:13:03,173 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 998.1 MB)
2023-04-19 17:13:03,177 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_3_piece0 in memory on 192.168.1.125:41995 (size: 7.6 KB, free: 998.3 MB)
2023-04-19 17:13:03,177 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 3 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:03,179 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at SparkController.java:55) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:03,180 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 1.0 with 1 tasks
2023-04-19 17:13:03,182 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-19 17:13:03,183 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 1] Running task 0.0 in stage 1.0 (TID 1)
2023-04-19 17:13:03,223 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 1] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-19 17:13:03,283 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 1] Finished task 0.0 in stage 1.0 (TID 1). 1493 bytes result sent to driver
2023-04-19 17:13:03,286 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 1.0 (TID 1) in 105 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:03,289 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 1 (csv at SparkController.java:55) finished in 0.123 s
2023-04-19 17:13:03,294 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 1.0, whose tasks have all completed, from pool 
2023-04-19 17:13:03,294 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 1 finished: csv at SparkController.java:55, took 0.134427 s
2023-04-19 17:13:03,397 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:03,399 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:03,400 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:03,402 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:03,493 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 38.494058 ms
2023-04-19 17:13:03,543 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_4 stored as values in memory (estimated size 112.7 KB, free 998.0 MB)
2023-04-19 17:13:03,559 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KB, free 998.0 MB)
2023-04-19 17:13:03,561 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_4_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:03,562 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 4 from show at SparkController.java:58
2023-04-19 17:13:03,608 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:03,669 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:58
2023-04-19 17:13:03,671 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 2 (show at SparkController.java:58) with 1 output partitions
2023-04-19 17:13:03,672 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 2 (show at SparkController.java:58)
2023-04-19 17:13:03,672 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:03,672 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:03,673 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 2 (MapPartitionsRDD[13] at show at SparkController.java:58), which has no missing parents
2023-04-19 17:13:03,678 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_5 stored as values in memory (estimated size 10.4 KB, free 998.0 MB)
2023-04-19 17:13:03,685 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 998.0 MB)
2023-04-19 17:13:03,686 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_5_piece0 in memory on 192.168.1.125:41995 (size: 5.7 KB, free: 998.3 MB)
2023-04-19 17:13:03,687 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 5 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:03,689 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at show at SparkController.java:58) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:03,689 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 2.0 with 1 tasks
2023-04-19 17:13:03,690 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-19 17:13:03,691 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 2] Running task 0.0 in stage 2.0 (TID 2)
2023-04-19 17:13:03,697 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 2] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-19 17:13:03,733 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 2] Code generated in 31.327006 ms
2023-04-19 17:13:03,802 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 2] Finished task 0.0 in stage 2.0 (TID 2). 1677 bytes result sent to driver
2023-04-19 17:13:03,806 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 2.0 (TID 2) in 116 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:03,808 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 2.0, whose tasks have all completed, from pool 
2023-04-19 17:13:03,810 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 2 (show at SparkController.java:58) finished in 0.133 s
2023-04-19 17:13:03,811 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 2 finished: show at SparkController.java:58, took 0.141156 s
2023-04-19 17:13:03,855 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Csv File
2023-04-19 17:13:03,979 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-19 17:13:04,096 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-19 17:13:04,324 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:04,325 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#53, None)) > 0)
2023-04-19 17:13:04,326 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:13:04,327 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:04,402 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_6 stored as values in memory (estimated size 112.8 KB, free 997.8 MB)
2023-04-19 17:13:04,426 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.8 MB)
2023-04-19 17:13:04,428 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_6_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:04,430 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 6 from csv at SparkController.java:66
2023-04-19 17:13:04,431 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:04,503 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:66
2023-04-19 17:13:04,506 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 3 (csv at SparkController.java:66) with 1 output partitions
2023-04-19 17:13:04,506 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 3 (csv at SparkController.java:66)
2023-04-19 17:13:04,507 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:04,508 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:04,513 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 3 (MapPartitionsRDD[17] at csv at SparkController.java:66), which has no missing parents
2023-04-19 17:13:04,519 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_7 stored as values in memory (estimated size 8.9 KB, free 997.8 MB)
2023-04-19 17:13:04,524 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 997.8 MB)
2023-04-19 17:13:04,526 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_7_piece0 in memory on 192.168.1.125:41995 (size: 4.6 KB, free: 998.3 MB)
2023-04-19 17:13:04,527 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 7 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:04,528 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at csv at SparkController.java:66) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:04,528 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 3.0 with 1 tasks
2023-04-19 17:13:04,530 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-19 17:13:04,530 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 3] Running task 0.0 in stage 3.0 (TID 3)
2023-04-19 17:13:04,539 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 3] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-19 17:13:04,577 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 3] Finished task 0.0 in stage 3.0 (TID 3). 1315 bytes result sent to driver
2023-04-19 17:13:04,579 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 3.0 (TID 3) in 50 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:04,579 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 3.0, whose tasks have all completed, from pool 
2023-04-19 17:13:04,580 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 3 (csv at SparkController.java:66) finished in 0.066 s
2023-04-19 17:13:04,581 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 3 finished: csv at SparkController.java:66, took 0.077563 s
2023-04-19 17:13:04,634 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:04,635 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:04,636 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:13:04,637 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:04,684 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_8 stored as values in memory (estimated size 112.8 KB, free 997.7 MB)
2023-04-19 17:13:04,701 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.7 MB)
2023-04-19 17:13:04,703 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_8_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:04,707 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 8 from csv at SparkController.java:66
2023-04-19 17:13:04,709 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:04,739 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:66
2023-04-19 17:13:04,743 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 4 (csv at SparkController.java:66) with 1 output partitions
2023-04-19 17:13:04,743 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 4 (csv at SparkController.java:66)
2023-04-19 17:13:04,743 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:04,744 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:04,744 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 4 (MapPartitionsRDD[23] at csv at SparkController.java:66), which has no missing parents
2023-04-19 17:13:04,752 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_9 stored as values in memory (estimated size 13.9 KB, free 997.7 MB)
2023-04-19 17:13:04,756 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.6 KB, free 997.7 MB)
2023-04-19 17:13:04,757 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_9_piece0 in memory on 192.168.1.125:41995 (size: 7.6 KB, free: 998.3 MB)
2023-04-19 17:13:04,758 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 9 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:04,760 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at csv at SparkController.java:66) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:04,761 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 4.0 with 1 tasks
2023-04-19 17:13:04,763 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-19 17:13:04,763 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 4] Running task 0.0 in stage 4.0 (TID 4)
2023-04-19 17:13:04,774 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 4] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-19 17:13:04,782 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 4] Finished task 0.0 in stage 4.0 (TID 4). 1543 bytes result sent to driver
2023-04-19 17:13:04,786 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 4.0 (TID 4) in 24 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:04,786 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 4.0, whose tasks have all completed, from pool 
2023-04-19 17:13:04,788 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 4 (csv at SparkController.java:66) finished in 0.040 s
2023-04-19 17:13:04,790 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 4 finished: csv at SparkController.java:66, took 0.049547 s
2023-04-19 17:13:04,886 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:04,888 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:04,889 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:04,889 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:05,020 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 30.441914 ms
2023-04-19 17:13:05,068 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_10 stored as values in memory (estimated size 112.8 KB, free 997.6 MB)
2023-04-19 17:13:05,082 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.5 MB)
2023-04-19 17:13:05,084 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_10_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:05,092 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 10 from show at SparkController.java:69
2023-04-19 17:13:05,094 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:05,155 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:69
2023-04-19 17:13:05,157 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 5 (show at SparkController.java:69) with 1 output partitions
2023-04-19 17:13:05,157 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 5 (show at SparkController.java:69)
2023-04-19 17:13:05,157 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:05,158 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:05,158 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 5 (MapPartitionsRDD[27] at show at SparkController.java:69), which has no missing parents
2023-04-19 17:13:05,163 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_11 stored as values in memory (estimated size 12.6 KB, free 997.5 MB)
2023-04-19 17:13:05,166 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.3 KB, free 997.5 MB)
2023-04-19 17:13:05,167 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_11_piece0 in memory on 192.168.1.125:41995 (size: 6.3 KB, free: 998.2 MB)
2023-04-19 17:13:05,170 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 11 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:05,172 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at show at SparkController.java:69) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:05,173 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 5.0 with 1 tasks
2023-04-19 17:13:05,174 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-19 17:13:05,175 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 5] Running task 0.0 in stage 5.0 (TID 5)
2023-04-19 17:13:05,181 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 5] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-19 17:13:05,212 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 5] Code generated in 25.869724 ms
2023-04-19 17:13:05,226 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 5] Finished task 0.0 in stage 5.0 (TID 5). 1695 bytes result sent to driver
2023-04-19 17:13:05,227 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 5.0 (TID 5) in 53 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:05,228 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 5.0, whose tasks have all completed, from pool 
2023-04-19 17:13:05,229 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 5 (show at SparkController.java:69) finished in 0.067 s
2023-04-19 17:13:05,230 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 5 finished: show at SparkController.java:69, took 0.074153 s
2023-04-19 17:13:05,233 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Psv File
2023-04-19 17:13:05,354 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 4 ms to list leaf files for 1 paths.
2023-04-19 17:13:05,461 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-19 17:13:05,574 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:05,575 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: (length(trim(value#106, None)) > 0)
2023-04-19 17:13:05,575 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:13:05,576 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:05,632 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_12 stored as values in memory (estimated size 112.8 KB, free 997.4 MB)
2023-04-19 17:13:05,651 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.4 MB)
2023-04-19 17:13:05,653 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_12_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:05,655 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 12 from csv at SparkController.java:76
2023-04-19 17:13:05,656 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:05,723 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:76
2023-04-19 17:13:05,724 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 6 (csv at SparkController.java:76) with 1 output partitions
2023-04-19 17:13:05,725 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 6 (csv at SparkController.java:76)
2023-04-19 17:13:05,725 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:05,725 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:05,726 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 6 (MapPartitionsRDD[31] at csv at SparkController.java:76), which has no missing parents
2023-04-19 17:13:05,730 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_13 stored as values in memory (estimated size 8.9 KB, free 997.4 MB)
2023-04-19 17:13:05,734 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.6 KB, free 997.4 MB)
2023-04-19 17:13:05,735 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_13_piece0 in memory on 192.168.1.125:41995 (size: 4.6 KB, free: 998.2 MB)
2023-04-19 17:13:05,736 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 13 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:05,738 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[31] at csv at SparkController.java:76) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:05,738 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 6.0 with 1 tasks
2023-04-19 17:13:05,746 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-19 17:13:05,747 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 6] Running task 0.0 in stage 6.0 (TID 6)
2023-04-19 17:13:05,754 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 6] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-19 17:13:05,811 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 6] Finished task 0.0 in stage 6.0 (TID 6). 1325 bytes result sent to driver
2023-04-19 17:13:05,812 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 6.0 (TID 6) in 67 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:05,812 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 6.0, whose tasks have all completed, from pool 
2023-04-19 17:13:05,813 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 6 (csv at SparkController.java:76) finished in 0.085 s
2023-04-19 17:13:05,814 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 6 finished: csv at SparkController.java:76, took 0.090447 s
2023-04-19 17:13:05,859 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:05,860 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:05,860 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<value: string>
2023-04-19 17:13:05,861 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:05,920 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_14 stored as values in memory (estimated size 112.8 KB, free 997.3 MB)
2023-04-19 17:13:05,934 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_14_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.2 MB)
2023-04-19 17:13:05,937 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_14_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:05,941 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 14 from csv at SparkController.java:76
2023-04-19 17:13:05,942 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:05,978 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: csv at SparkController.java:76
2023-04-19 17:13:05,979 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 7 (csv at SparkController.java:76) with 1 output partitions
2023-04-19 17:13:05,979 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 7 (csv at SparkController.java:76)
2023-04-19 17:13:05,980 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:05,980 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:05,981 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 7 (MapPartitionsRDD[37] at csv at SparkController.java:76), which has no missing parents
2023-04-19 17:13:05,986 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_15 stored as values in memory (estimated size 14.0 KB, free 997.2 MB)
2023-04-19 17:13:05,988 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KB, free 997.2 MB)
2023-04-19 17:13:05,989 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_15_piece0 in memory on 192.168.1.125:41995 (size: 7.6 KB, free: 998.2 MB)
2023-04-19 17:13:05,991 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 15 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:05,992 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[37] at csv at SparkController.java:76) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:05,993 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 7.0 with 1 tasks
2023-04-19 17:13:05,994 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-19 17:13:05,995 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 7] Running task 0.0 in stage 7.0 (TID 7)
2023-04-19 17:13:06,003 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 7] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-19 17:13:06,107 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 7] Finished task 0.0 in stage 7.0 (TID 7). 1637 bytes result sent to driver
2023-04-19 17:13:06,108 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 7.0 (TID 7) in 114 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:06,109 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 7.0, whose tasks have all completed, from pool 
2023-04-19 17:13:06,110 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 7 (csv at SparkController.java:76) finished in 0.128 s
2023-04-19 17:13:06,112 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 7 finished: csv at SparkController.java:76, took 0.133845 s
2023-04-19 17:13:06,203 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:06,203 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:06,205 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-19 17:13:06,205 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:06,287 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 41.683522 ms
2023-04-19 17:13:06,346 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_16 stored as values in memory (estimated size 112.8 KB, free 997.1 MB)
2023-04-19 17:13:06,361 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_16_piece0 stored as bytes in memory (estimated size 20.7 KB, free 997.1 MB)
2023-04-19 17:13:06,362 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_16_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:06,363 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 16 from show at SparkController.java:79
2023-04-19 17:13:06,364 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:06,422 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:79
2023-04-19 17:13:06,424 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 8 (show at SparkController.java:79) with 1 output partitions
2023-04-19 17:13:06,424 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 8 (show at SparkController.java:79)
2023-04-19 17:13:06,424 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:06,424 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:06,425 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 8 (MapPartitionsRDD[41] at show at SparkController.java:79), which has no missing parents
2023-04-19 17:13:06,434 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_17 stored as values in memory (estimated size 12.8 KB, free 997.1 MB)
2023-04-19 17:13:06,440 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.5 KB, free 997.1 MB)
2023-04-19 17:13:06,441 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_17_piece0 in memory on 192.168.1.125:41995 (size: 6.5 KB, free: 998.2 MB)
2023-04-19 17:13:06,442 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 17 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:06,443 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[41] at show at SparkController.java:79) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:06,443 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 8.0 with 1 tasks
2023-04-19 17:13:06,444 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-19 17:13:06,445 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 8] Running task 0.0 in stage 8.0 (TID 8)
2023-04-19 17:13:06,454 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 8] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-19 17:13:06,492 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 8] Code generated in 35.165264 ms
2023-04-19 17:13:06,506 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 8] Finished task 0.0 in stage 8.0 (TID 8). 2219 bytes result sent to driver
2023-04-19 17:13:06,508 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 8.0 (TID 8) in 64 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:06,509 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 8.0, whose tasks have all completed, from pool 
2023-04-19 17:13:06,510 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 8 (show at SparkController.java:79) finished in 0.080 s
2023-04-19 17:13:06,510 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 8 finished: show at SparkController.java:79, took 0.087521 s
2023-04-19 17:13:06,516 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Psv File
2023-04-19 17:13:06,662 INFO org.apache.spark.sql.execution.datasources.InMemoryFileIndex [http-nio-8080-exec-1] It took 1 ms to list leaf files for 1 paths.
2023-04-19 17:13:06,779 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_18 stored as values in memory (estimated size 168.0 KB, free 996.9 MB)
2023-04-19 17:13:06,793 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.9 KB, free 996.9 MB)
2023-04-19 17:13:06,794 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_18_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.1 MB)
2023-04-19 17:13:06,795 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 18 from json at SparkController.java:87
2023-04-19 17:13:06,890 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat [http-nio-8080-exec-1] Total input paths to process : 1
2023-04-19 17:13:06,892 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat [http-nio-8080-exec-1] Total input paths to process : 1
2023-04-19 17:13:06,951 INFO org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat [http-nio-8080-exec-1] DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 308
2023-04-19 17:13:06,976 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: json at SparkController.java:87
2023-04-19 17:13:06,977 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 9 (json at SparkController.java:87) with 1 output partitions
2023-04-19 17:13:06,977 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 9 (json at SparkController.java:87)
2023-04-19 17:13:06,977 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:06,978 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:06,978 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 9 (MapPartitionsRDD[44] at json at SparkController.java:87), which has no missing parents
2023-04-19 17:13:07,007 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_19 stored as values in memory (estimated size 6.0 KB, free 996.9 MB)
2023-04-19 17:13:07,010 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_19_piece0 stored as bytes in memory (estimated size 3.6 KB, free 996.9 MB)
2023-04-19 17:13:07,011 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_19_piece0 in memory on 192.168.1.125:41995 (size: 3.6 KB, free: 998.1 MB)
2023-04-19 17:13:07,013 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 19 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:07,014 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[44] at json at SparkController.java:87) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:07,014 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 9.0 with 1 tasks
2023-04-19 17:13:07,048 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7982 bytes)
2023-04-19 17:13:07,049 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 9] Running task 0.0 in stage 9.0 (TID 9)
2023-04-19 17:13:07,077 INFO org.apache.spark.rdd.BinaryFileRDD [Executor task launch worker for task 9] Input split: Paths:/home/inferyx/Documents/Files/sample.json:0+308
2023-04-19 17:13:07,233 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 9] Finished task 0.0 in stage 9.0 (TID 9). 2005 bytes result sent to driver
2023-04-19 17:13:07,235 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 9.0 (TID 9) in 218 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:07,236 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 9.0, whose tasks have all completed, from pool 
2023-04-19 17:13:07,240 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 9 (json at SparkController.java:87) finished in 0.236 s
2023-04-19 17:13:07,242 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 9 finished: json at SparkController.java:87, took 0.265178 s
2023-04-19 17:13:07,398 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:07,400 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:07,401 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-19 17:13:07,402 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:07,506 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 42.608455 ms
2023-04-19 17:13:07,561 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_20 stored as values in memory (estimated size 112.3 KB, free 996.8 MB)
2023-04-19 17:13:07,576 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KB, free 996.7 MB)
2023-04-19 17:13:07,577 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_20_piece0 in memory on 192.168.1.125:41995 (size: 20.7 KB, free: 998.1 MB)
2023-04-19 17:13:07,578 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 20 from show at SparkController.java:89
2023-04-19 17:13:07,581 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:07,595 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:89
2023-04-19 17:13:07,596 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 10 (show at SparkController.java:89) with 1 output partitions
2023-04-19 17:13:07,597 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 10 (show at SparkController.java:89)
2023-04-19 17:13:07,597 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:07,597 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:07,598 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 10 (MapPartitionsRDD[48] at show at SparkController.java:89), which has no missing parents
2023-04-19 17:13:07,605 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_21 stored as values in memory (estimated size 16.4 KB, free 996.7 MB)
2023-04-19 17:13:07,608 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.3 KB, free 996.7 MB)
2023-04-19 17:13:07,609 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_21_piece0 in memory on 192.168.1.125:41995 (size: 7.3 KB, free: 998.1 MB)
2023-04-19 17:13:07,611 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 21 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:07,612 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at show at SparkController.java:89) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:07,612 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 10.0 with 1 tasks
2023-04-19 17:13:07,614 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-19 17:13:07,615 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 10] Running task 0.0 in stage 10.0 (TID 10)
2023-04-19 17:13:07,625 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 10] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-19 17:13:07,676 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 10] Code generated in 36.587193 ms
2023-04-19 17:13:07,741 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 10] Finished task 0.0 in stage 10.0 (TID 10). 1364 bytes result sent to driver
2023-04-19 17:13:07,742 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 10.0 (TID 10) in 129 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:07,742 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 10.0, whose tasks have all completed, from pool 
2023-04-19 17:13:07,743 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 10 (show at SparkController.java:89) finished in 0.143 s
2023-04-19 17:13:07,744 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 10 finished: show at SparkController.java:89, took 0.148704 s
2023-04-19 17:13:07,747 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Json File
2023-04-19 17:13:08,711 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 44
2023-04-19 17:13:08,712 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 287
2023-04-19 17:13:08,712 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 283
2023-04-19 17:13:08,712 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 127
2023-04-19 17:13:08,712 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 243
2023-04-19 17:13:08,712 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 297
2023-04-19 17:13:08,713 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 203
2023-04-19 17:13:08,716 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 280
2023-04-19 17:13:08,716 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 87
2023-04-19 17:13:08,716 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 207
2023-04-19 17:13:08,717 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 80
2023-04-19 17:13:08,767 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_9_piece0 on 192.168.1.125:41995 in memory (size: 7.6 KB, free: 998.1 MB)
2023-04-19 17:13:08,800 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 165
2023-04-19 17:13:08,801 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 197
2023-04-19 17:13:08,801 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 185
2023-04-19 17:13:08,801 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 267
2023-04-19 17:13:08,802 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 324
2023-04-19 17:13:08,806 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_15_piece0 on 192.168.1.125:41995 in memory (size: 7.6 KB, free: 998.1 MB)
2023-04-19 17:13:08,813 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 14
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 95
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 112
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 62
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 276
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 261
2023-04-19 17:13:08,814 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 201
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 277
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 174
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 115
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 163
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 190
2023-04-19 17:13:08,815 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 234
2023-04-19 17:13:08,816 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 24
2023-04-19 17:13:08,816 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 94
2023-04-19 17:13:08,816 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 180
2023-04-19 17:13:08,816 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 282
2023-04-19 17:13:08,817 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 21
2023-04-19 17:13:08,817 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 110
2023-04-19 17:13:08,817 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 36
2023-04-19 17:13:08,817 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 227
2023-04-19 17:13:08,817 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 166
2023-04-19 17:13:08,822 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_4_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.1 MB)
2023-04-19 17:13:08,831 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 248
2023-04-19 17:13:08,831 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 320
2023-04-19 17:13:08,831 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 290
2023-04-19 17:13:08,831 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 186
2023-04-19 17:13:08,832 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 124
2023-04-19 17:13:08,832 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 7
2023-04-19 17:13:08,832 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 311
2023-04-19 17:13:08,835 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_14_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:08,844 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 225
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 93
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 68
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 100
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 131
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 255
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 323
2023-04-19 17:13:08,845 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 246
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 193
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 304
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 66
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 170
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 172
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 8
2023-04-19 17:13:08,846 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 122
2023-04-19 17:13:08,847 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 313
2023-04-19 17:13:08,856 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_10_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:08,859 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 224
2023-04-19 17:13:08,860 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 181
2023-04-19 17:13:08,860 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 194
2023-04-19 17:13:08,860 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 222
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 306
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 279
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 183
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 188
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 160
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 143
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 78
2023-04-19 17:13:08,861 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 53
2023-04-19 17:13:08,862 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 73
2023-04-19 17:13:08,879 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_0_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.2 MB)
2023-04-19 17:13:08,892 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 223
2023-04-19 17:13:08,902 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_11_piece0 on 192.168.1.125:41995 in memory (size: 6.3 KB, free: 998.2 MB)
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 5
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 111
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 235
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 171
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 40
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 140
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 315
2023-04-19 17:13:08,906 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 116
2023-04-19 17:13:08,907 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 64
2023-04-19 17:13:08,907 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 244
2023-04-19 17:13:08,912 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_17_piece0 on 192.168.1.125:41995 in memory (size: 6.5 KB, free: 998.2 MB)
2023-04-19 17:13:08,925 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 42
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 10
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 146
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 6
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 130
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 23
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 249
2023-04-19 17:13:08,926 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 275
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 49
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 119
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 157
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 179
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 266
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 107
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 253
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 48
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 274
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 56
2023-04-19 17:13:08,927 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 182
2023-04-19 17:13:08,929 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_5_piece0 on 192.168.1.125:41995 in memory (size: 5.7 KB, free: 998.2 MB)
2023-04-19 17:13:08,940 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 245
2023-04-19 17:13:08,941 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 247
2023-04-19 17:13:08,941 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 308
2023-04-19 17:13:08,941 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 52
2023-04-19 17:13:08,941 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 61
2023-04-19 17:13:08,941 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 239
2023-04-19 17:13:08,942 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 33
2023-04-19 17:13:08,942 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 206
2023-04-19 17:13:08,942 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 120
2023-04-19 17:13:08,942 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 229
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 176
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 148
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 37
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 164
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 316
2023-04-19 17:13:08,943 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 79
2023-04-19 17:13:08,953 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_19_piece0 on 192.168.1.125:41995 in memory (size: 3.6 KB, free: 998.2 MB)
2023-04-19 17:13:08,973 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 292
2023-04-19 17:13:08,974 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 28
2023-04-19 17:13:08,974 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 241
2023-04-19 17:13:08,974 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 30
2023-04-19 17:13:08,974 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 54
2023-04-19 17:13:08,974 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 106
2023-04-19 17:13:08,987 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 28.142225 ms
2023-04-19 17:13:08,988 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_21_piece0 on 192.168.1.125:41995 in memory (size: 7.3 KB, free: 998.2 MB)
2023-04-19 17:13:08,994 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 18
2023-04-19 17:13:08,994 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 263
2023-04-19 17:13:08,994 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 314
2023-04-19 17:13:08,994 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 294
2023-04-19 17:13:08,994 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 152
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 231
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 11
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 220
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 29
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 70
2023-04-19 17:13:08,995 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 219
2023-04-19 17:13:08,998 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_16_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:09,002 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 284
2023-04-19 17:13:09,002 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 65
2023-04-19 17:13:09,002 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 209
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 125
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 204
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 31
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 88
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 310
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 103
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 205
2023-04-19 17:13:09,003 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 217
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 300
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 285
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 16
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 41
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 195
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 46
2023-04-19 17:13:09,004 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 3
2023-04-19 17:13:09,005 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 307
2023-04-19 17:13:09,005 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 155
2023-04-19 17:13:09,005 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 104
2023-04-19 17:13:09,005 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 136
2023-04-19 17:13:09,005 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 268
2023-04-19 17:13:09,011 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_3_piece0 on 192.168.1.125:41995 in memory (size: 7.6 KB, free: 998.3 MB)
2023-04-19 17:13:09,014 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 142
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 177
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 26
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 69
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 1
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 147
2023-04-19 17:13:09,015 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 226
2023-04-19 17:13:09,016 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 240
2023-04-19 17:13:09,025 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_2_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:09,032 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 24.934145 ms
2023-04-19 17:13:09,039 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 202
2023-04-19 17:13:09,039 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 257
2023-04-19 17:13:09,040 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 0
2023-04-19 17:13:09,040 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 108
2023-04-19 17:13:09,040 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 286
2023-04-19 17:13:09,040 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 102
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 187
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 278
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 199
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 128
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 321
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 25
2023-04-19 17:13:09,041 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 299
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 264
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 281
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 91
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 17
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 137
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 20
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 210
2023-04-19 17:13:09,042 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 256
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 309
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 150
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 191
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 71
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 250
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 27
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 75
2023-04-19 17:13:09,043 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 270
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 105
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 254
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 211
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 9
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 129
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 123
2023-04-19 17:13:09,044 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 228
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 317
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 198
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 237
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 269
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 138
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 133
2023-04-19 17:13:09,045 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 173
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 92
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 175
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 262
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 167
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 67
2023-04-19 17:13:09,046 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 60
2023-04-19 17:13:09,055 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Removed broadcast_1_piece0 on 192.168.1.125:41995 in memory (size: 4.6 KB, free: 998.3 MB)
2023-04-19 17:13:09,059 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 162
2023-04-19 17:13:09,060 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 47
2023-04-19 17:13:09,062 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 312
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 85
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 145
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 89
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 322
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 90
2023-04-19 17:13:09,063 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 212
2023-04-19 17:13:09,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 252
2023-04-19 17:13:09,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 265
2023-04-19 17:13:09,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 272
2023-04-19 17:13:09,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 151
2023-04-19 17:13:09,064 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 113
2023-04-19 17:13:09,066 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Removed broadcast_6_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 121
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 82
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 4
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 13
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 72
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 216
2023-04-19 17:13:09,072 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 144
2023-04-19 17:13:09,073 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 118
2023-04-19 17:13:09,073 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 98
2023-04-19 17:13:09,073 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 319
2023-04-19 17:13:09,075 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_20_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.3 MB)
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 326
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 327
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 99
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 38
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 233
2023-04-19 17:13:09,079 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 2
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 81
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 109
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 221
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 293
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 126
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 169
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 15
2023-04-19 17:13:09,080 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 101
2023-04-19 17:13:09,081 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 153
2023-04-19 17:13:09,086 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_13_piece0 on 192.168.1.125:41995 in memory (size: 4.6 KB, free: 998.3 MB)
2023-04-19 17:13:09,089 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 117
2023-04-19 17:13:09,089 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 12
2023-04-19 17:13:09,089 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 251
2023-04-19 17:13:09,089 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 134
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 51
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 208
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 238
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 159
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 86
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 325
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 43
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 158
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 168
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 50
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 59
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 154
2023-04-19 17:13:09,090 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 77
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 63
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 156
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 215
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 114
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 178
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 230
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 32
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 19
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 57
2023-04-19 17:13:09,091 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 305
2023-04-19 17:13:09,096 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_8_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.4 MB)
2023-04-19 17:13:09,096 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:106
2023-04-19 17:13:09,098 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 11 (show at SparkController.java:106) with 1 output partitions
2023-04-19 17:13:09,098 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 11 (show at SparkController.java:106)
2023-04-19 17:13:09,098 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:09,098 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:09,099 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 11 (MapPartitionsRDD[53] at show at SparkController.java:106), which has no missing parents
2023-04-19 17:13:09,105 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 76
2023-04-19 17:13:09,106 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 236
2023-04-19 17:13:09,106 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 132
2023-04-19 17:13:09,106 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 34
2023-04-19 17:13:09,107 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_22 stored as values in memory (estimated size 7.5 KB, free 998.1 MB)
2023-04-19 17:13:09,110 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_22_piece0 stored as bytes in memory (estimated size 3.5 KB, free 998.1 MB)
2023-04-19 17:13:09,111 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_22_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.4 MB)
2023-04-19 17:13:09,113 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 22 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:09,113 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Removed broadcast_7_piece0 on 192.168.1.125:41995 in memory (size: 4.6 KB, free: 998.4 MB)
2023-04-19 17:13:09,114 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[53] at show at SparkController.java:106) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:09,114 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 11.0 with 1 tasks
2023-04-19 17:13:09,122 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 218
2023-04-19 17:13:09,122 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 302
2023-04-19 17:13:09,122 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 301
2023-04-19 17:13:09,122 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 96
2023-04-19 17:13:09,122 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 303
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 141
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 161
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 232
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 84
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 196
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 149
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 22
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 184
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 273
2023-04-19 17:13:09,123 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 39
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 74
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 189
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 83
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 298
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 35
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 55
2023-04-19 17:13:09,124 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 213
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 242
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 291
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 288
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 200
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 192
2023-04-19 17:13:09,125 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 271
2023-04-19 17:13:09,126 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 8705 bytes)
2023-04-19 17:13:09,127 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 11] Running task 0.0 in stage 11.0 (TID 11)
2023-04-19 17:13:09,132 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_12_piece0 on 192.168.1.125:41995 in memory (size: 20.7 KB, free: 998.4 MB)
2023-04-19 17:13:09,143 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 11] Finished task 0.0 in stage 11.0 (TID 11). 1841 bytes result sent to driver
2023-04-19 17:13:09,145 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 58
2023-04-19 17:13:09,146 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 45
2023-04-19 17:13:09,146 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 289
2023-04-19 17:13:09,146 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 318
2023-04-19 17:13:09,146 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 11.0 (TID 11) in 31 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:09,146 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 11.0, whose tasks have all completed, from pool 
2023-04-19 17:13:09,149 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 11 (show at SparkController.java:106) finished in 0.048 s
2023-04-19 17:13:09,150 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 11 finished: show at SparkController.java:106, took 0.053500 s
2023-04-19 17:13:09,155 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Removed broadcast_18_piece0 on 192.168.1.125:41995 in memory (size: 20.9 KB, free: 998.4 MB)
2023-04-19 17:13:09,158 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:106
2023-04-19 17:13:09,159 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 12 (show at SparkController.java:106) with 2 output partitions
2023-04-19 17:13:09,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 12 (show at SparkController.java:106)
2023-04-19 17:13:09,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:09,160 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 259
2023-04-19 17:13:09,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:09,160 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 139
2023-04-19 17:13:09,160 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 214
2023-04-19 17:13:09,160 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 258
2023-04-19 17:13:09,161 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 296
2023-04-19 17:13:09,161 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 12 (MapPartitionsRDD[53] at show at SparkController.java:106), which has no missing parents
2023-04-19 17:13:09,161 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 295
2023-04-19 17:13:09,161 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 260
2023-04-19 17:13:09,161 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 97
2023-04-19 17:13:09,161 INFO org.apache.spark.ContextCleaner [Spark Context Cleaner] Cleaned accumulator 135
2023-04-19 17:13:09,167 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_23 stored as values in memory (estimated size 7.5 KB, free 998.4 MB)
2023-04-19 17:13:09,170 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.5 KB, free 998.4 MB)
2023-04-19 17:13:09,171 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_23_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.4 MB)
2023-04-19 17:13:09,172 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 23 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:09,173 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[53] at show at SparkController.java:106) (first 15 tasks are for partitions Vector(1, 2))
2023-04-19 17:13:09,173 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 12.0 with 2 tasks
2023-04-19 17:13:09,174 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 1, PROCESS_LOCAL, 8334 bytes)
2023-04-19 17:13:09,175 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 1.0 in stage 12.0 (TID 13, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-19 17:13:09,176 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 12] Running task 0.0 in stage 12.0 (TID 12)
2023-04-19 17:13:09,176 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 13] Running task 1.0 in stage 12.0 (TID 13)
2023-04-19 17:13:09,181 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 13] Finished task 1.0 in stage 12.0 (TID 13). 1112 bytes result sent to driver
2023-04-19 17:13:09,184 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 1.0 in stage 12.0 (TID 13) in 10 ms on localhost (executor driver) (1/2)
2023-04-19 17:13:09,185 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 12] Finished task 0.0 in stage 12.0 (TID 12). 1186 bytes result sent to driver
2023-04-19 17:13:09,186 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 12.0 (TID 12) in 12 ms on localhost (executor driver) (2/2)
2023-04-19 17:13:09,186 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 12.0, whose tasks have all completed, from pool 
2023-04-19 17:13:09,189 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 12 (show at SparkController.java:106) finished in 0.027 s
2023-04-19 17:13:09,190 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 12 finished: show at SparkController.java:106, took 0.031887 s
2023-04-19 17:13:09,195 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] Reading Excel File
2023-04-19 17:13:10,007 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:10,008 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:10,009 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:10,010 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:10,023 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_24 stored as values in memory (estimated size 167.6 KB, free 998.2 MB)
2023-04-19 17:13:10,036 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_24_piece0 stored as bytes in memory (estimated size 20.9 KB, free 998.2 MB)
2023-04-19 17:13:10,038 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_24_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.4 MB)
2023-04-19 17:13:10,040 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 24 from jdbc at SparkController.java:125
2023-04-19 17:13:10,042 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:10,077 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:125
2023-04-19 17:13:10,078 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 13 (jdbc at SparkController.java:125) with 1 output partitions
2023-04-19 17:13:10,078 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 13 (jdbc at SparkController.java:125)
2023-04-19 17:13:10,079 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:10,079 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:10,079 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 13 (MapPartitionsRDD[58] at jdbc at SparkController.java:125), which has no missing parents
2023-04-19 17:13:10,089 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_25 stored as values in memory (estimated size 15.9 KB, free 998.2 MB)
2023-04-19 17:13:10,093 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.5 KB, free 998.2 MB)
2023-04-19 17:13:10,094 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_25_piece0 in memory on 192.168.1.125:41995 (size: 8.5 KB, free: 998.4 MB)
2023-04-19 17:13:10,095 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 25 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:10,096 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[58] at jdbc at SparkController.java:125) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:10,096 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 13.0 with 1 tasks
2023-04-19 17:13:10,098 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-19 17:13:10,099 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 14] Running task 0.0 in stage 13.0 (TID 14)
2023-04-19 17:13:10,153 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 14] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-19 17:13:10,336 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 14] Finished task 0.0 in stage 13.0 (TID 14). 1437 bytes result sent to driver
2023-04-19 17:13:10,338 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 13.0 (TID 14) in 240 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:10,339 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 13.0, whose tasks have all completed, from pool 
2023-04-19 17:13:10,340 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 13 (jdbc at SparkController.java:125) finished in 0.257 s
2023-04-19 17:13:10,341 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 13 finished: jdbc at SparkController.java:125, took 0.263578 s
2023-04-19 17:13:10,476 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:10,477 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:10,477 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:10,478 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:10,506 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_26 stored as values in memory (estimated size 167.6 KB, free 998.0 MB)
2023-04-19 17:13:10,518 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_26_piece0 stored as bytes in memory (estimated size 20.9 KB, free 998.0 MB)
2023-04-19 17:13:10,520 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_26_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.3 MB)
2023-04-19 17:13:10,522 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 26 from show at SparkController.java:127
2023-04-19 17:13:10,523 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:10,540 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:127
2023-04-19 17:13:10,542 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 14 (show at SparkController.java:127) with 1 output partitions
2023-04-19 17:13:10,542 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 14 (show at SparkController.java:127)
2023-04-19 17:13:10,542 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:10,542 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:10,543 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 14 (MapPartitionsRDD[64] at show at SparkController.java:127), which has no missing parents
2023-04-19 17:13:10,546 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_27 stored as values in memory (estimated size 10.4 KB, free 998.0 MB)
2023-04-19 17:13:10,549 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.7 KB, free 998.0 MB)
2023-04-19 17:13:10,552 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_27_piece0 in memory on 192.168.1.125:41995 (size: 5.7 KB, free: 998.3 MB)
2023-04-19 17:13:10,552 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 27 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:10,553 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[64] at show at SparkController.java:127) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:10,553 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 14.0 with 1 tasks
2023-04-19 17:13:10,555 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8266 bytes)
2023-04-19 17:13:10,555 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 15] Running task 0.0 in stage 14.0 (TID 15)
2023-04-19 17:13:10,562 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 15] Reading File path: file:///home/inferyx/Documents/Files/addresses.csv, range: 0-328, partition values: [empty row]
2023-04-19 17:13:10,571 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 15] Finished task 0.0 in stage 14.0 (TID 15). 1677 bytes result sent to driver
2023-04-19 17:13:10,572 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 14.0 (TID 15) in 18 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:10,573 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 14.0, whose tasks have all completed, from pool 
2023-04-19 17:13:10,574 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 14 (show at SparkController.java:127) finished in 0.030 s
2023-04-19 17:13:10,575 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 14 finished: show at SparkController.java:127, took 0.033765 s
2023-04-19 17:13:10,577 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Csv File
2023-04-19 17:13:10,753 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:10,754 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:10,754 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:10,755 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:10,765 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_28 stored as values in memory (estimated size 167.8 KB, free 997.8 MB)
2023-04-19 17:13:10,785 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_28_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.8 MB)
2023-04-19 17:13:10,786 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_28_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.3 MB)
2023-04-19 17:13:10,789 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 28 from jdbc at SparkController.java:134
2023-04-19 17:13:10,790 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:10,812 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:134
2023-04-19 17:13:10,813 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 15 (jdbc at SparkController.java:134) with 1 output partitions
2023-04-19 17:13:10,813 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 15 (jdbc at SparkController.java:134)
2023-04-19 17:13:10,814 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:10,815 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:10,817 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 15 (MapPartitionsRDD[69] at jdbc at SparkController.java:134), which has no missing parents
2023-04-19 17:13:10,822 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_29 stored as values in memory (estimated size 16.0 KB, free 997.8 MB)
2023-04-19 17:13:10,824 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.6 KB, free 997.8 MB)
2023-04-19 17:13:10,824 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_29_piece0 in memory on 192.168.1.125:41995 (size: 8.6 KB, free: 998.3 MB)
2023-04-19 17:13:10,825 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 29 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:10,826 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[69] at jdbc at SparkController.java:134) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:10,827 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 15.0 with 1 tasks
2023-04-19 17:13:10,828 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-19 17:13:10,828 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 16] Running task 0.0 in stage 15.0 (TID 16)
2023-04-19 17:13:10,871 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 16] Code generated in 25.668087 ms
2023-04-19 17:13:10,908 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 16] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-19 17:13:11,150 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 16] Finished task 0.0 in stage 15.0 (TID 16). 1394 bytes result sent to driver
2023-04-19 17:13:11,152 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 15.0 (TID 16) in 324 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:11,152 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 15.0, whose tasks have all completed, from pool 
2023-04-19 17:13:11,153 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 15 (jdbc at SparkController.java:134) finished in 0.334 s
2023-04-19 17:13:11,153 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 15 finished: jdbc at SparkController.java:134, took 0.341061 s
2023-04-19 17:13:11,249 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:11,250 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:11,251 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct< John: string, Doe: string, 120 jefferson st.: string, Riverside: string,  NJ: string ... 1 more field>
2023-04-19 17:13:11,251 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:11,286 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_30 stored as values in memory (estimated size 167.8 KB, free 997.6 MB)
2023-04-19 17:13:11,300 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_30_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.6 MB)
2023-04-19 17:13:11,302 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_30_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.3 MB)
2023-04-19 17:13:11,304 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 30 from show at SparkController.java:136
2023-04-19 17:13:11,304 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:11,320 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:136
2023-04-19 17:13:11,322 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 16 (show at SparkController.java:136) with 1 output partitions
2023-04-19 17:13:11,322 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 16 (show at SparkController.java:136)
2023-04-19 17:13:11,322 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:11,322 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:11,323 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 16 (MapPartitionsRDD[75] at show at SparkController.java:136), which has no missing parents
2023-04-19 17:13:11,326 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_31 stored as values in memory (estimated size 12.6 KB, free 997.6 MB)
2023-04-19 17:13:11,328 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_31_piece0 stored as bytes in memory (estimated size 6.3 KB, free 997.6 MB)
2023-04-19 17:13:11,329 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_31_piece0 in memory on 192.168.1.125:41995 (size: 6.3 KB, free: 998.3 MB)
2023-04-19 17:13:11,329 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 31 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:11,330 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[75] at show at SparkController.java:136) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:11,330 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 16.0 with 1 tasks
2023-04-19 17:13:11,332 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8263 bytes)
2023-04-19 17:13:11,334 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 17] Running task 0.0 in stage 16.0 (TID 17)
2023-04-19 17:13:11,338 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 17] Reading File path: file:///home/inferyx/Documents/Files/output.psv, range: 0-340, partition values: [empty row]
2023-04-19 17:13:11,351 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 17] Finished task 0.0 in stage 16.0 (TID 17). 1695 bytes result sent to driver
2023-04-19 17:13:11,352 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 16.0 (TID 17) in 21 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:11,353 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 16.0, whose tasks have all completed, from pool 
2023-04-19 17:13:11,354 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 16 (show at SparkController.java:136) finished in 0.029 s
2023-04-19 17:13:11,355 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 16 finished: show at SparkController.java:136, took 0.033832 s
2023-04-19 17:13:11,358 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Psv File
2023-04-19 17:13:11,463 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:11,464 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:11,465 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-19 17:13:11,466 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:11,474 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_32 stored as values in memory (estimated size 167.8 KB, free 997.4 MB)
2023-04-19 17:13:11,488 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_32_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.4 MB)
2023-04-19 17:13:11,489 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_32_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.3 MB)
2023-04-19 17:13:11,491 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 32 from jdbc at SparkController.java:142
2023-04-19 17:13:11,491 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:11,508 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:142
2023-04-19 17:13:11,510 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 17 (jdbc at SparkController.java:142) with 1 output partitions
2023-04-19 17:13:11,510 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 17 (jdbc at SparkController.java:142)
2023-04-19 17:13:11,511 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:11,511 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:11,512 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 17 (MapPartitionsRDD[80] at jdbc at SparkController.java:142), which has no missing parents
2023-04-19 17:13:11,520 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_33 stored as values in memory (estimated size 16.0 KB, free 997.4 MB)
2023-04-19 17:13:11,522 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.6 KB, free 997.4 MB)
2023-04-19 17:13:11,523 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_33_piece0 in memory on 192.168.1.125:41995 (size: 8.6 KB, free: 998.3 MB)
2023-04-19 17:13:11,524 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 33 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:11,526 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[80] at jdbc at SparkController.java:142) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:11,526 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 17.0 with 1 tasks
2023-04-19 17:13:11,528 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-19 17:13:11,528 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 18] Running task 0.0 in stage 17.0 (TID 18)
2023-04-19 17:13:11,563 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 18] Code generated in 23.098877 ms
2023-04-19 17:13:11,593 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 18] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-19 17:13:12,752 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 18] Finished task 0.0 in stage 17.0 (TID 18). 1394 bytes result sent to driver
2023-04-19 17:13:12,753 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 17.0 (TID 18) in 1226 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:12,753 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 17.0, whose tasks have all completed, from pool 
2023-04-19 17:13:12,754 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 17 (jdbc at SparkController.java:142) finished in 1.241 s
2023-04-19 17:13:12,755 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 17 finished: jdbc at SparkController.java:142, took 1.245979 s
2023-04-19 17:13:12,833 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:12,834 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:12,835 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<Name: string, " ""Team""": string, " ""Position""": string, " ""Height(inches)""": int, " ""Weight(lbs)""": string ... 1 more field>
2023-04-19 17:13:12,836 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:12,868 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_34 stored as values in memory (estimated size 167.8 KB, free 997.2 MB)
2023-04-19 17:13:12,885 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_34_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.2 MB)
2023-04-19 17:13:12,887 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_34_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.2 MB)
2023-04-19 17:13:12,889 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 34 from show at SparkController.java:144
2023-04-19 17:13:12,890 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:12,908 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:144
2023-04-19 17:13:12,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 18 (show at SparkController.java:144) with 1 output partitions
2023-04-19 17:13:12,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 18 (show at SparkController.java:144)
2023-04-19 17:13:12,909 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:12,910 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:12,910 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 18 (MapPartitionsRDD[86] at show at SparkController.java:144), which has no missing parents
2023-04-19 17:13:12,915 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_35 stored as values in memory (estimated size 12.8 KB, free 997.2 MB)
2023-04-19 17:13:12,917 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_35_piece0 stored as bytes in memory (estimated size 6.5 KB, free 997.1 MB)
2023-04-19 17:13:12,918 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_35_piece0 in memory on 192.168.1.125:41995 (size: 6.5 KB, free: 998.2 MB)
2023-04-19 17:13:12,919 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 35 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:12,920 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[86] at show at SparkController.java:144) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:12,920 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 18.0 with 1 tasks
2023-04-19 17:13:12,921 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 18.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8268 bytes)
2023-04-19 17:13:12,922 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 19] Running task 0.0 in stage 18.0 (TID 19)
2023-04-19 17:13:12,926 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 19] Reading File path: file:///home/inferyx/Documents/Files/mlb_players.tsv, range: 0-61049, partition values: [empty row]
2023-04-19 17:13:12,936 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 19] Finished task 0.0 in stage 18.0 (TID 19). 2219 bytes result sent to driver
2023-04-19 17:13:12,937 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 18.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:12,937 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 18.0, whose tasks have all completed, from pool 
2023-04-19 17:13:12,938 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 18 (show at SparkController.java:144) finished in 0.027 s
2023-04-19 17:13:12,938 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 18 finished: show at SparkController.java:144, took 0.029695 s
2023-04-19 17:13:12,942 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Tsv File
2023-04-19 17:13:13,195 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:13,196 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:13,196 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-19 17:13:13,197 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:13,265 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 9.555775 ms
2023-04-19 17:13:13,306 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [http-nio-8080-exec-1] Code generated in 27.840389 ms
2023-04-19 17:13:13,315 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_36 stored as values in memory (estimated size 167.5 KB, free 997.0 MB)
2023-04-19 17:13:13,333 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_36_piece0 stored as bytes in memory (estimated size 20.9 KB, free 997.0 MB)
2023-04-19 17:13:13,334 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-0] Added broadcast_36_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.2 MB)
2023-04-19 17:13:13,336 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 36 from show at SparkController.java:155
2023-04-19 17:13:13,336 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:13,362 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:155
2023-04-19 17:13:13,364 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 19 (show at SparkController.java:155) with 1 output partitions
2023-04-19 17:13:13,364 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 19 (show at SparkController.java:155)
2023-04-19 17:13:13,364 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:13,365 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:13,366 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 19 (MapPartitionsRDD[93] at show at SparkController.java:155), which has no missing parents
2023-04-19 17:13:13,478 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_37 stored as values in memory (estimated size 27.6 KB, free 996.9 MB)
2023-04-19 17:13:13,481 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_37_piece0 stored as bytes in memory (estimated size 12.1 KB, free 996.9 MB)
2023-04-19 17:13:13,481 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_37_piece0 in memory on 192.168.1.125:41995 (size: 12.1 KB, free: 998.2 MB)
2023-04-19 17:13:13,483 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 37 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:13,484 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[93] at show at SparkController.java:155) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:13,484 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 19.0 with 1 tasks
2023-04-19 17:13:13,486 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-2] Starting task 0.0 in stage 19.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-19 17:13:13,487 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 20] Running task 0.0 in stage 19.0 (TID 20)
2023-04-19 17:13:13,573 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 20] Code generated in 43.09926 ms
2023-04-19 17:13:13,606 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 20] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-19 17:13:13,751 INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator [Executor task launch worker for task 20] Code generated in 82.638926 ms
2023-04-19 17:13:13,764 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 20] Finished task 0.0 in stage 19.0 (TID 20). 1727 bytes result sent to driver
2023-04-19 17:13:13,765 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 19.0 (TID 20) in 279 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:13,766 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 19.0, whose tasks have all completed, from pool 
2023-04-19 17:13:13,767 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 19 (show at SparkController.java:155) finished in 0.399 s
2023-04-19 17:13:13,767 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 19 finished: show at SparkController.java:155, took 0.404377 s
2023-04-19 17:13:13,919 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Pruning directories with: 
2023-04-19 17:13:13,920 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Post-Scan Filters: 
2023-04-19 17:13:13,921 INFO org.apache.spark.sql.execution.datasources.FileSourceStrategy [http-nio-8080-exec-1] Output Data Schema: struct<address: struct<city: string, postalCode: string, state: string, streetAddress: string ... 2 more fields>, age: bigint, firstName: string, gender: string, lastName: string ... 1 more field>
2023-04-19 17:13:13,921 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Pushed Filters: 
2023-04-19 17:13:13,934 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_38 stored as values in memory (estimated size 167.5 KB, free 996.8 MB)
2023-04-19 17:13:13,948 INFO org.apache.spark.storage.memory.MemoryStore [http-nio-8080-exec-1] Block broadcast_38_piece0 stored as bytes in memory (estimated size 20.9 KB, free 996.7 MB)
2023-04-19 17:13:13,949 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_38_piece0 in memory on 192.168.1.125:41995 (size: 20.9 KB, free: 998.2 MB)
2023-04-19 17:13:13,952 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Created broadcast 38 from jdbc at SparkController.java:160
2023-04-19 17:13:13,954 INFO org.apache.spark.sql.execution.FileSourceScanExec [http-nio-8080-exec-1] Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2023-04-19 17:13:13,991 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:160
2023-04-19 17:13:13,992 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 20 (jdbc at SparkController.java:160) with 1 output partitions
2023-04-19 17:13:13,992 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 20 (jdbc at SparkController.java:160)
2023-04-19 17:13:13,992 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:13,993 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:13,996 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 20 (MapPartitionsRDD[101] at jdbc at SparkController.java:160), which has no missing parents
2023-04-19 17:13:14,008 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_39 stored as values in memory (estimated size 30.0 KB, free 996.7 MB)
2023-04-19 17:13:14,010 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_39_piece0 stored as bytes in memory (estimated size 13.5 KB, free 996.7 MB)
2023-04-19 17:13:14,011 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_39_piece0 in memory on 192.168.1.125:41995 (size: 13.5 KB, free: 998.2 MB)
2023-04-19 17:13:14,012 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 39 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:14,013 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[101] at jdbc at SparkController.java:160) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:14,013 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 20.0 with 1 tasks
2023-04-19 17:13:14,015 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 20.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8264 bytes)
2023-04-19 17:13:14,018 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 21] Running task 0.0 in stage 20.0 (TID 21)
2023-04-19 17:13:14,075 INFO org.apache.spark.sql.execution.datasources.FileScanRDD [Executor task launch worker for task 21] Reading File path: file:///home/inferyx/Documents/Files/sample.json, range: 0-308, partition values: [empty row]
2023-04-19 17:13:14,258 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 21] Finished task 0.0 in stage 20.0 (TID 21). 1484 bytes result sent to driver
2023-04-19 17:13:14,259 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 20.0 (TID 21) in 245 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:14,259 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 20.0, whose tasks have all completed, from pool 
2023-04-19 17:13:14,260 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 20 (jdbc at SparkController.java:160) finished in 0.263 s
2023-04-19 17:13:14,261 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 20 finished: jdbc at SparkController.java:160, took 0.269686 s
2023-04-19 17:13:14,407 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:162
2023-04-19 17:13:14,409 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 21 (show at SparkController.java:162) with 1 output partitions
2023-04-19 17:13:14,409 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 21 (show at SparkController.java:162)
2023-04-19 17:13:14,409 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:14,409 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:14,410 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 21 (MapPartitionsRDD[108] at show at SparkController.java:162), which has no missing parents
2023-04-19 17:13:14,415 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_40 stored as values in memory (estimated size 7.5 KB, free 996.7 MB)
2023-04-19 17:13:14,420 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.5 KB, free 996.7 MB)
2023-04-19 17:13:14,421 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_40_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.2 MB)
2023-04-19 17:13:14,422 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 40 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:14,423 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[108] at show at SparkController.java:162) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:14,423 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 21.0 with 1 tasks
2023-04-19 17:13:14,424 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 21.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8705 bytes)
2023-04-19 17:13:14,425 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 22] Running task 0.0 in stage 21.0 (TID 22)
2023-04-19 17:13:14,428 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 22] Finished task 0.0 in stage 21.0 (TID 22). 1798 bytes result sent to driver
2023-04-19 17:13:14,430 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 0.0 in stage 21.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:14,431 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-2] Removed TaskSet 21.0, whose tasks have all completed, from pool 
2023-04-19 17:13:14,432 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 21 (show at SparkController.java:162) finished in 0.020 s
2023-04-19 17:13:14,432 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 21 finished: show at SparkController.java:162, took 0.024336 s
2023-04-19 17:13:14,440 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:162
2023-04-19 17:13:14,441 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 22 (show at SparkController.java:162) with 2 output partitions
2023-04-19 17:13:14,441 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 22 (show at SparkController.java:162)
2023-04-19 17:13:14,442 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:14,442 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:14,442 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 22 (MapPartitionsRDD[108] at show at SparkController.java:162), which has no missing parents
2023-04-19 17:13:14,444 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_41 stored as values in memory (estimated size 7.5 KB, free 996.7 MB)
2023-04-19 17:13:14,445 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.5 KB, free 996.7 MB)
2023-04-19 17:13:14,446 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-2] Added broadcast_41_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.2 MB)
2023-04-19 17:13:14,449 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 41 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:14,450 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 22 (MapPartitionsRDD[108] at show at SparkController.java:162) (first 15 tasks are for partitions Vector(1, 2))
2023-04-19 17:13:14,450 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 22.0 with 2 tasks
2023-04-19 17:13:14,453 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 0.0 in stage 22.0 (TID 23, localhost, executor driver, partition 1, PROCESS_LOCAL, 8334 bytes)
2023-04-19 17:13:14,453 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-1] Starting task 1.0 in stage 22.0 (TID 24, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-19 17:13:14,454 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 23] Running task 0.0 in stage 22.0 (TID 23)
2023-04-19 17:13:14,454 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 24] Running task 1.0 in stage 22.0 (TID 24)
2023-04-19 17:13:14,459 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 24] Finished task 1.0 in stage 22.0 (TID 24). 1112 bytes result sent to driver
2023-04-19 17:13:14,460 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 23] Finished task 0.0 in stage 22.0 (TID 23). 1186 bytes result sent to driver
2023-04-19 17:13:14,460 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 1.0 in stage 22.0 (TID 24) in 7 ms on localhost (executor driver) (1/2)
2023-04-19 17:13:14,461 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 0.0 in stage 22.0 (TID 23) in 8 ms on localhost (executor driver) (2/2)
2023-04-19 17:13:14,461 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 22.0, whose tasks have all completed, from pool 
2023-04-19 17:13:14,462 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 22 (show at SparkController.java:162) finished in 0.019 s
2023-04-19 17:13:14,462 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 22 finished: show at SparkController.java:162, took 0.021220 s
2023-04-19 17:13:14,465 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Json File
2023-04-19 17:13:14,676 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: jdbc at SparkController.java:170
2023-04-19 17:13:14,678 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 23 (jdbc at SparkController.java:170) with 4 output partitions
2023-04-19 17:13:14,678 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 23 (jdbc at SparkController.java:170)
2023-04-19 17:13:14,678 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:14,678 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:14,678 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 23 (MapPartitionsRDD[114] at jdbc at SparkController.java:170), which has no missing parents
2023-04-19 17:13:14,690 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_42 stored as values in memory (estimated size 13.9 KB, free 996.7 MB)
2023-04-19 17:13:14,692 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_42_piece0 stored as bytes in memory (estimated size 6.8 KB, free 996.7 MB)
2023-04-19 17:13:14,692 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-3] Added broadcast_42_piece0 in memory on 192.168.1.125:41995 (size: 6.8 KB, free: 998.1 MB)
2023-04-19 17:13:14,693 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 42 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:14,693 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 4 missing tasks from ResultStage 23 (MapPartitionsRDD[114] at jdbc at SparkController.java:170) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2023-04-19 17:13:14,694 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 23.0 with 4 tasks
2023-04-19 17:13:14,695 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 0.0 in stage 23.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8705 bytes)
2023-04-19 17:13:14,695 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 1.0 in stage 23.0 (TID 26, localhost, executor driver, partition 1, PROCESS_LOCAL, 8334 bytes)
2023-04-19 17:13:14,695 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 2.0 in stage 23.0 (TID 27, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-19 17:13:14,696 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-0] Starting task 3.0 in stage 23.0 (TID 28, localhost, executor driver, partition 3, PROCESS_LOCAL, 8295 bytes)
2023-04-19 17:13:14,696 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 25] Running task 0.0 in stage 23.0 (TID 25)
2023-04-19 17:13:14,696 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 26] Running task 1.0 in stage 23.0 (TID 26)
2023-04-19 17:13:14,699 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 27] Running task 2.0 in stage 23.0 (TID 27)
2023-04-19 17:13:14,709 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 28] Running task 3.0 in stage 23.0 (TID 28)
2023-04-19 17:13:14,878 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 26] Finished task 1.0 in stage 23.0 (TID 26). 1064 bytes result sent to driver
2023-04-19 17:13:14,878 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 1.0 in stage 23.0 (TID 26) in 183 ms on localhost (executor driver) (1/4)
2023-04-19 17:13:14,938 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 27] Finished task 2.0 in stage 23.0 (TID 27). 1064 bytes result sent to driver
2023-04-19 17:13:14,938 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 25] Finished task 0.0 in stage 23.0 (TID 25). 1064 bytes result sent to driver
2023-04-19 17:13:14,940 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 2.0 in stage 23.0 (TID 27) in 245 ms on localhost (executor driver) (2/4)
2023-04-19 17:13:14,942 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 23.0 (TID 25) in 248 ms on localhost (executor driver) (3/4)
2023-04-19 17:13:14,949 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 28] Finished task 3.0 in stage 23.0 (TID 28). 1064 bytes result sent to driver
2023-04-19 17:13:14,950 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-0] Finished task 3.0 in stage 23.0 (TID 28) in 254 ms on localhost (executor driver) (4/4)
2023-04-19 17:13:14,950 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-0] Removed TaskSet 23.0, whose tasks have all completed, from pool 
2023-04-19 17:13:14,952 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 23 (jdbc at SparkController.java:170) finished in 0.271 s
2023-04-19 17:13:14,952 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 23 finished: jdbc at SparkController.java:170, took 0.275345 s
2023-04-19 17:13:15,128 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:172
2023-04-19 17:13:15,129 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 24 (show at SparkController.java:172) with 1 output partitions
2023-04-19 17:13:15,130 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 24 (show at SparkController.java:172)
2023-04-19 17:13:15,130 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:15,130 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:15,130 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 24 (MapPartitionsRDD[121] at show at SparkController.java:172), which has no missing parents
2023-04-19 17:13:15,133 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_43 stored as values in memory (estimated size 7.5 KB, free 996.7 MB)
2023-04-19 17:13:15,136 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.5 KB, free 996.6 MB)
2023-04-19 17:13:15,137 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_43_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.1 MB)
2023-04-19 17:13:15,138 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 43 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:15,139 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[121] at show at SparkController.java:172) (first 15 tasks are for partitions Vector(0))
2023-04-19 17:13:15,140 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 24.0 with 1 tasks
2023-04-19 17:13:15,141 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 24.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 8705 bytes)
2023-04-19 17:13:15,142 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 29] Running task 0.0 in stage 24.0 (TID 29)
2023-04-19 17:13:15,148 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 29] Finished task 0.0 in stage 24.0 (TID 29). 1841 bytes result sent to driver
2023-04-19 17:13:15,150 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-1] Finished task 0.0 in stage 24.0 (TID 29) in 9 ms on localhost (executor driver) (1/1)
2023-04-19 17:13:15,150 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-1] Removed TaskSet 24.0, whose tasks have all completed, from pool 
2023-04-19 17:13:15,151 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 24 (show at SparkController.java:172) finished in 0.020 s
2023-04-19 17:13:15,152 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 24 finished: show at SparkController.java:172, took 0.023455 s
2023-04-19 17:13:15,158 INFO org.apache.spark.SparkContext [http-nio-8080-exec-1] Starting job: show at SparkController.java:172
2023-04-19 17:13:15,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Got job 25 (show at SparkController.java:172) with 2 output partitions
2023-04-19 17:13:15,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Final stage: ResultStage 25 (show at SparkController.java:172)
2023-04-19 17:13:15,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Parents of final stage: List()
2023-04-19 17:13:15,160 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Missing parents: List()
2023-04-19 17:13:15,161 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting ResultStage 25 (MapPartitionsRDD[121] at show at SparkController.java:172), which has no missing parents
2023-04-19 17:13:15,163 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_44 stored as values in memory (estimated size 7.5 KB, free 996.6 MB)
2023-04-19 17:13:15,168 INFO org.apache.spark.storage.memory.MemoryStore [dag-scheduler-event-loop] Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.5 KB, free 996.6 MB)
2023-04-19 17:13:15,169 INFO org.apache.spark.storage.BlockManagerInfo [dispatcher-event-loop-1] Added broadcast_44_piece0 in memory on 192.168.1.125:41995 (size: 3.5 KB, free: 998.1 MB)
2023-04-19 17:13:15,170 INFO org.apache.spark.SparkContext [dag-scheduler-event-loop] Created broadcast 44 from broadcast at DAGScheduler.scala:1163
2023-04-19 17:13:15,171 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] Submitting 2 missing tasks from ResultStage 25 (MapPartitionsRDD[121] at show at SparkController.java:172) (first 15 tasks are for partitions Vector(1, 2))
2023-04-19 17:13:15,171 INFO org.apache.spark.scheduler.TaskSchedulerImpl [dag-scheduler-event-loop] Adding task set 25.0 with 2 tasks
2023-04-19 17:13:15,173 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 0.0 in stage 25.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 8334 bytes)
2023-04-19 17:13:15,174 INFO org.apache.spark.scheduler.TaskSetManager [dispatcher-event-loop-3] Starting task 1.0 in stage 25.0 (TID 31, localhost, executor driver, partition 2, PROCESS_LOCAL, 8271 bytes)
2023-04-19 17:13:15,174 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 31] Running task 1.0 in stage 25.0 (TID 31)
2023-04-19 17:13:15,174 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 30] Running task 0.0 in stage 25.0 (TID 30)
2023-04-19 17:13:15,178 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 31] Finished task 1.0 in stage 25.0 (TID 31). 1112 bytes result sent to driver
2023-04-19 17:13:15,179 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-2] Finished task 1.0 in stage 25.0 (TID 31) in 6 ms on localhost (executor driver) (1/2)
2023-04-19 17:13:15,180 INFO org.apache.spark.executor.Executor [Executor task launch worker for task 30] Finished task 0.0 in stage 25.0 (TID 30). 1186 bytes result sent to driver
2023-04-19 17:13:15,190 INFO org.apache.spark.scheduler.TaskSetManager [task-result-getter-3] Finished task 0.0 in stage 25.0 (TID 30) in 18 ms on localhost (executor driver) (2/2)
2023-04-19 17:13:15,190 INFO org.apache.spark.scheduler.TaskSchedulerImpl [task-result-getter-3] Removed TaskSet 25.0, whose tasks have all completed, from pool 
2023-04-19 17:13:15,192 INFO org.apache.spark.scheduler.DAGScheduler [dag-scheduler-event-loop] ResultStage 25 (show at SparkController.java:172) finished in 0.030 s
2023-04-19 17:13:15,195 INFO org.apache.spark.scheduler.DAGScheduler [http-nio-8080-exec-1] Job 25 finished: show at SparkController.java:172, took 0.036345 s
2023-04-19 17:13:15,201 INFO com.example.spring.jwt.mongodb.controllers.SparkController [http-nio-8080-exec-1] writting Excel File
